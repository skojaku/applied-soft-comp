<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Part 3: From Categories to Coordinates – Applied Soft Computing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../m07-representation/04-universal.html" rel="next">
<link href="../m07-representation/02-structuralism.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-1f36e651aa5e1ffb5e4e9439ef2eb9d4.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "|"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../assets/custom.css">
</head>

<body class="nav-sidebar docked nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Applied Soft Computing</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../toc.html"> 
<span class="menu-text">Table of Contents</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-modules" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Modules</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-modules">    
        <li>
    <a class="dropdown-item" href="../m01-toolkit/overview.html">
 <span class="dropdown-text">Module 1: The Data Scientist’s Toolkit</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-visualization/overview.html">
 <span class="dropdown-text">Module 2: Visualizing Complexity</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m03-agentic-coding/overview.html">
 <span class="dropdown-text">Module 3: Agentic Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m04-text/overview.html">
 <span class="dropdown-text">Module 4: Deep Learning for Text</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m05-images/overview.html">
 <span class="dropdown-text">Module 5: Deep Learning for Images</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m06-graph/overview.html">
 <span class="dropdown-text">Module 6: Deep Learning for Graphs</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m07-representation/overview.html">
 <span class="dropdown-text">Module 7: Representations &amp; Structuralism</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../m07-representation/overview.html">Module 7: Representations &amp; Structuralism</a></li><li class="breadcrumb-item"><a href="../m07-representation/03-embeddings.html">Part 3: From Categories to Coordinates</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Course Information</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/welcome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About Us</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/why-applied-soft-computing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Why applied soft computing?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/discord.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Discord</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/discord-bot-usage.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Discord Bot Usage</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/sprint-project.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sprint Projects</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/deliverables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deliverables</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 1: The Data Scientist’s Toolkit</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/git-github.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Version Control with Git &amp; GitHub</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/tidy-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Tidy Data Philosophy</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/data-provenance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Provenance</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/reproduceability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Reproducibility</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 2: Visualizing Complexity</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Principles of Effective Visualization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/1d-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing 1D Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/2d-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing 2D Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/highd-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing High-Dimensional Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/time-series.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing Time-Series</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 3: Agentic Coding</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-agentic-coding/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-agentic-coding/hands-on.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hands-on</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-agentic-coding/prompt-tuning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prompt Tuning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-agentic-coding/agentic-ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Agentic AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-agentic-coding/context-engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Context Engineering</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 4: Deep Learning for Text</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-text/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-text/llm-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Large Language Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-text/gpt-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GPT Inference: Sampling Strategies</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-text/tokenization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tokenization: Unboxing How LLMs Read Text</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-text/transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Transformers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-text/bert-gpt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BERT &amp; GPT</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-text/sentence-transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sentence Transformers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-text/word-embeddings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-text/semaxis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Semaxis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-text/word-bias.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word Bias</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 5: Deep Learning for Images</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-images/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-images/01-what-is-an-image.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part 1: What is an Image?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-images/02-the-deep-learning-revolution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part 2: The Deep Learning Revolution</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-images/03-using-cnn-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part 3: Using CNN Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-images/04-cnn-innovations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part 4: CNN Innovations</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 6: Deep Learning for Graphs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-graph/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-graph/01-from-images-to-graphs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part 1: From Images to Graphs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-graph/02-spectral-perspective.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part 2: The Spectral Perspective</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-graph/03-spatial-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part 3: Spatial Graph Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-graph/04-graph-embeddings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part 4: Graph Embeddings</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 7: Representations &amp; Structuralism</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-representation/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-representation/01-boundaries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part 1: When Boundaries Blur</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-representation/02-structuralism.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part 2: Meaning as Difference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-representation/03-embeddings.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Part 3: From Categories to Coordinates</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-representation/04-universal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part 4: Universal Representations</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../m07-representation/overview.html">Module 7: Representations &amp; Structuralism</a></li><li class="breadcrumb-item"><a href="../m07-representation/03-embeddings.html">Part 3: From Categories to Coordinates</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Part 3: From Categories to Coordinates</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-note callout-titled" title="What you'll learn in this module">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What you’ll learn in this module
</div>
</div>
<div class="callout-body-container callout-body">
<p>This module introduces vector embeddings as the computational realization of structuralism.</p>
<p>You’ll learn:</p>
<ul>
<li>What <strong>vector embeddings</strong> are and how they dissolve artificial category boundaries.</li>
<li>How <strong>word2vec</strong> learns meaning from context through the distributional hypothesis.</li>
<li>The role of <strong>contrastive learning</strong> and negative sampling in carving semantic space.</li>
<li>Why <strong>vector arithmetic</strong> captures relationships as geometric directions.</li>
<li>How <strong>hyperbolic embeddings</strong> use geometry to capture hierarchy (metaphor) vs.&nbsp;association (metonymy).</li>
<li>The counterintuitive insight that meaning emerges from exclusion (Apoha theory) and the notion of <strong>continuous representation</strong>.</li>
<li>Practical consequences for understanding political ideology, semantic similarity, and beyond.</li>
</ul>
</div>
</div>
<section id="the-limits-of-traditional-classification" class="level2">
<h2 class="anchored" data-anchor-id="the-limits-of-traditional-classification">The Limits of Traditional Classification</h2>
<p>Let’s talk about how traditional machine learning builds decision boundaries. You collect labeled data, extract features, and train a classifier to draw a line (or hyperplane) separating Class A from Class B. The output is binary: spam or not-spam, fraud or legitimate, cat or dog.</p>
<p>This approach works when categories are genuinely discrete. But what about political ideology? You might lean liberal on economic issues but conservative on others. Your position isn’t “left or right” but a point in a multidimensional space, and forcing it into a binary choice destroys information.</p>
<p>What about word meanings? Is “dog” more similar to “wolf” or “cat”? The answer is “it depends” on whether you care about biology (dogs and wolves share a genus) or domestication (dogs and cats are both pets). A classification system would force you to choose one dimension, while a continuous representation can capture both simultaneously.</p>
</section>
<section id="enter-vector-embeddings" class="level2">
<h2 class="anchored" data-anchor-id="enter-vector-embeddings">Enter Vector Embeddings</h2>
<p>Vector embeddings solve this by mapping each concept to coordinates in a high-dimensional continuous space. Instead of “this word belongs to category X”, you get “this word lives at position <span class="math inline">[0.23, -0.15, 0.87, ...]</span> in 300-dimensional space”. Similarity becomes geometric distance, and relationships become directional vectors.</p>
<p><img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgzOCWLMCxaOTTpZKlTr-o3t4l2Uq_IekgKg8P-1nM1OdwonDOiNs0ZCXaMbv12MMTMrstCb2NuKVwS2Oalw7R615Agjr2dkU6-P31BTQxZCHrBAQWJynwROgxFTuHCpwQzTPQauoDd5JQ/s1600/embedding-mnist.gif" class="img-fluid"></p>
<p>This is the mathematical realization of structuralism. Each word’s meaning is determined by its position relative to all other words. There are no hard boundaries, only neighborhoods of varying density.</p>
</section>
<section id="how-word2vec-works" class="level2">
<h2 class="anchored" data-anchor-id="how-word2vec-works">How Word2Vec Works</h2>
<p>Word2vec learns through a prediction task. Given a center word, predict the context words around it.</p>
<p>Specifically, the model of word2vec is given by</p>
<p><span class="math display">
P(j \vert i) = \frac{\exp(u_i^\top v_j)}{\sum_{k \in \mathcal{V}} \exp(u_i^\top v_k)},
</span></p>
<p>where <span class="math inline">u_i</span> is the “in-vector” of center word <span class="math inline">i</span> and <span class="math inline">v_j</span> is the “out-vector” of context word <span class="math inline">j</span>.</p>
<p>But here’s the problem. The denominator involves a sum over all words in the dictionary, which is not computable even for a moderate vocabulary size since we need to compute the probability of all words many times during training.</p>
<p>What’s the solution? <strong>Negative Sampling</strong> offers an elegant answer.</p>
<p>Instead of calculating probabilities over the entire dictionary, we play a simpler game. We give the model a pair of words and ask: “Is this a real context pair, or did I just randomly grab a word from the dictionary?”</p>
<p>The model tries to output <span class="math inline">1</span> for real pairs and <span class="math inline">0</span> for random (negative) pairs. Mathematically, we want to maximize this objective:</p>
<p><span class="math display"> J(\theta) = \log \sigma(\mathbf{u}_w \cdot \mathbf{v}_c) + \sum_{i=1}^k \mathbb{E}_{v_n \sim P_n} [\log \sigma(-\mathbf{u}_w \cdot \mathbf{v}_{n})] </span></p>
<p>Here, <span class="math inline">\sigma</span> is the sigmoid function that squashes values between 0 and 1. The first term encourages the model to put (<span class="math inline">v_c</span>) close to (<span class="math inline">v_w</span>). The second term encourages it to push (<span class="math inline">v_c</span>) away from (<span class="math inline">v_n</span>).</p>
<section id="why-does-negative-sampling-work" class="level3">
<h3 class="anchored" data-anchor-id="why-does-negative-sampling-work">Why Does Negative Sampling Work?</h3>
<p>We can prove that this seemingly ad-hoc contrastive training is actually doing the right thing. Let us write explicitly the sigmoid function:</p>
<p><span class="math display">
p(y=1 \vert x) = \sigma(x) = \frac{1}{1 + \exp(-x)}
</span></p>
<p>The probability that two words <span class="math inline">x=(i,j)</span> are positive (i.e., <span class="math inline">y=1</span>) relative to the probability that they are not (i.e., <span class="math inline">y=0</span>) is given by:</p>
<p><span class="math display">
\log \frac{p(y=1 \vert x)}{p(y=0 \vert x)} = x
</span></p>
<p>Thus, the argument of the sigmoid function (i.e., <span class="math inline">x</span>) represents the log-odds of the positive example, also called <strong>logits</strong>.</p>
<p>Now, let us make it clear that the negative samples are sampled from a probability distribution <span class="math inline">q</span>. When observing a word pair <span class="math inline">x=(i,j)</span>, there are two possible events:</p>
<ol type="1">
<li><span class="math inline">y=1</span>: The pair <span class="math inline">(i,j)</span> is a real context pair, with probability <span class="math inline">p(i,j)</span></li>
<li><span class="math inline">y=0</span>: The pair <span class="math inline">(i,j)</span> is sampled by random chance, with probability <span class="math inline">q(i,j)</span></li>
</ol>
<p>The probability that <span class="math inline">x</span> comes from the positive class is given by:</p>
<p><span class="math display">
p(y=1 \vert x) = \frac{p(i,j)}{p(i,j) + q(i,j)}
</span></p>
<p>This is a sigmoid function, i.e.,</p>
<p><span class="math display">
p(y=1 \vert x) = \frac{1}{1 + \exp\left(-\ln p(i,j) + \ln q(i,j)\right)}
</span></p>
<p>with the logits given by</p>
<p><span class="math display">
\ln p(i,j) - \ln q(i,j)
</span></p>
<p>which word2vec expresses as the dot similarity of two vectors, i.e.,</p>
<p><span class="math display">
u_i^\top v_j
</span></p>
<p>Putting together we have</p>
<p><span class="math display">
u_i^\top v_j = \ln p(i,j) - \ln q(j) \implies p(i,j) = \frac{q(i,j)\exp\left(u_i^\top v_j\right)}{\sum_{k \in \mathcal{V}} q(i,k)\exp\left(u_i^\top v_k\right)}
</span></p>
<p>Therefore, negative sampling learns the word2vec model when sampling the negatives uniformly at random <span class="math inline">q(j) = \frac{1}{|\mathcal{V}|}</span>.</p>
<p>In practice, the noise distribution <span class="math inline">q</span> is not uniform but is (roughly) proportional to the frequency of the word <span class="math inline">j</span>. Consequently, the learned model is not precisely the word2vec model but a variant with an inference bias. Yet, this bias is surprisingly useful in downstream tasks. See <span class="citation" data-cites="kojaku2021neurips">(<a href="#ref-kojaku2021neurips" role="doc-biblioref">Kojaku et al. 2021</a>)</span> and <span class="citation" data-cites="kojaku2023network">(<a href="#ref-kojaku2023network" role="doc-biblioref">Kojaku et al. 2023</a>)</span> for more details.</p>
</section>
</section>
<section id="word2vec-implicitly-factorizes-a-co-occurrence-matrix" class="level2">
<h2 class="anchored" data-anchor-id="word2vec-implicitly-factorizes-a-co-occurrence-matrix">Word2Vec Implicitly Factorizes a Co-Occurrence Matrix</h2>
<p><img src="../figs/word2vec-factorization.png" class="img-fluid"></p>
<p>We have taken for granted that word2vec learns useful embeddings of words. But why are learned embeddings so useful despite being learned heuristically?</p>
<p>The previous section allows us to approach this theoretical question. It provides the analytical form of the similarity as:</p>
<p><span class="math display">
u_i^\top v_j = \ln p(i,j) - \ln q(j).
</span></p>
<p>Notice that <span class="math inline">u_i, v_i</span> have dimension <span class="math inline">d</span> much smaller than the vocabulary size <span class="math inline">|\mathcal{V}|</span>. On the other hand, the right hand side can have distinct values for each pair <span class="math inline">(i,j)</span>, forming a matrix with <span class="math inline">|\mathcal{V}|^2</span> entries.</p>
<p>From this perspective, word2vec is approximating this matrix by a product of two submatrices:</p>
<p><span class="math display">
\mathbf{U} \cdot \mathbf{V}^\top = \mathbf{R},
</span></p>
<p>where</p>
<p><span class="math display">
\begin{align}
\mathbf{R} &amp;= \log p(i,j) - \log q(j) \\
\mathbf{U} &amp;= \begin{bmatrix}
u_1 \\ u_2 \\ \vdots \\ u_{|\mathcal{V}|}
\end{bmatrix},
\mathbf{V} &amp;= \begin{bmatrix}
v_1 \\ v_2 \\ \vdots \\ v_{|\mathcal{V}|}
\end{bmatrix}
\end{align}
</span></p>
<p>What does <span class="math inline">R_{ij}</span> mean? The matrix entry <span class="math inline">R_{ij}</span> has an information-theoretic meaning.</p>
<p>It is called the pointwise mutual information (PMI) between words <span class="math inline">i</span> and <span class="math inline">j</span>. In other words, the dot product of the vectors represents this information-theoretic quantity.</p>
<p>This is an interesting insight as it provides a clear interpretation of the learned embeddings. Furthermore, it also provides a clear analytical threshold as to when word2vec can capture groups and miss them. See <span class="citation" data-cites="kojaku2023network">(<a href="#ref-kojaku2023network" role="doc-biblioref">Kojaku et al. 2023</a>)</span> for more details.</p>
<section id="a-universe-of-contrast" class="level3">
<h3 class="anchored" data-anchor-id="a-universe-of-contrast">A Universe of Contrast</h3>
<p>This principle of pulling positive examples together while pushing negative ones apart grew into one of the most successful ideas in modern AI: <strong>Contrastive Learning</strong>.</p>
<p>Different tasks require different mathematical formulations of this “push-pull” dynamic.</p>
<section id="ranking-triplet-loss" class="level4">
<h4 class="anchored" data-anchor-id="ranking-triplet-loss">Ranking &amp; Triplet Loss</h4>
<p>Used historically in systems like FaceNet for face recognition. The goal here is <strong>relative order</strong>.</p>
<p>We don’t care about the absolute coordinates, only that your face is closer to your own photos than to anyone else’s.</p>
<p>We define an <strong>anchor</strong> (<span class="math inline">a</span>), a <strong>positive</strong> example (<span class="math inline">p</span>), and a <strong>negative</strong> example (<span class="math inline">n</span>). We want the distance <span class="math inline">d(a, p)</span> to be smaller than <span class="math inline">d(a, n)</span> by at least a margin <span class="math inline">m</span>:</p>
<p><span class="math display"> L = \max(0, d(a, p) - d(a, n) + m) </span></p>
<p>This forces a structured geometry where: <span class="math inline">d(a, p) + m &lt; d(a, n)</span>. The model learns to “rank” the correct match higher than the incorrect one.</p>
</section>
<section id="infonce-simclr-clip" class="level4">
<h4 class="anchored" data-anchor-id="infonce-simclr-clip">InfoNCE (SimCLR, CLIP)</h4>
<p>This is the standard loss for modern self-supervised learning (like SimCLR or CLIP). Instead of comparing one positive against one negative, we play a game of “pick the correct partner from the lineup.”</p>
<p>Given a batch of <span class="math inline">N</span> examples, the model must identify the single correct positive pair <span class="math inline">(i, j)</span> against all other <span class="math inline">N-1</span> “negative” samples in the batch.</p>
<p><span class="math display"> L_{i,j} = -\log \frac{\exp(\text{sim}(\mathbf{z}_i, \mathbf{z}_j) / \tau)}{\sum_{k=1}^{2N} \mathbb{1}_{[k \neq i]} \exp(\text{sim}(\mathbf{z}_i, \mathbf{z}_k) / \tau)} </span></p>
<p>It looks like a Softmax (specifically, categorical cross-entropy), but calculated only over the current batch rather than the full vocabulary. It forces the embedding to filter out specifically hard negatives from the current batch.</p>
</section>
</section>
</section>
<section id="the-magic-of-vector-arithmetic" class="level2">
<h2 class="anchored" data-anchor-id="the-magic-of-vector-arithmetic">The Magic of Vector Arithmetic</h2>
<p>Once you have vectors, you can do arithmetic on meaning. The famous example:</p>
<p><span class="math display"> \vec{\text{King}} - \vec{\text{Man}} + \vec{\text{Woman}} \approx \vec{\text{Queen}} </span></p>
<p>Why does this work? Relationships are directions in space.</p>
<p>The vector from “Man” to “King” represents the relationship “royal-version-of”. When you apply that same direction to “Woman”, you arrive near “Queen”.</p>
<p>The arrows from countries to capitals are parallel. They point in roughly the same direction because they represent the same relationship.</p>
<p>This structure wasn’t programmed in. It emerged from observing how words co-occur in text.</p>
<p>The model discovered that “France” and “Paris” appear in similar contexts to how “Germany” and “Berlin” appear, and encoded this as geometric parallelism.</p>
<p>There are many such examples.</p>
<ul>
<li><a href="https://www.nature.com/articles/s41586-019-1335-8">Tshitoyan, V., Dagdelen, J., Weston, L., Dunn, A., Rong, Z., Kononova, O., … &amp; Jain, A. (2019). Unsupervised word embeddings capture latent knowledge from materials science literature. Nature, 571(7763), 95-98.</a></li>
<li><a href="https://www.science.org/doi/full/10.1126/sciadv.abb9004">Peng, H., Ke, Q., Budak, C., Romero, D. M., &amp; Ahn, Y. Y. (2021). Neural embeddings of scholarly periodicals reveal complex disciplinary organizations. Science Advances, 7(17), eabb9004.</a></li>
<li><a href="https://dl.acm.org/doi/10.1145/3589334.3645464">Kim, S., Ahn, Y. Y., &amp; Park, J. (2024, May). Labor space: A unifying representation of the labor market via large language models. In Proceedings of the ACM Web Conference 2024 (pp.&nbsp;2441-2451).</a></li>
<li><a href="https://academic.oup.com/jamia/article-abstract/26/6/516/5369362">Ke, Q. (2019). Identifying translational science through embeddings of controlled vocabularies. Journal of the American Medical Informatics Association, 26(6), 516-523.</a></li>
</ul>
</section>
<section id="image-embeddings-also-exhibit-semantic-structure" class="level2">
<h2 class="anchored" data-anchor-id="image-embeddings-also-exhibit-semantic-structure">Image Embeddings Also Exhibit Semantic Structure</h2>
<p><img src="https://blog.metaphysic.ai/wp-content/uploads/2022/07/male-to-female-stylegan-EXAMPLE-v2.gif" class="img-fluid"></p>
<p>This phenomenon isn’t limited to text. Generative models for images, such as VAEs (Variational Autoencoders) and GANs (Generative Adversarial Networks), learn a high-dimensional <strong>latent space</strong> where every point represents a possible image.</p>
<p>Just as with word embeddings, this space is semantically structured. Moving in a specific direction corresponds to a meaningful change in the image.</p>
<p>For example, we can calculate an <strong>attribute vector</strong> for “smiling” by taking the average position of all smiling faces and subtracting the average position of non-smiling faces:</p>
<p><span class="math display"> \vec{v}_{\text{smile}} = \text{mean}(\text{smiling faces}) - \text{mean}(\text{neutral faces}) </span></p>
<p>Adding this vector to the latent code of a new, neutral face will continuously transform it into a smiling one. This works for glasses, age, gender, and many other attributes.</p>
<p>The model doesn’t just memorize pixels. It learns the underlying factors of variation in the visual world. See <a href="https://arxiv.org/abs/1609.04468">White, T. (2016). Sampling generative networks. arXiv preprint arXiv:1609.04468.</a>.</p>
</section>
<section id="hyperbolic-embeddings" class="level2">
<h2 class="anchored" data-anchor-id="hyperbolic-embeddings">Hyperbolic Embeddings</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://ja.stateofaiguides.com/content/images/2022/12/poincare-01.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Shift your attention to a fundamental limitation in everything we’ve seen so far. Models like Word2Vec and GloVe are built on <strong>Metonymy</strong> (from the Greek <em>meta</em> “change” + <em>onyma</em> “name”), learning from the syntagmatic axis, the “next-to” relationship. “Crown” is embedded near “King” because they appear together in text context. They capture <em>association</em>.</p>
<p>But what about <strong>Metaphor</strong>? Metaphor relies on the paradigmatic axis, the “is-a” or “substitution” relationship. A “Lion” is implicitly like a “Tiger” not because they hang out together, but because they occupy the same structural slot in the hierarchy of life (they are both big cats).</p>
<p>To capture this structural similarity, researchers turned to <strong>WordNet</strong>, a massive database explicitly constructed to map these “is-a” (hypernym) relationships. It is a map of taxonomies, effectively a giant tree of concepts.</p>
<p>When they tried to train standard Euclidean embeddings on WordNet, they hit a wall. Even with hundreds of dimensions, the models struggled to represent the deep, branching hierarchy without distorting the relationships. The problem wasn’t the data but the geometry itself.</p>
<p>Euclidean space is flat, but in a hierarchy (like a biological taxonomy or a corporate org chart), the number of nodes expands <strong>exponentially</strong> as you go deeper (Root <span class="math inline">\to</span> Children <span class="math inline">\to</span> Grandchildren). In flat space, the available volume only grows polynomially, so there simply isn’t enough “room” at the boundaries to fit this exponential growth. You end up crushing the leaf nodes together, losing the distinct structure.</p>
<p>To solve this, we need to exit flat space and enter <strong>Hyperbolic Space</strong>, often visualized as a Poincaré ball. In this non-Euclidean geometry, space itself expands exponentially as you move away from the center. Imagine a disk where, using a specific distance metric (Poincaré distance), the path to the edge is effectively infinite. Because the “room” available grows exactly as fast as the tree branches, you can fit an infinite tree structure within this finite disk by placing the root at the center, with the leaves fitting naturally near the boundary without crushing into each other.</p>
<p>This alignment of geometry and data is powerful. While Euclidean models might require 300 dimensions to separate concepts in WordNet, <strong>Poincaré embeddings</strong> can capture the same complex structure with high precision in as few as <strong>5 dimensions</strong>.</p>
<p>When the geometry fits the data, when we model metaphor with a space designed for hierarchies, the representation becomes incredibly efficient.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-kojaku2023network" class="csl-entry" role="listitem">
Kojaku, Sadamori, Filippo Radicchi, Yong-Yeol Ahn, and Santo Fortunato. 2023. <span>“Network Community Detection via Neural Embeddings.”</span> <em>arXiv Preprint arXiv:2306.13400</em>.
</div>
<div id="ref-kojaku2021neurips" class="csl-entry" role="listitem">
Kojaku, Sadamori, Jisung Yoon, Isabel Constantino, and Yong-Yeol Ahn. 2021. <span>“Residual2Vec: Debiasing Graph Embedding Using Random Graphs.”</span> In <em>Advances in Neural Information Processing Systems</em>. Curran Associates, Inc.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/skojaku\.github\.io\/applied-soft-comp\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../m07-representation/02-structuralism.html" class="pagination-link" aria-label="Part 2: Meaning as Difference">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Part 2: Meaning as Difference</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../m07-representation/04-universal.html" class="pagination-link" aria-label="Part 4: Universal Representations">
        <span class="nav-page-text">Part 4: Universal Representations</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2025, Sadamori Kojaku</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/skojaku/applied-soft-comp">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>
<script src="../assets/breadcrumb-toc.js"></script>




</body></html>