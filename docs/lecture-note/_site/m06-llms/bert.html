<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sadamori Kojaku">
<meta name="dcterms.date" content="2025-10-19">

<title>Applied Soft Computing: Modeling Complex Systems with Deep Learning – Applied Soft Computing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-0348920b7671f696dc9078d39bff215e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-fee01c958fd55f7b3b50896185ea610a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "|"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../assets/custom.css">
</head>

<body class="nav-sidebar docked nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../logo.jpg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Applied Soft Computing</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-toolkit--workflow" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Toolkit &amp; Workflow</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-toolkit--workflow">    
        <li class="dropdown-header">─── Module 1 ───</li>
        <li>
    <a class="dropdown-item" href="../m01-toolkit/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-toolkit/git-github.html">
 <span class="dropdown-text">Git &amp; GitHub</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-toolkit/tidy-data.html">
 <span class="dropdown-text">Tidy Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-toolkit/data-provenance.html">
 <span class="dropdown-text">Data Provenance</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-toolkit/environments.html">
 <span class="dropdown-text">Environments</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-visualization" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Visualization</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-visualization">    
        <li class="dropdown-header">─── Module 2 ───</li>
        <li>
    <a class="dropdown-item" href="../m02-visualization/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-visualization/principles.html">
 <span class="dropdown-text">Principles</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-visualization/dimensionality-reduction.html">
 <span class="dropdown-text">High-Dimensional Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-visualization/networks.html">
 <span class="dropdown-text">Networks</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-visualization/time-series.html">
 <span class="dropdown-text">Time-Series</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-deep-learning" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Deep Learning</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-deep-learning">    
        <li class="dropdown-header">─── Module 3: Text ───</li>
        <li>
    <a class="dropdown-item" href="../m03-text/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m03-text/word2vec.md">
 <span class="dropdown-text">Word2Vec</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m03-text/lstm.md">
 <span class="dropdown-text">RNNs &amp; LSTMs</span></a>
  </li>  
        <li class="dropdown-header">─── Module 4: Images ───</li>
        <li>
    <a class="dropdown-item" href="../m04-images/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m04-images/cnn.md">
 <span class="dropdown-text">CNNs</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m04-images/resnet.md">
 <span class="dropdown-text">ResNet</span></a>
  </li>  
        <li class="dropdown-header">─── Module 5: Graphs ───</li>
        <li>
    <a class="dropdown-item" href="../m05-graphs/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m05-graphs/graph-embedding-w-word2vec.html">
 <span class="dropdown-text">Graph Embeddings</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m05-graphs/graph-convolutional-network.html">
 <span class="dropdown-text">GNNs</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-advanced-topics" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Advanced Topics</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-advanced-topics">    
        <li class="dropdown-header">─── Module 6: LLMs ───</li>
        <li>
    <a class="dropdown-item" href="../m06-llms/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m06-llms/transformers.html">
 <span class="dropdown-text">Transformers</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m06-llms/scaling-emergence.html">
 <span class="dropdown-text">Scaling &amp; Emergence</span></a>
  </li>  
        <li class="dropdown-header">─── Module 7: Self-Supervised ───</li>
        <li>
    <a class="dropdown-item" href="../m07-self-supervised/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m07-self-supervised/contrastive-learning.html">
 <span class="dropdown-text">Contrastive Learning</span></a>
  </li>  
        <li class="dropdown-header">─── Module 8: Explainability ───</li>
        <li>
    <a class="dropdown-item" href="../m08-explainability/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m08-explainability/fairness.html">
 <span class="dropdown-text">Fairness &amp; Ethics</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Applied Soft Computing: Modeling Complex Systems with Deep Learning</li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Course Information</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Applied Soft Computing: Modeling Complex Systems with Deep Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/welcome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About Us</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/why-applied-soft-computing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Applied Soft Computing: Modeling Complex Systems with Deep Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/discord.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Discord</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/minidora-usage.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Using Minidora</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/how-to-submit-assignment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to submit assignment</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/deliverables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Applied Soft Computing: Modeling Complex Systems with Deep Learning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 1: The Data Scientist’s Toolkit</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/git-github.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Version Control with Git &amp; GitHub</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/tidy-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Tidy Data Philosophy</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/data-provenance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Provenance</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/environments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Reproducible Environments</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 2: Visualizing Complexity</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Principles of Effective Visualization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/dimensionality-reduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing High-Dimensional Data (t-SNE, UMAP)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/time-series.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing Time-Series</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 3: Deep Learning for Text</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/tf-idf.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">TF-IDF: Bag-of-Words Representation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/word2vec.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word Embeddings (Word2Vec)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/word2vec_plus.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Word2Vec Techniques</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/sem-axis.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Semantic Axes &amp; Historical Bias</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/bias-in-embedding.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bias in Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/doc2vec.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Document Embeddings (Doc2Vec)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/reccurrent-neural-net.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recurrent Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/lstm.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LSTM Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/elmo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ELMo: Contextual Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/seq2seq.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sequence-to-Sequence Models</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 4: Deep Learning for Images</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/image-processing.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Processing Fundamentals</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/cnn.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Convolutional Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/lenet.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LeNet Architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/alexnet.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AlexNet: Deep CNN Revolution</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/vgg.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">VGG Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/inception.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Inception &amp; Multi-Scale Features</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/batch-normalization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Batch Normalization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/resnet.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ResNet &amp; Skip Connections</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 5: Deep Learning for Graphs</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/spectral-embedding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Spectral Graph Embedding</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/graph-embedding-w-word2vec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Graph Embeddings with Word2Vec</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/spectral-vs-neural-embedding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Spectral vs.&nbsp;Neural Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/from-image-to-graph.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">From Images to Graphs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/graph-convolutional-network.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Graph Convolutional Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/popular-gnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Popular GNN Architectures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/software.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GNN Software &amp; Tools</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 6: Large Language Models &amp; Emergent Behavior</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Transformer Architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/bert.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BERT &amp; Contextual Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/sentence-bert.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sentence-BERT for Semantic Similarity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/gpt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GPT &amp; Generative Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/from-language-model-to-instruction-following.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">From Language Models to Instruction Following</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/prompt-tuning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prompt Engineering &amp; In-Context Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/scaling-emergence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Scaling Laws &amp; Emergent Abilities</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/llms-as-complex-systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LLMs as Complex Systems</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 7: Self-Supervised Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-self-supervised/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-self-supervised/paradigm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Self-Supervised Paradigm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-self-supervised/contrastive-learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Contrastive Learning (SimCLR)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-self-supervised/graphs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Self-Supervised Learning for Graphs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-self-supervised/time-series.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Self-Supervised Learning for Time-Series</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 8: Explainability &amp; Ethics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/need.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Need for Explainability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/attention.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Attention Visualization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/lime-shap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LIME &amp; SHAP</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/fairness.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Algorithmic Fairness &amp; Bias</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Causality vs.&nbsp;Correlation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Legacy Materials</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/what-to-learn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word &amp; Document Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/what-to-learn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recurrent Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/what-to-learn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Processing (CNNs)</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Applied Soft Computing: Modeling Complex Systems with Deep Learning</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Sadamori Kojaku </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 19, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="bidirectional-encoder-representations-from-transformers-bert" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Bidirectional Encoder Representations from Transformers (BERT)</h1>
<p>We learned about ELMo’s approach to the problem of polysemy using bidirectional LSTMs. BERT builds upon its bidirectional approach by using a self-attention mechanism in transformers. BERT has become the leading transformer model for natural language processing tasks like question answering and text classification. Its effectiveness led Google to incorporate it into their search engine to improve query understanding. In this section, we will explore BERT’s architecture and mechanisms.</p>
<p>```vjbtdgma https://cdn.botpenguin.com/assets/website/BERT_c35709b509.webp :name: bert_mlm :alt: BERT MLM :width: 50% :align: center</p>
<pre><code>
```{admonition} BERT in interactive mode:
:class: tip

[Here is a demo notebook for BERT](https://static.marimo.app/static/bert-ux7g)

To run the notebook, download the notebook as a `.py` file and run it with:

&gt; marimo edit --sandbox bert.py

You will need to install `marimo` and `uv` to run the notebook. But other packages will be installed automatically in uv's virtual environment.</code></pre>
<section id="architecture" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="architecture"><span class="header-section-number">1.1</span> Architecture</h2>
<p>BERT consists of a stack of encoder transformer layers. Each layer is composed of a self-attention mechanism, a feed-forward neural network, and layer normalization, wired together with residual connections. The output of each layer is fed into the next layer, and as we go through the layers, the token embeddings get more and more contextualized, reflecting the context more and more, thanks to the self-attention mechanism.</p>
<p>```vjbtdgma https://www.researchgate.net/publication/372906672/figure/fig2/AS:11431281179224913@1691164535766/BERT-model-architecture.ppm :name: bert_architecture :alt: BERT architecture :width: 80% :align: center</p>
<p>BERT consists of a stack of encoder transformer layers. The position embeddings are added to the token embeddings to provide the model with information about the position of the tokens in the sequence.</p>
<pre><code>
```{admonition} Which layer of BERT should we use?
:class: tip

BERT internally generates multiple hierarchical representations of the input sentence. The higher layers of the model capture more abstract and context-sensitive information, while the lower layers capture more local and surface-level information. Which layer to use depends on the task. For example, if we want to do text classification, we should use the output of the last layer. If we are interested in word-level representations, we should use the output of the first layer.</code></pre>
</section>
<section id="special-tokens" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="special-tokens"><span class="header-section-number">1.2</span> Special tokens</h2>
<p>BERT uses several special tokens to represent the input sentence.</p>
<ul>
<li>[CLS] is used to represent the start of the sentence.</li>
<li>[SEP] is used to represent the end of the sentence.</li>
<li>[MASK] is used to represent the masked words.</li>
<li>[UNK] is used to represent the unknown words.</li>
</ul>
<p>For example, the sentence “The cat sat on the mat. It then went to sleep.” is represented as “[CLS] The cat sat on the mat [SEP] It then went to sleep [SEP]”.</p>
<p>In BERT, [CLS] token is used to classify the input sentences, as we will see later. As a result, the model learns to encode a summary of the input sentence into the [CLS] token, which is particularly useful when we want the embedding of the whole input text, instead of the token level embeddings. {footcite}<code>reimers2019sentence</code></p>
</section>
<section id="position-and-segment-embeddings" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="position-and-segment-embeddings"><span class="header-section-number">1.3</span> Position and Segment embeddings</h2>
<p>BERT uses <em>position</em> and <em>segment</em> embeddings to provide the model with information about the position of the tokens in the sequence.</p>
<ul>
<li><p>Position embeddings are used to provide the model with information about the position of the tokens in the sequence. Unlike the sinusoidal position embedding used in the original transformer paper {footcite}<code>vaswani2017attention</code>, BERT uses learnable position embeddings.</p></li>
<li><p>The segment embeddings are used to distinguish the sentences in the input. For example, for the sentence “The cat sat on the mat. It then went to sleep.”, the tokens in the first sentence are added with segment embedding 0, and the tokens in the second sentence are added with segment embedding 1. These segmend embeddings are also learned during the pre-training process.</p></li>
</ul>
<p>```vjbtdgma https://lh3.googleusercontent.com/stK9CWIWiSuF_aq75q7_6wUqyqfePKzeLxqVet9IVNqrcyJqqg9hXkhuFXBXXbIjaGY15gSF9Yr7kyjceVXs5HbDMpmkhet49fhbtLsm9-4E4iCYckzGTsYSxOqRaVGNTkkhWykg :name: bert_position_segment_embeddings :alt: BERT position and segment embeddings :width: 80% :align: center</p>
<p>Position and segment embeddings in BERT. Position embeddings, which are learnable, are added to the token embeddings. Segment embeddings indicate the sentence that the token belongs to (e.g., <span class="math inline">E_A</span> and <span class="math inline">E_B</span>).</p>
<pre><code>
```{tip}
:class: tip

Position embeddings can be either absolute or relative:

Absolute position embeddings (like in BERT) directly encode the position of each token as a fixed index (1st, 2nd, 3rd position etc). Each position gets its own unique embedding vector that is learned during training.

Relative position embeddings (like sinusoidal embeddings in the original Transformer) encode the relative distance between tokens rather than their absolute positions. For example, they can encode that token A is 2 positions away from token B, regardless of their absolute positions in the sequence. This makes them more flexible for handling sequences of varying lengths.

For interested readers, you can read more about the difference between absolute and relative position embeddings in [The Use Case for Relative Position Embeddings – Ofir Press](https://ofir.io/The-Use-Case-for-Relative-Position-Embeddings/) and [Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation](https://arxiv.org/abs/2108.12409).</code></pre>
<section id="pre-training" class="level3">
<h3 class="anchored" data-anchor-id="pre-training">Pre-training</h3>
<p>A key aspect of BERT is its pre-training process, which involves two main objectives:</p>
<ul>
<li>Masked Language Modeling (MLM)</li>
<li>Next Sentence Prediction (NSP)</li>
</ul>
<p>Both objectives are designed to learn the language structure, such as the relationship between words and sentences.</p>
<section id="masked-language-modeling-mlm" class="level4">
<h4 class="anchored" data-anchor-id="masked-language-modeling-mlm">Masked Language Modeling (MLM)</h4>
<p>In MLM, the model is trained to predict the original words that are masked in the input sentence. The masked words are replaced with a special token, [MASK], and the model is trained to predict the original words. For example, the sentence “The cat [MASK] on the mat” is transformed into “The cat [MASK] on the mat”. The model is trained to predict the original word “sat” in the sentence.</p>
<p>```vjbtdgma https://raw.githubusercontent.com/UKPLab/sentence-transformers/master/docs/img/MLM.png :name: bert_mlm :alt: BERT MLM :width: 80% :align: center</p>
<p>Masked Language Modeling (MLM). A token is randomly masked and the model is trained to predict the original word.</p>
<pre><code>
To generate training data for MLM, BERT randomly masks 15% of the tokens in each sequence. However, the masking process is not as straightforward as simply replacing words with [MASK] tokens. For the 15% of tokens chosen for masking:

- 80% of the time, replace the word with the [MASK] token
  - Example: "the cat sat on the mat" → "the cat [MASK] on the mat"

- 10% of the time, replace the word with a random word
  - Example: "the cat sat on the mat" → "the cat dog on the mat"

- 10% of the time, keep the word unchanged
  - Example: "the cat sat on the mat" → "the cat sat on the mat"

The model must predict the original token for all selected positions, regardless of whether they were masked, replaced, or left unchanged. This helps prevent the model from simply learning to detect replaced tokens.

During training, the model processes the modified input sequence through its transformer layers and predicts the original token at each masked position using the contextual representations.

```{tip}
While replacing words with random tokens or leaving them unchanged may seem counterintuitive, research has shown this approach is effective {footcite}`raffel2020exploring`. It has become an essential component of BERT's pre-training process.</code></pre>
</section>
<section id="next-sentence-prediction-nsp" class="level4">
<h4 class="anchored" data-anchor-id="next-sentence-prediction-nsp">Next Sentence Prediction (NSP)</h4>
<p>```vjbtdgma https://amitness.com/posts/images/bert-nsp.png :name: bert_nsp :alt: BERT NSP :width: 80% :align: center</p>
<p>Next Sentence Prediction (NSP). The model is trained to predict whether two sentences are consecutive or not.</p>
<pre><code>
Next Sentence Prediction (NSP) trains BERT to understand relationships between sentences. The model learns to predict whether two sentences naturally follow each other in text. During training, half of the sentence pairs are consecutive sentences from documents (labeled as IsNext), while the other half are random sentence pairs (labeled as NotNext).

The input format uses special tokens to structure the sentence pairs: a [CLS] token at the start, the first sentence, a [SEP] token, the second sentence, and a final [SEP] token. For instance:

$$
\text{``[CLS] }\underbrace{\text{I went to the store}}_{\text{Sentence 1}}\text{ [SEP] }\underbrace{\text{They were out of milk}}_{\text{Sentence 2}}\text{ [SEP]}".
$$

BERT uses the final hidden state of the [CLS] token to classify whether the sentences are consecutive or not. This helps the model develop a broader understanding of language context and relationships between sentences.

These two objectives help BERT learn the structure of language, such as the relationship between words and sentences.


## Fine-tuning

A powerful aspect of BERT is its ability to be fine-tuned on a wide range of tasks with minimal changes to the model architecture. This is achieved through transfer learning, where the pre-trained BERT model is used as a starting point for specific tasks.

Consider a hospital that wants to classify patient reviews. Due to privacy concerns, collecting enough data to train a deep learning model from scratch would be difficult. This is where BERT shines - since it's already pre-trained on vast amounts of text data and understands language structure, it can be fine-tuned effectively even with a small dataset of patient reviews. The pre-trained BERT model can be adapted to this specific classification task with only minor architectural changes.

```{tip}
:class: tip

You can find many fine-tuned and pre-trained models for various tasks by searching the [Hugging Face model hub](https://huggingface.co/models), with the keyword "BERT".</code></pre>
</section>
</section>
</section>
<section id="variants-and-improvements" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="variants-and-improvements"><span class="header-section-number">1.4</span> Variants and improvements</h2>
<p>**RoBERTa (Robustly Optimized BERT Approach)* {footcite}<code>liu2019roberta</code>* improved upon BERT through several optimizations: removing the Next Sentence Prediction task, using dynamic masking that changes the mask patterns across training epochs, training with larger batches, and using a larger dataset. These changes led to significant performance improvements while maintaining BERT’s core architecture.</p>
<p><strong>DistilBERT</strong> {footcite}<code>sanh2019distilbert</code> focused on making BERT more efficient through knowledge distillation, where a smaller student model learns from the larger BERT teacher model. It achieves 95% of BERT’s performance while being 40% smaller and 60% faster, making it more suitable for resource-constrained environments and real-world applications.</p>
<p><strong>ALBERT</strong> {footcite}<code>lan2019albert</code> introduced parameter reduction techniques to address BERT’s memory limitations. It uses factorized embedding parameterization and cross-layer parameter sharing to dramatically reduce parameters while maintaining performance. ALBERT also replaced Next Sentence Prediction with Sentence Order Prediction, where the model must determine if two consecutive sentences are in the correct order.</p>
<p>Domain-specific BERT models have been trained on specialized corpora to better handle specific fields. Examples include <strong>BioBERT</strong> {footcite}<code>lee2020biobert</code> for biomedical text, <strong>SciBERT</strong> {footcite}<code>reimers2019sentence</code> for scientific papers, and <strong>FinBERT</strong> {footcite}<code>araci2019finbert</code> for financial documents. These models demonstrate superior performance in their respective domains compared to the general-purpose BERT.</p>
<p><strong>Multilingual BERT (mBERT)</strong> {footcite}<code>liu2019roberta</code> was trained on Wikipedia data from 104 languages, using a shared vocabulary across all languages. Despite not having explicit cross-lingual objectives during training, mBERT shows remarkable zero-shot cross-lingual transfer abilities, allowing it to perform tasks in languages it wasn’t explicitly aligned on. This has made it a valuable resource for low-resource languages and cross-lingual applications.</p>
</section>
<section id="hands-on" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="hands-on"><span class="header-section-number">1.5</span> Hands on</h2>
<p>Let us load a pre-trained BERT model and see how it works using a sense disambiguation task. The sense disambiguation task is a task that involves identifying the correct sense of a word in a sentence. For example, given a sentence with word “apple”, we need to identify whether it refers to the fruit or the technology company.</p>
<p>Let us first load the necessary libraries.</p>
<p><code>aribilrqzll python import pandas as pd import numpy as np import sys import torch import transformers import matplotlib.pyplot as plt from tqdm import tqdm from sklearn.decomposition import PCA from bokeh.plotting import figure, show from bokeh.io import output_notebook from bokeh.models import ColumnDataSource, HoverTool</code></p>
<p>We will use <a href="https://github.com/danlou/bert-disambiguation/tree/master/data/CoarseWSD-20">CoarseWSD-20</a>. The dataset contains sentences with polysemous words and their sense labels. We will see how to use BERT to disambiguate the word senses. Read the <a href="https://github.com/danlou/bert-disambiguation/blob/master/data/CoarseWSD-20/README.txt">README</a> for more details.</p>
<p>```aribilrqzll python def load_data(focal_word, is_train, n_samples=100): data_type = “train” if is_train else “test” data_file = f”https://raw.githubusercontent.com/danlou/bert-disambiguation/master/data/CoarseWSD-20/{focal_word}/{data_type}.data.txt” label_file = f”https://raw.githubusercontent.com/danlou/bert-disambiguation/master/data/CoarseWSD-20/{focal_word}/{data_type}.gold.txt”</p>
<pre><code>data_table = pd.read_csv(
    data_file,
    sep="\t",
    header=None,
    dtype={"word_pos": int, "sentence": str},
    names=["word_pos", "sentence"],
)
label_table = pd.read_csv(
    label_file,
    sep="\t",
    header=None,
    dtype={"label": int},
    names=["label"],
)
combined_table = pd.concat([data_table, label_table], axis=1)
return combined_table.sample(n_samples)</code></pre>
<p>focal_word = “apple”</p>
<p>train_data = load_data(focal_word, is_train=True)</p>
<p>train_data.head(10)</p>
<pre><code>
We will use transformers library developed by Hugging Face to define the BERT model. To use the model, we will need:

- BERT tokenizer that converts the text into tokens.
- BERT model that computes the embeddings of the tokens.

We will use the bert-base-uncased model and tokenizer. Let's define the model and tokenizer.

```{code-cell} python
tokenizer = transformers.AutoTokenizer.from_pretrained("bert-base-uncased")
model = transformers.AutoModel.from_pretrained("bert-base-uncased")
model.eval() # set the model to evaluation mode
print(model) # Print the model architecture</code></pre>
<p>This prints the model architecture, which shows:</p>
<ol type="1">
<li>BertEmbeddings layer that converts tokens into embeddings using:
<ul>
<li>Word embeddings (30522 vocab size, 768 dimensions)</li>
<li>Position embeddings (512 positions, 768 dimensions)</li>
<li>Token type embeddings (2 types, 768 dimensions)</li>
<li>Layer normalization and dropout</li>
</ul></li>
<li>BertEncoder with 12 identical BertLayers, each containing:
<ul>
<li>Self-attention mechanism with query/key/value projections</li>
<li>Intermediate layer with GELU activation</li>
<li>Output layer with layer normalization</li>
</ul></li>
<li>BertPooler that processes the [CLS] token embedding with:
<ul>
<li>Dense layer (768 dimensions)</li>
<li>Tanh activation</li>
</ul></li>
</ol>
<p>All layers maintain the 768-dimensional hidden size, except the intermediate layer which expands to 3072 dimensions.</p>
<p>With BERT, we need to prepare text in ways that BERT can understand. Specifically, we prepend it with [CLS] and append [SEP]. We will then convert the text to a tensor of token ids, which is ready to be fed into the model.</p>
<p>```aribilrqzll python def prepare_text(text): text = “[CLS]” + text + ” [SEP]” tokenized_text = tokenizer.tokenize(text) indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)</p>
<pre><code>segments_ids = torch.ones((1, len(indexed_tokens)), dtype=torch.long)
tokens_tensor = torch.tensor([indexed_tokens])
segments_tensor = segments_ids.clone()
return tokenized_text, tokens_tensor, segments_tensor</code></pre>
<pre><code>
Let's get the BERT embeddings for the sentence "Bank is located in the city of London".

```{code-cell} python
text = "Bank is located in the city of London"
tokenized_text, tokens_tensor, segments_tensor = prepare_text(text)</code></pre>
<p>This produces the following output. <strong>Tokenized text</strong>: <code>aribilrqzll python print(tokenized_text)</code> <strong>Token IDs</strong>: <code>aribilrqzll python print(tokens_tensor)</code> <strong>Segment IDs</strong>: <code>aribilrqzll python print(segments_tensor)</code></p>
<p>Then, let’s get the BERT embeddings for each token.</p>
<p>```aribilrqzll python # Configure model to return hidden states model.config.output_hidden_states = True</p>
<p>outputs = model(tokens_tensor, segments_tensor)</p>
<pre><code>
The output includes `loss`, `logits`, and `hidden_states`. We will use `hidden_states`, which contains the embeddings of the tokens.

```{code-cell} python
hidden_states = outputs.hidden_states

print("how many layers? ", len(hidden_states))
print("Shape? ", hidden_states[0].shape)</code></pre>
<p>The hidden states are a list of 13 tensors, where each tensor is of shape (batch_size, sequence_length, hidden_size). The first tensor is the input embeddings, and the subsequent tensors are the hidden states of the BERT layers.</p>
<p>So, we have 13 choice of hidden states. Deep layers close to the output capture the context of the word from the previous layers.</p>
<p>Here we will take the average over the last four hidden states for each token.</p>
<p>```aribilrqzll python last_four_layers = hidden_states[-4:] # Stack the layers and then calculate mean stacked_layers = torch.stack(last_four_layers) emb = torch.mean(stacked_layers, dim=0)</p>
<p>print(emb.shape)</p>
<pre><code>emb is of shape (sequence_length, hidden_size). Let us summarize the embeddings of the tokens into a function.

```{code-cell} python
def get_bert_embeddings(text):
    tokenized_text, tokens_tensor, segments_tensor = prepare_text(text)
    outputs = model(tokens_tensor, segments_tensor)
    hidden_states = outputs[2]  # Access hidden states from tuple output
    # Stack the last 4 layers then take mean
    stacked_layers = torch.stack(hidden_states[-4:])
    emb = torch.mean(stacked_layers, dim=0)
    return emb, tokenized_text</code></pre>
<p>Now, let us embed text and get the embeddings of the focal token.</p>
<p>```aribilrqzll python labels = [] # label emb = [] # embedding sentences = [] # sentence</p>
<p>def get_focal_token_embedding(text, focal_word_idx): emb, tokenized_text = get_bert_embeddings(text) return emb[0][focal_word_idx] # Access first batch dimension</p>
<p>for index, row in train_data.iterrows(): text = row[“sentence”] focal_word_idx = row[“word_pos”] _emb = get_focal_token_embedding(text, focal_word_idx) labels.append(row[“label”]) emb.append(_emb) sentences.append(text)</p>
<pre><code>Finally, let us visualize the embeddings using PCA.

```{code-cell} python
:tags: [hide-input]

# Convert list of tensors to numpy array
emb_numpy = torch.stack(emb).detach().numpy()

pca = PCA(n_components=2, random_state=42)
xy = pca.fit_transform(emb_numpy)

output_notebook()

# Create data source for Bokeh
source = ColumnDataSource(data=dict(
    x=xy[:, 0],
    y=xy[:, 1],
    label=labels,
    sentence=sentences
))

# Create Bokeh figure
p = figure(title="Word Embeddings Visualization", x_axis_label="PCA 1", y_axis_label="PCA 2",
           width=700, height=500)

# Add hover tool
hover = HoverTool(tooltips=[
    ('Label', '@label'),
    ('Sentence', '@sentence')
])
p.add_tools(hover)

# Create color map for labels
import seaborn as sns

unique_labels = list(set(labels))
color_map = sns.color_palette().as_hex()[0:len(unique_labels)]
source.data['color'] = [color_map[label] for label in labels]

# Add scatter plot
p.scatter('x', 'y', size=12, line_color="DarkSlateGrey", line_width=2,
         fill_color='color', source=source)

show(p)</code></pre>
</section>
<section id="exercise" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="exercise"><span class="header-section-number">1.6</span> Exercise</h2>
<p>We have used the last 4 layers of BERT to generate the embeddings of the tokens. Now, let’s use the last <span class="math inline">k = 1, 2, 3</span> layers of BERT to generate the embeddings of the tokens. Then plot the embeddings using PCA.</p>
</section>
<section id="references" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="references"><span class="header-section-number">1.7</span> References</h2>
<pre class="{footbibliography}"><code>:style: unsrt</code></pre>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb14" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="an">jupytext:</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co">  formats: md:myst</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co">  text_representation:</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co">    extension: .md</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co">    format_name: myst</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="an">kernelspec:</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co">  display_name: Python 3</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co">  language: python</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co">  name: python3</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="fu"># Bidirectional Encoder Representations from Transformers (BERT)</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>We learned about ELMo's approach to the problem of polysemy using bidirectional LSTMs. BERT builds upon its bidirectional approach by using a self-attention mechanism in transformers.</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>BERT has become the leading transformer model for natural language processing tasks like question answering and text classification. Its effectiveness led Google to incorporate it into their search engine to improve query understanding. In this section, we will explore BERT's architecture and mechanisms.</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="in">```{figure} https://cdn.botpenguin.com/assets/website/BERT_c35709b509.webp</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="in">:name: bert_mlm</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a><span class="in">:alt: BERT MLM</span></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="in">:width: 50%</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a><span class="in">:align: center</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="in">```{admonition} BERT in interactive mode:</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a><span class="in">:class: tip</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a><span class="in">[Here is a demo notebook for BERT](https://static.marimo.app/static/bert-ux7g)</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a><span class="in">To run the notebook, download the notebook as a `.py` file and run it with:</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a><span class="in">&gt; marimo edit --sandbox bert.py</span></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a><span class="in">You will need to install `marimo` and `uv` to run the notebook. But other packages will be installed automatically in uv's virtual environment.</span></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a><span class="fu">## Architecture</span></span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>BERT consists of a stack of encoder transformer layers. Each layer is composed of a self-attention mechanism, a feed-forward neural network, and layer normalization, wired together with residual connections.</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>The output of each layer is fed into the next layer, and as we go through the layers, the token embeddings get more and more contextualized, reflecting the context more and more, thanks to the self-attention mechanism.</span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a><span class="in">```{figure} https://www.researchgate.net/publication/372906672/figure/fig2/AS:11431281179224913@1691164535766/BERT-model-architecture.ppm</span></span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a><span class="in">:name: bert_architecture</span></span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a><span class="in">:alt: BERT architecture</span></span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a><span class="in">:width: 80%</span></span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a><span class="in">:align: center</span></span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a><span class="in">BERT consists of a stack of encoder transformer layers. The position embeddings are added to the token embeddings to provide the model with information about the position of the tokens in the sequence.</span></span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a><span class="in">```{admonition} Which layer of BERT should we use?</span></span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a><span class="in">:class: tip</span></span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a><span class="in">BERT internally generates multiple hierarchical representations of the input sentence. The higher layers of the model capture more abstract and context-sensitive information, while the lower layers capture more local and surface-level information. Which layer to use depends on the task. For example, if we want to do text classification, we should use the output of the last layer. If we are interested in word-level representations, we should use the output of the first layer.</span></span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a><span class="fu">## Special tokens</span></span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a>BERT uses several special tokens to represent the input sentence.</span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">CLS</span><span class="co">]</span> is used to represent the start of the sentence.</span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">SEP</span><span class="co">]</span> is used to represent the end of the sentence.</span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">MASK</span><span class="co">]</span> is used to represent the masked words.</span>
<span id="cb14-66"><a href="#cb14-66" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">UNK</span><span class="co">]</span> is used to represent the unknown words.</span>
<span id="cb14-67"><a href="#cb14-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-68"><a href="#cb14-68" aria-hidden="true" tabindex="-1"></a>For example, the sentence "The cat sat on the mat. It then went to sleep." is represented as "<span class="co">[</span><span class="ot">CLS</span><span class="co">]</span> The cat sat on the mat <span class="co">[</span><span class="ot">SEP</span><span class="co">]</span> It then went to sleep <span class="co">[</span><span class="ot">SEP</span><span class="co">]</span>".</span>
<span id="cb14-69"><a href="#cb14-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-70"><a href="#cb14-70" aria-hidden="true" tabindex="-1"></a>In BERT, <span class="co">[</span><span class="ot">CLS</span><span class="co">]</span> token is used to classify the input sentences, as we will see later. As a result, the model learns to encode a summary of the input sentence into the <span class="co">[</span><span class="ot">CLS</span><span class="co">]</span> token, which is particularly useful when we want the embedding of the whole input text, instead of the token level embeddings. {footcite}<span class="in">`reimers2019sentence`</span></span>
<span id="cb14-71"><a href="#cb14-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-72"><a href="#cb14-72" aria-hidden="true" tabindex="-1"></a><span class="fu">## Position and Segment embeddings</span></span>
<span id="cb14-73"><a href="#cb14-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-74"><a href="#cb14-74" aria-hidden="true" tabindex="-1"></a>BERT uses *position* and *segment* embeddings to provide the model with information about the position of the tokens in the sequence.</span>
<span id="cb14-75"><a href="#cb14-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-76"><a href="#cb14-76" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Position embeddings are used to provide the model with information about the position of the tokens in the sequence. Unlike the sinusoidal position embedding used in the original transformer paper {footcite}<span class="in">`vaswani2017attention`</span>, BERT uses learnable position embeddings.</span>
<span id="cb14-77"><a href="#cb14-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-78"><a href="#cb14-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-79"><a href="#cb14-79" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The segment embeddings are used to distinguish the sentences in the input. For example, for the sentence "The cat sat on the mat. It then went to sleep.", the tokens in the first sentence are added with segment embedding 0, and the tokens in the second sentence are added with segment embedding 1. These segmend embeddings are also learned during the pre-training process.</span>
<span id="cb14-80"><a href="#cb14-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-81"><a href="#cb14-81" aria-hidden="true" tabindex="-1"></a><span class="in">```{figure} https://lh3.googleusercontent.com/stK9CWIWiSuF_aq75q7_6wUqyqfePKzeLxqVet9IVNqrcyJqqg9hXkhuFXBXXbIjaGY15gSF9Yr7kyjceVXs5HbDMpmkhet49fhbtLsm9-4E4iCYckzGTsYSxOqRaVGNTkkhWykg</span></span>
<span id="cb14-82"><a href="#cb14-82" aria-hidden="true" tabindex="-1"></a><span class="in">:name: bert_position_segment_embeddings</span></span>
<span id="cb14-83"><a href="#cb14-83" aria-hidden="true" tabindex="-1"></a><span class="in">:alt: BERT position and segment embeddings</span></span>
<span id="cb14-84"><a href="#cb14-84" aria-hidden="true" tabindex="-1"></a><span class="in">:width: 80%</span></span>
<span id="cb14-85"><a href="#cb14-85" aria-hidden="true" tabindex="-1"></a><span class="in">:align: center</span></span>
<span id="cb14-86"><a href="#cb14-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-87"><a href="#cb14-87" aria-hidden="true" tabindex="-1"></a><span class="in">Position and segment embeddings in BERT. Position embeddings, which are learnable, are added to the token embeddings. Segment embeddings indicate the sentence that the token belongs to (e.g., $E_A$ and $E_B$).</span></span>
<span id="cb14-88"><a href="#cb14-88" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-89"><a href="#cb14-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-92"><a href="#cb14-92" aria-hidden="true" tabindex="-1"></a><span class="in">```{tip}</span></span>
<span id="cb14-93"><a href="#cb14-93" aria-hidden="true" tabindex="-1"></a><span class="in">:class: tip</span></span>
<span id="cb14-94"><a href="#cb14-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-95"><a href="#cb14-95" aria-hidden="true" tabindex="-1"></a><span class="in">Position embeddings can be either absolute or relative:</span></span>
<span id="cb14-96"><a href="#cb14-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-97"><a href="#cb14-97" aria-hidden="true" tabindex="-1"></a><span class="in">Absolute position embeddings (like in BERT) directly encode the position of each token as a fixed index (1st, 2nd, 3rd position etc). Each position gets its own unique embedding vector that is learned during training.</span></span>
<span id="cb14-98"><a href="#cb14-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-99"><a href="#cb14-99" aria-hidden="true" tabindex="-1"></a><span class="in">Relative position embeddings (like sinusoidal embeddings in the original Transformer) encode the relative distance between tokens rather than their absolute positions. For example, they can encode that token A is 2 positions away from token B, regardless of their absolute positions in the sequence. This makes them more flexible for handling sequences of varying lengths.</span></span>
<span id="cb14-100"><a href="#cb14-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-101"><a href="#cb14-101" aria-hidden="true" tabindex="-1"></a><span class="in">For interested readers, you can read more about the difference between absolute and relative position embeddings in [The Use Case for Relative Position Embeddings – Ofir Press](https://ofir.io/The-Use-Case-for-Relative-Position-Embeddings/) and [Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation](https://arxiv.org/abs/2108.12409).</span></span>
<span id="cb14-102"><a href="#cb14-102" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-103"><a href="#cb14-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-104"><a href="#cb14-104" aria-hidden="true" tabindex="-1"></a><span class="fu">### Pre-training</span></span>
<span id="cb14-105"><a href="#cb14-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-106"><a href="#cb14-106" aria-hidden="true" tabindex="-1"></a>A key aspect of BERT is its pre-training process, which involves two main objectives:</span>
<span id="cb14-107"><a href="#cb14-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-108"><a href="#cb14-108" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Masked Language Modeling (MLM)</span>
<span id="cb14-109"><a href="#cb14-109" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Next Sentence Prediction (NSP)</span>
<span id="cb14-110"><a href="#cb14-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-111"><a href="#cb14-111" aria-hidden="true" tabindex="-1"></a>Both objectives are designed to learn the language structure, such as the relationship between words and sentences.</span>
<span id="cb14-112"><a href="#cb14-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-113"><a href="#cb14-113" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Masked Language Modeling (MLM)</span></span>
<span id="cb14-114"><a href="#cb14-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-115"><a href="#cb14-115" aria-hidden="true" tabindex="-1"></a>In MLM, the model is trained to predict the original words that are masked in the input sentence. The masked words are replaced with a special token, <span class="co">[</span><span class="ot">MASK</span><span class="co">]</span>, and the model is trained to predict the original words. For example, the sentence "The cat <span class="co">[</span><span class="ot">MASK</span><span class="co">]</span> on the mat" is transformed into "The cat <span class="co">[</span><span class="ot">MASK</span><span class="co">]</span> on the mat". The model is trained to predict the original word "sat" in the sentence.</span>
<span id="cb14-116"><a href="#cb14-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-117"><a href="#cb14-117" aria-hidden="true" tabindex="-1"></a><span class="in">```{figure} https://raw.githubusercontent.com/UKPLab/sentence-transformers/master/docs/img/MLM.png</span></span>
<span id="cb14-118"><a href="#cb14-118" aria-hidden="true" tabindex="-1"></a><span class="in">:name: bert_mlm</span></span>
<span id="cb14-119"><a href="#cb14-119" aria-hidden="true" tabindex="-1"></a><span class="in">:alt: BERT MLM</span></span>
<span id="cb14-120"><a href="#cb14-120" aria-hidden="true" tabindex="-1"></a><span class="in">:width: 80%</span></span>
<span id="cb14-121"><a href="#cb14-121" aria-hidden="true" tabindex="-1"></a><span class="in">:align: center</span></span>
<span id="cb14-122"><a href="#cb14-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-123"><a href="#cb14-123" aria-hidden="true" tabindex="-1"></a><span class="in">Masked Language Modeling (MLM). A token is randomly masked and the model is trained to predict the original word.</span></span>
<span id="cb14-124"><a href="#cb14-124" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-125"><a href="#cb14-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-126"><a href="#cb14-126" aria-hidden="true" tabindex="-1"></a>To generate training data for MLM, BERT randomly masks 15% of the tokens in each sequence. However, the masking process is not as straightforward as simply replacing words with <span class="co">[</span><span class="ot">MASK</span><span class="co">]</span> tokens. For the 15% of tokens chosen for masking:</span>
<span id="cb14-127"><a href="#cb14-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-128"><a href="#cb14-128" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>80% of the time, replace the word with the <span class="co">[</span><span class="ot">MASK</span><span class="co">]</span> token</span>
<span id="cb14-129"><a href="#cb14-129" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Example: "the cat sat on the mat" → "the cat <span class="co">[</span><span class="ot">MASK</span><span class="co">]</span> on the mat"</span>
<span id="cb14-130"><a href="#cb14-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-131"><a href="#cb14-131" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>10% of the time, replace the word with a random word</span>
<span id="cb14-132"><a href="#cb14-132" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Example: "the cat sat on the mat" → "the cat dog on the mat"</span>
<span id="cb14-133"><a href="#cb14-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-134"><a href="#cb14-134" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>10% of the time, keep the word unchanged</span>
<span id="cb14-135"><a href="#cb14-135" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Example: "the cat sat on the mat" → "the cat sat on the mat"</span>
<span id="cb14-136"><a href="#cb14-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-137"><a href="#cb14-137" aria-hidden="true" tabindex="-1"></a>The model must predict the original token for all selected positions, regardless of whether they were masked, replaced, or left unchanged. This helps prevent the model from simply learning to detect replaced tokens.</span>
<span id="cb14-138"><a href="#cb14-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-139"><a href="#cb14-139" aria-hidden="true" tabindex="-1"></a>During training, the model processes the modified input sequence through its transformer layers and predicts the original token at each masked position using the contextual representations.</span>
<span id="cb14-140"><a href="#cb14-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-143"><a href="#cb14-143" aria-hidden="true" tabindex="-1"></a><span class="in">```{tip}</span></span>
<span id="cb14-144"><a href="#cb14-144" aria-hidden="true" tabindex="-1"></a><span class="in">While replacing words with random tokens or leaving them unchanged may seem counterintuitive, research has shown this approach is effective {footcite}`raffel2020exploring`. It has become an essential component of BERT's pre-training process.</span></span>
<span id="cb14-145"><a href="#cb14-145" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-146"><a href="#cb14-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-147"><a href="#cb14-147" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Next Sentence Prediction (NSP)</span></span>
<span id="cb14-148"><a href="#cb14-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-149"><a href="#cb14-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-150"><a href="#cb14-150" aria-hidden="true" tabindex="-1"></a><span class="in">```{figure} https://amitness.com/posts/images/bert-nsp.png</span></span>
<span id="cb14-151"><a href="#cb14-151" aria-hidden="true" tabindex="-1"></a><span class="in">:name: bert_nsp</span></span>
<span id="cb14-152"><a href="#cb14-152" aria-hidden="true" tabindex="-1"></a><span class="in">:alt: BERT NSP</span></span>
<span id="cb14-153"><a href="#cb14-153" aria-hidden="true" tabindex="-1"></a><span class="in">:width: 80%</span></span>
<span id="cb14-154"><a href="#cb14-154" aria-hidden="true" tabindex="-1"></a><span class="in">:align: center</span></span>
<span id="cb14-155"><a href="#cb14-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-156"><a href="#cb14-156" aria-hidden="true" tabindex="-1"></a><span class="in">Next Sentence Prediction (NSP). The model is trained to predict whether two sentences are consecutive or not.</span></span>
<span id="cb14-157"><a href="#cb14-157" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-158"><a href="#cb14-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-159"><a href="#cb14-159" aria-hidden="true" tabindex="-1"></a>Next Sentence Prediction (NSP) trains BERT to understand relationships between sentences. The model learns to predict whether two sentences naturally follow each other in text. During training, half of the sentence pairs are consecutive sentences from documents (labeled as IsNext), while the other half are random sentence pairs (labeled as NotNext).</span>
<span id="cb14-160"><a href="#cb14-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-161"><a href="#cb14-161" aria-hidden="true" tabindex="-1"></a>The input format uses special tokens to structure the sentence pairs: a <span class="co">[</span><span class="ot">CLS</span><span class="co">]</span> token at the start, the first sentence, a <span class="co">[</span><span class="ot">SEP</span><span class="co">]</span> token, the second sentence, and a final <span class="co">[</span><span class="ot">SEP</span><span class="co">]</span> token. For instance:</span>
<span id="cb14-162"><a href="#cb14-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-163"><a href="#cb14-163" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-164"><a href="#cb14-164" aria-hidden="true" tabindex="-1"></a>\text{``<span class="co">[</span><span class="ot">CLS</span><span class="co">]</span> }\underbrace{\text{I went to the store}}_{\text{Sentence 1}}\text{ [SEP] }\underbrace{\text{They were out of milk}}_{\text{Sentence 2}}\text{ <span class="co">[</span><span class="ot">SEP</span><span class="co">]</span>}".</span>
<span id="cb14-165"><a href="#cb14-165" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-166"><a href="#cb14-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-167"><a href="#cb14-167" aria-hidden="true" tabindex="-1"></a>BERT uses the final hidden state of the <span class="co">[</span><span class="ot">CLS</span><span class="co">]</span> token to classify whether the sentences are consecutive or not. This helps the model develop a broader understanding of language context and relationships between sentences.</span>
<span id="cb14-168"><a href="#cb14-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-169"><a href="#cb14-169" aria-hidden="true" tabindex="-1"></a>These two objectives help BERT learn the structure of language, such as the relationship between words and sentences.</span>
<span id="cb14-170"><a href="#cb14-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-171"><a href="#cb14-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-172"><a href="#cb14-172" aria-hidden="true" tabindex="-1"></a><span class="fu">## Fine-tuning</span></span>
<span id="cb14-173"><a href="#cb14-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-174"><a href="#cb14-174" aria-hidden="true" tabindex="-1"></a>A powerful aspect of BERT is its ability to be fine-tuned on a wide range of tasks with minimal changes to the model architecture. This is achieved through transfer learning, where the pre-trained BERT model is used as a starting point for specific tasks.</span>
<span id="cb14-175"><a href="#cb14-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-176"><a href="#cb14-176" aria-hidden="true" tabindex="-1"></a>Consider a hospital that wants to classify patient reviews. Due to privacy concerns, collecting enough data to train a deep learning model from scratch would be difficult. This is where BERT shines - since it's already pre-trained on vast amounts of text data and understands language structure, it can be fine-tuned effectively even with a small dataset of patient reviews. The pre-trained BERT model can be adapted to this specific classification task with only minor architectural changes.</span>
<span id="cb14-177"><a href="#cb14-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-180"><a href="#cb14-180" aria-hidden="true" tabindex="-1"></a><span class="in">```{tip}</span></span>
<span id="cb14-181"><a href="#cb14-181" aria-hidden="true" tabindex="-1"></a><span class="in">:class: tip</span></span>
<span id="cb14-182"><a href="#cb14-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-183"><a href="#cb14-183" aria-hidden="true" tabindex="-1"></a><span class="in">You can find many fine-tuned and pre-trained models for various tasks by searching the [Hugging Face model hub](https://huggingface.co/models), with the keyword "BERT".</span></span>
<span id="cb14-184"><a href="#cb14-184" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-185"><a href="#cb14-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-186"><a href="#cb14-186" aria-hidden="true" tabindex="-1"></a><span class="fu">## Variants and improvements</span></span>
<span id="cb14-187"><a href="#cb14-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-188"><a href="#cb14-188" aria-hidden="true" tabindex="-1"></a>**RoBERTa (Robustly Optimized BERT Approach)* {footcite}`liu2019roberta`* improved upon BERT through several optimizations: removing the Next Sentence Prediction task, using dynamic masking that changes the mask patterns across training epochs, training with larger batches, and using a larger dataset. These changes led to significant performance improvements while maintaining BERT's core architecture.</span>
<span id="cb14-189"><a href="#cb14-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-190"><a href="#cb14-190" aria-hidden="true" tabindex="-1"></a>**DistilBERT** {footcite}<span class="in">`sanh2019distilbert`</span> focused on making BERT more efficient through knowledge distillation, where a smaller student model learns from the larger BERT teacher model. It achieves 95% of BERT's performance while being 40% smaller and 60% faster, making it more suitable for resource-constrained environments and real-world applications.</span>
<span id="cb14-191"><a href="#cb14-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-192"><a href="#cb14-192" aria-hidden="true" tabindex="-1"></a>**ALBERT** {footcite}<span class="in">`lan2019albert`</span> introduced parameter reduction techniques to address BERT's memory limitations. It uses factorized embedding parameterization and cross-layer parameter sharing to dramatically reduce parameters while maintaining performance. ALBERT also replaced Next Sentence Prediction with Sentence Order Prediction, where the model must determine if two consecutive sentences are in the correct order.</span>
<span id="cb14-193"><a href="#cb14-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-194"><a href="#cb14-194" aria-hidden="true" tabindex="-1"></a>Domain-specific BERT models have been trained on specialized corpora to better handle specific fields. Examples include **BioBERT** {footcite}`lee2020biobert` for biomedical text, **SciBERT** {footcite}`reimers2019sentence` for scientific papers, and **FinBERT** {footcite}<span class="in">`araci2019finbert`</span> for financial documents. These models demonstrate superior performance in their respective domains compared to the general-purpose BERT.</span>
<span id="cb14-195"><a href="#cb14-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-196"><a href="#cb14-196" aria-hidden="true" tabindex="-1"></a>**Multilingual BERT (mBERT)** {footcite}<span class="in">`liu2019roberta`</span> was trained on Wikipedia data from 104 languages, using a shared vocabulary across all languages. Despite not having explicit cross-lingual objectives during training, mBERT shows remarkable zero-shot cross-lingual transfer abilities, allowing it to perform tasks in languages it wasn't explicitly aligned on. This has made it a valuable resource for low-resource languages and cross-lingual applications.</span>
<span id="cb14-197"><a href="#cb14-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-198"><a href="#cb14-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-199"><a href="#cb14-199" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hands on</span></span>
<span id="cb14-200"><a href="#cb14-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-201"><a href="#cb14-201" aria-hidden="true" tabindex="-1"></a>Let us load a pre-trained BERT model and see how it works using a sense disambiguation task. The sense disambiguation task is a task that involves identifying the correct sense of a word in a sentence. For example, given a sentence with word "apple", we need to identify whether it refers to the fruit or the technology company.</span>
<span id="cb14-202"><a href="#cb14-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-203"><a href="#cb14-203" aria-hidden="true" tabindex="-1"></a>Let us first load the necessary libraries.</span>
<span id="cb14-204"><a href="#cb14-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-205"><a href="#cb14-205" aria-hidden="true" tabindex="-1"></a><span class="in">```{code-cell} python</span></span>
<span id="cb14-206"><a href="#cb14-206" aria-hidden="true" tabindex="-1"></a>import pandas as pd</span>
<span id="cb14-207"><a href="#cb14-207" aria-hidden="true" tabindex="-1"></a>import numpy as np</span>
<span id="cb14-208"><a href="#cb14-208" aria-hidden="true" tabindex="-1"></a>import sys</span>
<span id="cb14-209"><a href="#cb14-209" aria-hidden="true" tabindex="-1"></a>import torch</span>
<span id="cb14-210"><a href="#cb14-210" aria-hidden="true" tabindex="-1"></a>import transformers</span>
<span id="cb14-211"><a href="#cb14-211" aria-hidden="true" tabindex="-1"></a>import matplotlib<span class="op">.</span>pyplot as plt</span>
<span id="cb14-212"><a href="#cb14-212" aria-hidden="true" tabindex="-1"></a>from tqdm import tqdm</span>
<span id="cb14-213"><a href="#cb14-213" aria-hidden="true" tabindex="-1"></a>from sklearn<span class="op">.</span>decomposition import PCA</span>
<span id="cb14-214"><a href="#cb14-214" aria-hidden="true" tabindex="-1"></a>from bokeh<span class="op">.</span>plotting import figure<span class="op">,</span> show</span>
<span id="cb14-215"><a href="#cb14-215" aria-hidden="true" tabindex="-1"></a>from bokeh<span class="op">.</span>io import output_notebook</span>
<span id="cb14-216"><a href="#cb14-216" aria-hidden="true" tabindex="-1"></a>from bokeh<span class="op">.</span>models import ColumnDataSource<span class="op">,</span> HoverTool</span>
<span id="cb14-217"><a href="#cb14-217" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-218"><a href="#cb14-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-219"><a href="#cb14-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-220"><a href="#cb14-220" aria-hidden="true" tabindex="-1"></a>We will use <span class="co">[</span><span class="ot">CoarseWSD-20</span><span class="co">](https://github.com/danlou/bert-disambiguation/tree/master/data/CoarseWSD-20)</span>. The dataset contains sentences with polysemous words and their sense labels. We will see how to use BERT to disambiguate the word senses. Read the <span class="co">[</span><span class="ot">README</span><span class="co">](https://github.com/danlou/bert-disambiguation/blob/master/data/CoarseWSD-20/README.txt)</span> for more details.</span>
<span id="cb14-221"><a href="#cb14-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-222"><a href="#cb14-222" aria-hidden="true" tabindex="-1"></a><span class="in">```{code-cell} python</span></span>
<span id="cb14-223"><a href="#cb14-223" aria-hidden="true" tabindex="-1"></a>def load_data<span class="op">(</span>focal_word<span class="op">,</span> is_train<span class="op">,</span> n_samples<span class="op">=</span><span class="dv">100</span><span class="op">):</span></span>
<span id="cb14-224"><a href="#cb14-224" aria-hidden="true" tabindex="-1"></a>    data_type <span class="op">=</span> <span class="st">"train"</span> <span class="cf">if</span> is_train <span class="cf">else</span> <span class="st">"test"</span></span>
<span id="cb14-225"><a href="#cb14-225" aria-hidden="true" tabindex="-1"></a>    data_file <span class="op">=</span> f<span class="st">"https://raw.githubusercontent.com/danlou/bert-disambiguation/master/data/CoarseWSD-20/{focal_word}/{data_type}.data.txt"</span></span>
<span id="cb14-226"><a href="#cb14-226" aria-hidden="true" tabindex="-1"></a>    label_file <span class="op">=</span> f<span class="st">"https://raw.githubusercontent.com/danlou/bert-disambiguation/master/data/CoarseWSD-20/{focal_word}/{data_type}.gold.txt"</span></span>
<span id="cb14-227"><a href="#cb14-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-228"><a href="#cb14-228" aria-hidden="true" tabindex="-1"></a>    data_table <span class="op">=</span> pd<span class="op">.</span>read_csv<span class="op">(</span></span>
<span id="cb14-229"><a href="#cb14-229" aria-hidden="true" tabindex="-1"></a>        data_file<span class="op">,</span></span>
<span id="cb14-230"><a href="#cb14-230" aria-hidden="true" tabindex="-1"></a>        sep<span class="op">=</span><span class="st">"</span><span class="sc">\t</span><span class="st">"</span><span class="op">,</span></span>
<span id="cb14-231"><a href="#cb14-231" aria-hidden="true" tabindex="-1"></a>        header<span class="op">=</span>None<span class="op">,</span></span>
<span id="cb14-232"><a href="#cb14-232" aria-hidden="true" tabindex="-1"></a>        dtype<span class="op">={</span><span class="st">"word_pos"</span><span class="op">:</span> <span class="dt">int</span><span class="op">,</span> <span class="st">"sentence"</span><span class="op">:</span> str<span class="op">},</span></span>
<span id="cb14-233"><a href="#cb14-233" aria-hidden="true" tabindex="-1"></a>        names<span class="op">=[</span><span class="st">"word_pos"</span><span class="op">,</span> <span class="st">"sentence"</span><span class="op">],</span></span>
<span id="cb14-234"><a href="#cb14-234" aria-hidden="true" tabindex="-1"></a>    <span class="op">)</span></span>
<span id="cb14-235"><a href="#cb14-235" aria-hidden="true" tabindex="-1"></a>    label_table <span class="op">=</span> pd<span class="op">.</span>read_csv<span class="op">(</span></span>
<span id="cb14-236"><a href="#cb14-236" aria-hidden="true" tabindex="-1"></a>        label_file<span class="op">,</span></span>
<span id="cb14-237"><a href="#cb14-237" aria-hidden="true" tabindex="-1"></a>        sep<span class="op">=</span><span class="st">"</span><span class="sc">\t</span><span class="st">"</span><span class="op">,</span></span>
<span id="cb14-238"><a href="#cb14-238" aria-hidden="true" tabindex="-1"></a>        header<span class="op">=</span>None<span class="op">,</span></span>
<span id="cb14-239"><a href="#cb14-239" aria-hidden="true" tabindex="-1"></a>        dtype<span class="op">={</span><span class="st">"label"</span><span class="op">:</span> <span class="dt">int</span><span class="op">},</span></span>
<span id="cb14-240"><a href="#cb14-240" aria-hidden="true" tabindex="-1"></a>        names<span class="op">=[</span><span class="st">"label"</span><span class="op">],</span></span>
<span id="cb14-241"><a href="#cb14-241" aria-hidden="true" tabindex="-1"></a>    <span class="op">)</span></span>
<span id="cb14-242"><a href="#cb14-242" aria-hidden="true" tabindex="-1"></a>    combined_table <span class="op">=</span> pd<span class="op">.</span>concat<span class="op">([</span>data_table<span class="op">,</span> label_table<span class="op">],</span> axis<span class="op">=</span><span class="dv">1</span><span class="op">)</span></span>
<span id="cb14-243"><a href="#cb14-243" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> combined_table<span class="op">.</span>sample<span class="op">(</span>n_samples<span class="op">)</span></span>
<span id="cb14-244"><a href="#cb14-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-245"><a href="#cb14-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-246"><a href="#cb14-246" aria-hidden="true" tabindex="-1"></a>focal_word <span class="op">=</span> <span class="st">"apple"</span></span>
<span id="cb14-247"><a href="#cb14-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-248"><a href="#cb14-248" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> load_data<span class="op">(</span>focal_word<span class="op">,</span> is_train<span class="op">=</span>True<span class="op">)</span></span>
<span id="cb14-249"><a href="#cb14-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-250"><a href="#cb14-250" aria-hidden="true" tabindex="-1"></a>train_data<span class="op">.</span>head<span class="op">(</span><span class="dv">10</span><span class="op">)</span></span>
<span id="cb14-251"><a href="#cb14-251" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-252"><a href="#cb14-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-253"><a href="#cb14-253" aria-hidden="true" tabindex="-1"></a>We will use transformers library developed by Hugging Face to define the BERT model. To use the model, we will need:</span>
<span id="cb14-254"><a href="#cb14-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-255"><a href="#cb14-255" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>BERT tokenizer that converts the text into tokens.</span>
<span id="cb14-256"><a href="#cb14-256" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>BERT model that computes the embeddings of the tokens.</span>
<span id="cb14-257"><a href="#cb14-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-258"><a href="#cb14-258" aria-hidden="true" tabindex="-1"></a>We will use the bert-base-uncased model and tokenizer. Let's define the model and tokenizer.</span>
<span id="cb14-259"><a href="#cb14-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-260"><a href="#cb14-260" aria-hidden="true" tabindex="-1"></a><span class="in">```{code-cell} python</span></span>
<span id="cb14-261"><a href="#cb14-261" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> transformers<span class="op">.</span>AutoTokenizer<span class="op">.</span>from_pretrained<span class="op">(</span><span class="st">"bert-base-uncased"</span><span class="op">)</span></span>
<span id="cb14-262"><a href="#cb14-262" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> transformers<span class="op">.</span>AutoModel<span class="op">.</span>from_pretrained<span class="op">(</span><span class="st">"bert-base-uncased"</span><span class="op">)</span></span>
<span id="cb14-263"><a href="#cb14-263" aria-hidden="true" tabindex="-1"></a>model<span class="op">.</span>eval<span class="op">()</span> # set the model to evaluation mode</span>
<span id="cb14-264"><a href="#cb14-264" aria-hidden="true" tabindex="-1"></a>print<span class="op">(</span>model<span class="op">)</span> # Print the model architecture</span>
<span id="cb14-265"><a href="#cb14-265" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-266"><a href="#cb14-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-267"><a href="#cb14-267" aria-hidden="true" tabindex="-1"></a>This prints the model architecture, which shows:</span>
<span id="cb14-268"><a href="#cb14-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-269"><a href="#cb14-269" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>BertEmbeddings layer that converts tokens into embeddings using:</span>
<span id="cb14-270"><a href="#cb14-270" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Word embeddings (30522 vocab size, 768 dimensions)</span>
<span id="cb14-271"><a href="#cb14-271" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Position embeddings (512 positions, 768 dimensions)</span>
<span id="cb14-272"><a href="#cb14-272" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Token type embeddings (2 types, 768 dimensions)</span>
<span id="cb14-273"><a href="#cb14-273" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Layer normalization and dropout</span>
<span id="cb14-274"><a href="#cb14-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-275"><a href="#cb14-275" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>BertEncoder with 12 identical BertLayers, each containing:</span>
<span id="cb14-276"><a href="#cb14-276" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Self-attention mechanism with query/key/value projections</span>
<span id="cb14-277"><a href="#cb14-277" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Intermediate layer with GELU activation</span>
<span id="cb14-278"><a href="#cb14-278" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Output layer with layer normalization</span>
<span id="cb14-279"><a href="#cb14-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-280"><a href="#cb14-280" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>BertPooler that processes the <span class="co">[</span><span class="ot">CLS</span><span class="co">]</span> token embedding with:</span>
<span id="cb14-281"><a href="#cb14-281" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Dense layer (768 dimensions)</span>
<span id="cb14-282"><a href="#cb14-282" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Tanh activation</span>
<span id="cb14-283"><a href="#cb14-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-284"><a href="#cb14-284" aria-hidden="true" tabindex="-1"></a>All layers maintain the 768-dimensional hidden size, except the intermediate layer which expands to 3072 dimensions.</span>
<span id="cb14-285"><a href="#cb14-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-286"><a href="#cb14-286" aria-hidden="true" tabindex="-1"></a>With BERT, we need to prepare text in ways that BERT can understand. Specifically, we prepend it with <span class="co">[</span><span class="ot">CLS</span><span class="co">]</span> and append <span class="co">[</span><span class="ot">SEP</span><span class="co">]</span>. We will then convert the text to a tensor of token ids, which is ready to be fed into the model.</span>
<span id="cb14-287"><a href="#cb14-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-288"><a href="#cb14-288" aria-hidden="true" tabindex="-1"></a><span class="in">```{code-cell} python</span></span>
<span id="cb14-289"><a href="#cb14-289" aria-hidden="true" tabindex="-1"></a>def prepare_text<span class="op">(</span>text<span class="op">):</span></span>
<span id="cb14-290"><a href="#cb14-290" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> <span class="st">"[CLS] "</span> <span class="op">+</span> text <span class="op">+</span> <span class="st">" [SEP]"</span></span>
<span id="cb14-291"><a href="#cb14-291" aria-hidden="true" tabindex="-1"></a>    tokenized_text <span class="op">=</span> tokenizer<span class="op">.</span>tokenize<span class="op">(</span>text<span class="op">)</span></span>
<span id="cb14-292"><a href="#cb14-292" aria-hidden="true" tabindex="-1"></a>    indexed_tokens <span class="op">=</span> tokenizer<span class="op">.</span>convert_tokens_to_ids<span class="op">(</span>tokenized_text<span class="op">)</span></span>
<span id="cb14-293"><a href="#cb14-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-294"><a href="#cb14-294" aria-hidden="true" tabindex="-1"></a>    segments_ids <span class="op">=</span> torch<span class="op">.</span>ones<span class="op">((</span><span class="dv">1</span><span class="op">,</span> len<span class="op">(</span>indexed_tokens<span class="op">)),</span> dtype<span class="op">=</span>torch<span class="op">.</span><span class="dt">long</span><span class="op">)</span></span>
<span id="cb14-295"><a href="#cb14-295" aria-hidden="true" tabindex="-1"></a>    tokens_tensor <span class="op">=</span> torch<span class="op">.</span>tensor<span class="op">([</span>indexed_tokens<span class="op">])</span></span>
<span id="cb14-296"><a href="#cb14-296" aria-hidden="true" tabindex="-1"></a>    segments_tensor <span class="op">=</span> segments_ids<span class="op">.</span>clone<span class="op">()</span></span>
<span id="cb14-297"><a href="#cb14-297" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenized_text<span class="op">,</span> tokens_tensor<span class="op">,</span> segments_tensor</span>
<span id="cb14-298"><a href="#cb14-298" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-299"><a href="#cb14-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-300"><a href="#cb14-300" aria-hidden="true" tabindex="-1"></a>Let's get the BERT embeddings for the sentence "Bank is located in the city of London".</span>
<span id="cb14-301"><a href="#cb14-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-302"><a href="#cb14-302" aria-hidden="true" tabindex="-1"></a><span class="in">```{code-cell} python</span></span>
<span id="cb14-303"><a href="#cb14-303" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"Bank is located in the city of London"</span></span>
<span id="cb14-304"><a href="#cb14-304" aria-hidden="true" tabindex="-1"></a>tokenized_text<span class="op">,</span> tokens_tensor<span class="op">,</span> segments_tensor <span class="op">=</span> prepare_text<span class="op">(</span>text<span class="op">)</span></span>
<span id="cb14-305"><a href="#cb14-305" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-306"><a href="#cb14-306" aria-hidden="true" tabindex="-1"></a>This produces the following output.</span>
<span id="cb14-307"><a href="#cb14-307" aria-hidden="true" tabindex="-1"></a>**Tokenized text**:</span>
<span id="cb14-308"><a href="#cb14-308" aria-hidden="true" tabindex="-1"></a><span class="in">```{code-cell} python</span></span>
<span id="cb14-309"><a href="#cb14-309" aria-hidden="true" tabindex="-1"></a>print<span class="op">(</span>tokenized_text<span class="op">)</span></span>
<span id="cb14-310"><a href="#cb14-310" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-311"><a href="#cb14-311" aria-hidden="true" tabindex="-1"></a>**Token IDs**:</span>
<span id="cb14-312"><a href="#cb14-312" aria-hidden="true" tabindex="-1"></a><span class="in">```{code-cell} python</span></span>
<span id="cb14-313"><a href="#cb14-313" aria-hidden="true" tabindex="-1"></a>print<span class="op">(</span>tokens_tensor<span class="op">)</span></span>
<span id="cb14-314"><a href="#cb14-314" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-315"><a href="#cb14-315" aria-hidden="true" tabindex="-1"></a>**Segment IDs**:</span>
<span id="cb14-316"><a href="#cb14-316" aria-hidden="true" tabindex="-1"></a><span class="in">```{code-cell} python</span></span>
<span id="cb14-317"><a href="#cb14-317" aria-hidden="true" tabindex="-1"></a>print<span class="op">(</span>segments_tensor<span class="op">)</span></span>
<span id="cb14-318"><a href="#cb14-318" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-319"><a href="#cb14-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-320"><a href="#cb14-320" aria-hidden="true" tabindex="-1"></a>Then, let's get the BERT embeddings for each token.</span>
<span id="cb14-321"><a href="#cb14-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-322"><a href="#cb14-322" aria-hidden="true" tabindex="-1"></a><span class="in">```{code-cell} python</span></span>
<span id="cb14-323"><a href="#cb14-323" aria-hidden="true" tabindex="-1"></a><span class="pp"># </span><span class="er">Configure model to return hidden states</span></span>
<span id="cb14-324"><a href="#cb14-324" aria-hidden="true" tabindex="-1"></a>model<span class="op">.</span>config<span class="op">.</span>output_hidden_states <span class="op">=</span> True</span>
<span id="cb14-325"><a href="#cb14-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-326"><a href="#cb14-326" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> model<span class="op">(</span>tokens_tensor<span class="op">,</span> segments_tensor<span class="op">)</span></span>
<span id="cb14-327"><a href="#cb14-327" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-328"><a href="#cb14-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-329"><a href="#cb14-329" aria-hidden="true" tabindex="-1"></a>The output includes <span class="in">`loss`</span>, <span class="in">`logits`</span>, and <span class="in">`hidden_states`</span>. We will use <span class="in">`hidden_states`</span>, which contains the embeddings of the tokens.</span>
<span id="cb14-330"><a href="#cb14-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-331"><a href="#cb14-331" aria-hidden="true" tabindex="-1"></a><span class="in">```{code-cell} python</span></span>
<span id="cb14-332"><a href="#cb14-332" aria-hidden="true" tabindex="-1"></a>hidden_states <span class="op">=</span> outputs<span class="op">.</span>hidden_states</span>
<span id="cb14-333"><a href="#cb14-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-334"><a href="#cb14-334" aria-hidden="true" tabindex="-1"></a>print<span class="op">(</span><span class="st">"how many layers? "</span><span class="op">,</span> len<span class="op">(</span>hidden_states<span class="op">))</span></span>
<span id="cb14-335"><a href="#cb14-335" aria-hidden="true" tabindex="-1"></a>print<span class="op">(</span><span class="st">"Shape? "</span><span class="op">,</span> hidden_states<span class="op">[</span><span class="dv">0</span><span class="op">].</span>shape<span class="op">)</span></span>
<span id="cb14-336"><a href="#cb14-336" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-337"><a href="#cb14-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-338"><a href="#cb14-338" aria-hidden="true" tabindex="-1"></a>The hidden states are a list of 13 tensors, where each tensor is of shape (batch_size, sequence_length, hidden_size). The first tensor is the input embeddings, and the subsequent tensors are the hidden states of the BERT layers.</span>
<span id="cb14-339"><a href="#cb14-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-340"><a href="#cb14-340" aria-hidden="true" tabindex="-1"></a>So, we have 13 choice of hidden states. Deep layers close to the output capture the context of the word from the previous layers.</span>
<span id="cb14-341"><a href="#cb14-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-342"><a href="#cb14-342" aria-hidden="true" tabindex="-1"></a>Here we will take the average over the last four hidden states for each token.</span>
<span id="cb14-343"><a href="#cb14-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-344"><a href="#cb14-344" aria-hidden="true" tabindex="-1"></a><span class="in">```{code-cell} python</span></span>
<span id="cb14-345"><a href="#cb14-345" aria-hidden="true" tabindex="-1"></a>last_four_layers <span class="op">=</span> hidden_states<span class="op">[-</span><span class="dv">4</span><span class="op">:]</span></span>
<span id="cb14-346"><a href="#cb14-346" aria-hidden="true" tabindex="-1"></a><span class="pp"># </span><span class="er">Stack the layers and then calculate mean</span></span>
<span id="cb14-347"><a href="#cb14-347" aria-hidden="true" tabindex="-1"></a>stacked_layers <span class="op">=</span> torch<span class="op">.</span>stack<span class="op">(</span>last_four_layers<span class="op">)</span></span>
<span id="cb14-348"><a href="#cb14-348" aria-hidden="true" tabindex="-1"></a>emb <span class="op">=</span> torch<span class="op">.</span>mean<span class="op">(</span>stacked_layers<span class="op">,</span> dim<span class="op">=</span><span class="dv">0</span><span class="op">)</span></span>
<span id="cb14-349"><a href="#cb14-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-350"><a href="#cb14-350" aria-hidden="true" tabindex="-1"></a>print<span class="op">(</span>emb<span class="op">.</span>shape<span class="op">)</span></span>
<span id="cb14-351"><a href="#cb14-351" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-352"><a href="#cb14-352" aria-hidden="true" tabindex="-1"></a>emb is of shape (sequence_length, hidden_size). Let us summarize the embeddings of the tokens into a function.</span>
<span id="cb14-353"><a href="#cb14-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-354"><a href="#cb14-354" aria-hidden="true" tabindex="-1"></a><span class="in">```{code-cell} python</span></span>
<span id="cb14-355"><a href="#cb14-355" aria-hidden="true" tabindex="-1"></a>def get_bert_embeddings<span class="op">(</span>text<span class="op">):</span></span>
<span id="cb14-356"><a href="#cb14-356" aria-hidden="true" tabindex="-1"></a>    tokenized_text<span class="op">,</span> tokens_tensor<span class="op">,</span> segments_tensor <span class="op">=</span> prepare_text<span class="op">(</span>text<span class="op">)</span></span>
<span id="cb14-357"><a href="#cb14-357" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> model<span class="op">(</span>tokens_tensor<span class="op">,</span> segments_tensor<span class="op">)</span></span>
<span id="cb14-358"><a href="#cb14-358" aria-hidden="true" tabindex="-1"></a>    hidden_states <span class="op">=</span> outputs<span class="op">[</span><span class="dv">2</span><span class="op">]</span>  # Access hidden states from tuple output</span>
<span id="cb14-359"><a href="#cb14-359" aria-hidden="true" tabindex="-1"></a>    <span class="pp"># </span><span class="er">Stack the last 4 layers then take mean</span></span>
<span id="cb14-360"><a href="#cb14-360" aria-hidden="true" tabindex="-1"></a>    stacked_layers <span class="op">=</span> torch<span class="op">.</span>stack<span class="op">(</span>hidden_states<span class="op">[-</span><span class="dv">4</span><span class="op">:])</span></span>
<span id="cb14-361"><a href="#cb14-361" aria-hidden="true" tabindex="-1"></a>    emb <span class="op">=</span> torch<span class="op">.</span>mean<span class="op">(</span>stacked_layers<span class="op">,</span> dim<span class="op">=</span><span class="dv">0</span><span class="op">)</span></span>
<span id="cb14-362"><a href="#cb14-362" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> emb<span class="op">,</span> tokenized_text</span>
<span id="cb14-363"><a href="#cb14-363" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-364"><a href="#cb14-364" aria-hidden="true" tabindex="-1"></a>Now, let us embed text and get the embeddings of the focal token.</span>
<span id="cb14-365"><a href="#cb14-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-366"><a href="#cb14-366" aria-hidden="true" tabindex="-1"></a><span class="in">```{code-cell} python</span></span>
<span id="cb14-367"><a href="#cb14-367" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> <span class="op">[]</span>  # label</span>
<span id="cb14-368"><a href="#cb14-368" aria-hidden="true" tabindex="-1"></a>emb <span class="op">=</span> <span class="op">[]</span>  # embedding</span>
<span id="cb14-369"><a href="#cb14-369" aria-hidden="true" tabindex="-1"></a>sentences <span class="op">=</span> <span class="op">[]</span>  # sentence</span>
<span id="cb14-370"><a href="#cb14-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-371"><a href="#cb14-371" aria-hidden="true" tabindex="-1"></a>def get_focal_token_embedding<span class="op">(</span>text<span class="op">,</span> focal_word_idx<span class="op">):</span></span>
<span id="cb14-372"><a href="#cb14-372" aria-hidden="true" tabindex="-1"></a>    emb<span class="op">,</span> tokenized_text <span class="op">=</span> get_bert_embeddings<span class="op">(</span>text<span class="op">)</span></span>
<span id="cb14-373"><a href="#cb14-373" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> emb<span class="op">[</span><span class="dv">0</span><span class="op">][</span>focal_word_idx<span class="op">]</span>  # Access first batch dimension</span>
<span id="cb14-374"><a href="#cb14-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-375"><a href="#cb14-375" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> index<span class="op">,</span> row in train_data<span class="op">.</span>iterrows<span class="op">():</span></span>
<span id="cb14-376"><a href="#cb14-376" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> row<span class="op">[</span><span class="st">"sentence"</span><span class="op">]</span></span>
<span id="cb14-377"><a href="#cb14-377" aria-hidden="true" tabindex="-1"></a>    focal_word_idx <span class="op">=</span> row<span class="op">[</span><span class="st">"word_pos"</span><span class="op">]</span></span>
<span id="cb14-378"><a href="#cb14-378" aria-hidden="true" tabindex="-1"></a>    _emb <span class="op">=</span> get_focal_token_embedding<span class="op">(</span>text<span class="op">,</span> focal_word_idx<span class="op">)</span></span>
<span id="cb14-379"><a href="#cb14-379" aria-hidden="true" tabindex="-1"></a>    labels<span class="op">.</span>append<span class="op">(</span>row<span class="op">[</span><span class="st">"label"</span><span class="op">])</span></span>
<span id="cb14-380"><a href="#cb14-380" aria-hidden="true" tabindex="-1"></a>    emb<span class="op">.</span>append<span class="op">(</span>_emb<span class="op">)</span></span>
<span id="cb14-381"><a href="#cb14-381" aria-hidden="true" tabindex="-1"></a>    sentences<span class="op">.</span>append<span class="op">(</span>text<span class="op">)</span></span>
<span id="cb14-382"><a href="#cb14-382" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-383"><a href="#cb14-383" aria-hidden="true" tabindex="-1"></a>Finally, let us visualize the embeddings using PCA.</span>
<span id="cb14-384"><a href="#cb14-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-385"><a href="#cb14-385" aria-hidden="true" tabindex="-1"></a><span class="in">```{code-cell} python</span></span>
<span id="cb14-386"><a href="#cb14-386" aria-hidden="true" tabindex="-1"></a><span class="op">:</span>tags<span class="op">:</span> <span class="op">[</span>hide<span class="op">-</span>input<span class="op">]</span></span>
<span id="cb14-387"><a href="#cb14-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-388"><a href="#cb14-388" aria-hidden="true" tabindex="-1"></a><span class="pp"># </span><span class="er">Convert list of tensors to numpy array</span></span>
<span id="cb14-389"><a href="#cb14-389" aria-hidden="true" tabindex="-1"></a>emb_numpy <span class="op">=</span> torch<span class="op">.</span>stack<span class="op">(</span>emb<span class="op">).</span>detach<span class="op">().</span>numpy<span class="op">()</span></span>
<span id="cb14-390"><a href="#cb14-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-391"><a href="#cb14-391" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA<span class="op">(</span>n_components<span class="op">=</span><span class="dv">2</span><span class="op">,</span> random_state<span class="op">=</span><span class="dv">42</span><span class="op">)</span></span>
<span id="cb14-392"><a href="#cb14-392" aria-hidden="true" tabindex="-1"></a>xy <span class="op">=</span> pca<span class="op">.</span>fit_transform<span class="op">(</span>emb_numpy<span class="op">)</span></span>
<span id="cb14-393"><a href="#cb14-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-394"><a href="#cb14-394" aria-hidden="true" tabindex="-1"></a>output_notebook<span class="op">()</span></span>
<span id="cb14-395"><a href="#cb14-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-396"><a href="#cb14-396" aria-hidden="true" tabindex="-1"></a><span class="pp"># </span><span class="er">Create data source for Bokeh</span></span>
<span id="cb14-397"><a href="#cb14-397" aria-hidden="true" tabindex="-1"></a>source <span class="op">=</span> ColumnDataSource<span class="op">(</span>data<span class="op">=</span>dict<span class="op">(</span></span>
<span id="cb14-398"><a href="#cb14-398" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span>xy<span class="op">[:,</span> <span class="dv">0</span><span class="op">],</span></span>
<span id="cb14-399"><a href="#cb14-399" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>xy<span class="op">[:,</span> <span class="dv">1</span><span class="op">],</span></span>
<span id="cb14-400"><a href="#cb14-400" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span>labels<span class="op">,</span></span>
<span id="cb14-401"><a href="#cb14-401" aria-hidden="true" tabindex="-1"></a>    sentence<span class="op">=</span>sentences</span>
<span id="cb14-402"><a href="#cb14-402" aria-hidden="true" tabindex="-1"></a><span class="op">))</span></span>
<span id="cb14-403"><a href="#cb14-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-404"><a href="#cb14-404" aria-hidden="true" tabindex="-1"></a><span class="pp"># </span><span class="er">Create Bokeh figure</span></span>
<span id="cb14-405"><a href="#cb14-405" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> figure<span class="op">(</span>title<span class="op">=</span><span class="st">"Word Embeddings Visualization"</span><span class="op">,</span> x_axis_label<span class="op">=</span><span class="st">"PCA 1"</span><span class="op">,</span> y_axis_label<span class="op">=</span><span class="st">"PCA 2"</span><span class="op">,</span></span>
<span id="cb14-406"><a href="#cb14-406" aria-hidden="true" tabindex="-1"></a>           width<span class="op">=</span><span class="dv">700</span><span class="op">,</span> height<span class="op">=</span><span class="dv">500</span><span class="op">)</span></span>
<span id="cb14-407"><a href="#cb14-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-408"><a href="#cb14-408" aria-hidden="true" tabindex="-1"></a><span class="pp"># </span><span class="er">Add hover tool</span></span>
<span id="cb14-409"><a href="#cb14-409" aria-hidden="true" tabindex="-1"></a>hover <span class="op">=</span> HoverTool<span class="op">(</span>tooltips<span class="op">=[</span></span>
<span id="cb14-410"><a href="#cb14-410" aria-hidden="true" tabindex="-1"></a>    <span class="op">(</span><span class="ch">'L</span><span class="er">abel</span><span class="ch">'</span><span class="op">,</span> <span class="ch">'@</span><span class="er">label</span><span class="ch">'</span><span class="op">),</span></span>
<span id="cb14-411"><a href="#cb14-411" aria-hidden="true" tabindex="-1"></a>    <span class="op">(</span><span class="ch">'S</span><span class="er">entence</span><span class="ch">'</span><span class="op">,</span> <span class="ch">'@</span><span class="er">sentence</span><span class="ch">'</span><span class="op">)</span></span>
<span id="cb14-412"><a href="#cb14-412" aria-hidden="true" tabindex="-1"></a><span class="op">])</span></span>
<span id="cb14-413"><a href="#cb14-413" aria-hidden="true" tabindex="-1"></a>p<span class="op">.</span>add_tools<span class="op">(</span>hover<span class="op">)</span></span>
<span id="cb14-414"><a href="#cb14-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-415"><a href="#cb14-415" aria-hidden="true" tabindex="-1"></a><span class="pp"># </span><span class="er">Create color map for labels</span></span>
<span id="cb14-416"><a href="#cb14-416" aria-hidden="true" tabindex="-1"></a>import seaborn as sns</span>
<span id="cb14-417"><a href="#cb14-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-418"><a href="#cb14-418" aria-hidden="true" tabindex="-1"></a>unique_labels <span class="op">=</span> list<span class="op">(</span>set<span class="op">(</span>labels<span class="op">))</span></span>
<span id="cb14-419"><a href="#cb14-419" aria-hidden="true" tabindex="-1"></a>color_map <span class="op">=</span> sns<span class="op">.</span>color_palette<span class="op">().</span>as_hex<span class="op">()[</span><span class="dv">0</span><span class="op">:</span>len<span class="op">(</span>unique_labels<span class="op">)]</span></span>
<span id="cb14-420"><a href="#cb14-420" aria-hidden="true" tabindex="-1"></a>source<span class="op">.</span>data<span class="op">[</span><span class="ch">'c</span><span class="er">olor</span><span class="ch">'</span><span class="op">]</span> <span class="op">=</span> <span class="op">[</span>color_map<span class="op">[</span>label<span class="op">]</span> <span class="cf">for</span> label in labels<span class="op">]</span></span>
<span id="cb14-421"><a href="#cb14-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-422"><a href="#cb14-422" aria-hidden="true" tabindex="-1"></a><span class="pp"># </span><span class="er">Add scatter plot</span></span>
<span id="cb14-423"><a href="#cb14-423" aria-hidden="true" tabindex="-1"></a>p<span class="op">.</span>scatter<span class="op">(</span><span class="ch">'x'</span><span class="op">,</span> <span class="ch">'y'</span><span class="op">,</span> size<span class="op">=</span><span class="dv">12</span><span class="op">,</span> line_color<span class="op">=</span><span class="st">"DarkSlateGrey"</span><span class="op">,</span> line_width<span class="op">=</span><span class="dv">2</span><span class="op">,</span></span>
<span id="cb14-424"><a href="#cb14-424" aria-hidden="true" tabindex="-1"></a>         fill_color<span class="op">=</span><span class="ch">'c</span><span class="er">olor</span><span class="ch">'</span><span class="op">,</span> source<span class="op">=</span>source<span class="op">)</span></span>
<span id="cb14-425"><a href="#cb14-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-426"><a href="#cb14-426" aria-hidden="true" tabindex="-1"></a>show<span class="op">(</span>p<span class="op">)</span></span>
<span id="cb14-427"><a href="#cb14-427" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-428"><a href="#cb14-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-429"><a href="#cb14-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-430"><a href="#cb14-430" aria-hidden="true" tabindex="-1"></a><span class="fu">## Exercise</span></span>
<span id="cb14-431"><a href="#cb14-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-432"><a href="#cb14-432" aria-hidden="true" tabindex="-1"></a>We have used the last 4 layers of BERT to generate the embeddings of the tokens. Now, let's use the last $k = 1, 2, 3$ layers of BERT to generate the embeddings of the tokens. Then plot the embeddings using PCA.</span>
<span id="cb14-433"><a href="#cb14-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-434"><a href="#cb14-434" aria-hidden="true" tabindex="-1"></a><span class="fu">## References</span></span>
<span id="cb14-435"><a href="#cb14-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-438"><a href="#cb14-438" aria-hidden="true" tabindex="-1"></a><span class="in">```{footbibliography}</span></span>
<span id="cb14-439"><a href="#cb14-439" aria-hidden="true" tabindex="-1"></a><span class="in">:style: unsrt</span></span>
<span id="cb14-440"><a href="#cb14-440" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-441"><a href="#cb14-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-442"><a href="#cb14-442" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2025, Sadamori Kojaku</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions"><ul><li><a href="https://github.com/skojaku/applied-soft-comp/edit/main/m06-llms/bert.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/skojaku/applied-soft-comp/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/skojaku/applied-soft-comp">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>