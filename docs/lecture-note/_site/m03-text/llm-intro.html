<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sadamori Kojaku">
<meta name="dcterms.date" content="2025-11-22">

<title>Large Language Models in Practice – Applied Soft Computing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../m03-text/prompt-engineering.html" rel="next">
<link href="../m03-text/overview.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-0348920b7671f696dc9078d39bff215e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-b8a9bfad7ca18893f6a3351e12995b20.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "|"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../assets/custom.css">
</head>

<body class="nav-sidebar docked nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../logo.jpg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Applied Soft Computing</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-toolkit--workflow" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Toolkit &amp; Workflow</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-toolkit--workflow">    
        <li class="dropdown-header">─── Module 1 ───</li>
        <li>
    <a class="dropdown-item" href="../m01-toolkit/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-toolkit/git-github.html">
 <span class="dropdown-text">Git &amp; GitHub</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-toolkit/tidy-data.html">
 <span class="dropdown-text">Tidy Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-toolkit/data-provenance.html">
 <span class="dropdown-text">Data Provenance</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-toolkit/environments.qmd">
 <span class="dropdown-text">Environments</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-visualization" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Visualization</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-visualization">    
        <li class="dropdown-header">─── Module 2 ───</li>
        <li>
    <a class="dropdown-item" href="../m02-visualization/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-visualization/principles.html">
 <span class="dropdown-text">Principles</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-visualization/dimensionality-reduction.html">
 <span class="dropdown-text">High-Dimensional Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-visualization/networks.html">
 <span class="dropdown-text">Networks</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-visualization/time-series.html">
 <span class="dropdown-text">Time-Series</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-deep-learning" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Deep Learning</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-deep-learning">    
        <li class="dropdown-header">─── Module 3: Text ───</li>
        <li>
    <a class="dropdown-item" href="../m03-text/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m03-text/word2vec.md">
 <span class="dropdown-text">Word2Vec</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m03-text/lstm.md">
 <span class="dropdown-text">RNNs &amp; LSTMs</span></a>
  </li>  
        <li class="dropdown-header">─── Module 4: Images ───</li>
        <li>
    <a class="dropdown-item" href="../m04-images/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m04-images/cnn.md">
 <span class="dropdown-text">CNNs</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m04-images/resnet.md">
 <span class="dropdown-text">ResNet</span></a>
  </li>  
        <li class="dropdown-header">─── Module 5: Graphs ───</li>
        <li>
    <a class="dropdown-item" href="../m05-graphs/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m05-graphs/graph-embedding-w-word2vec.html">
 <span class="dropdown-text">Graph Embeddings</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m05-graphs/graph-convolutional-network.html">
 <span class="dropdown-text">GNNs</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-advanced-topics" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Advanced Topics</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-advanced-topics">    
        <li class="dropdown-header">─── Module 6: LLMs ───</li>
        <li>
    <a class="dropdown-item" href="../m06-llms/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m06-llms/transformers.md">
 <span class="dropdown-text">Transformers</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m06-llms/scaling-emergence.html">
 <span class="dropdown-text">Scaling &amp; Emergence</span></a>
  </li>  
        <li class="dropdown-header">─── Module 7: Self-Supervised ───</li>
        <li>
    <a class="dropdown-item" href="../m07-self-supervised/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m07-self-supervised/contrastive-learning.html">
 <span class="dropdown-text">Contrastive Learning</span></a>
  </li>  
        <li class="dropdown-header">─── Module 8: Explainability ───</li>
        <li>
    <a class="dropdown-item" href="../m08-explainability/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m08-explainability/fairness.html">
 <span class="dropdown-text">Fairness &amp; Ethics</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../m03-text/overview.html">Module 3: Deep Learning for Text</a></li><li class="breadcrumb-item"><a href="../m03-text/llm-intro.html">Large Language Models in Practice</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Course Information</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/welcome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About Us</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/why-applied-soft-computing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Why applied soft computing?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/discord.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Discord</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/minidora-usage.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Using Minidora</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/how-to-submit-assignment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to submit assignment</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/deliverables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deliverables</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 1: The Data Scientist’s Toolkit</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/git-github.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Version Control with Git &amp; GitHub</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/tidy-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Tidy Data Philosophy</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/data-provenance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Provenance</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/reproduceability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Reproducibility</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 2: Visualizing Complexity</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Principles of Effective Visualization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/1d-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing 1D Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/2d-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing 2D Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/highd-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing High-Dimensional Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/time-series.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing Time-Series</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 3: Deep Learning for Text</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/llm-intro.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Large Language Models in Practice</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/prompt-engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prompt Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/tokenization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tokenization: Unboxing How LLMs Read Text</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Transformers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/word-embeddings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/semantic-research.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Semaxis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/word-bias.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word Bias</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 4: Deep Learning for Images</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/image-processing.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Processing Fundamentals</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/cnn.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Convolutional Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/lenet.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LeNet Architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/alexnet.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AlexNet: Deep CNN Revolution</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/vgg.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">VGG Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/inception.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Inception &amp; Multi-Scale Features</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/batch-normalization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Batch Normalization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/resnet.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ResNet &amp; Skip Connections</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 5: Deep Learning for Graphs</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/spectral-embedding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Spectral Graph Embedding</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/graph-embedding-w-word2vec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Graph Embeddings with Word2Vec</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/spectral-vs-neural-embedding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Spectral vs.&nbsp;Neural Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/from-image-to-graph.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">From Images to Graphs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/graph-convolutional-network.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Graph Convolutional Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/popular-gnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Popular GNN Architectures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/software.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GNN Software &amp; Tools</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 6: Large Language Models &amp; Emergent Behavior</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/transformers.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Transformer Architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/bert.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BERT &amp; Contextual Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/sentence-bert.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sentence-BERT for Semantic Similarity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/gpt.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GPT &amp; Generative Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/from-language-model-to-instruction-following.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">From Language Models to Instruction Following</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/prompt-tuning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prompt Engineering &amp; In-Context Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/scaling-emergence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Scaling Laws &amp; Emergent Abilities</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/llms-as-complex-systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LLMs as Complex Systems</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 7: Self-Supervised Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-self-supervised/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-self-supervised/paradigm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Self-Supervised Paradigm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-self-supervised/contrastive-learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Contrastive Learning (SimCLR)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-self-supervised/graphs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Self-Supervised Learning for Graphs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-self-supervised/time-series.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Self-Supervised Learning for Time-Series</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 8: Explainability &amp; Ethics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/need.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Need for Explainability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/attention.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Attention Visualization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/lime-shap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LIME &amp; SHAP</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/fairness.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Algorithmic Fairness &amp; Bias</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Causality vs.&nbsp;Correlation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Legacy Materials</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/what-to-learn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word &amp; Document Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/what-to-learn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recurrent Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/what-to-learn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Processing (CNNs)</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../m03-text/overview.html">Module 3: Deep Learning for Text</a></li><li class="breadcrumb-item"><a href="../m03-text/llm-intro.html">Large Language Models in Practice</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Large Language Models in Practice</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Sadamori Kojaku </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 22, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Spoiler
</div>
</div>
<div class="callout-body-container callout-body">
<p>Large language models don’t understand language—they compress statistical regularities from billions of text samples into probability distributions that generate fluent outputs correlated with truth but not guaranteed to be true.</p>
</div>
</div>
<section id="the-naive-model-vs.-the-reality" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="the-naive-model-vs.-the-reality"><span class="header-section-number">1</span> The Naive Model vs.&nbsp;The Reality</h2>
<p>If a machine writes coherent essays, debugs code, and answers questions accurately, it must understand language the way humans do. This intuition traces to Turing’s 1950 test: if you can’t tell it’s a machine, treat it as intelligent. The assumption is that fluency requires comprehension.</p>
<p>ELIZA, a 1960s chatbot, shattered this assumption. It convinced users it was a therapist using only keyword substitution and reflection—no comprehension, just pattern matching. Large language models are ELIZA scaled by thirteen orders of magnitude. They predict which word comes next in a sequence, nothing more. Yet this simple objective forces them to encode grammar, facts, logic, and context—not because they understand, but because <strong>prediction requires compression of statistical regularities.</strong> The model that best predicts “The capital of France is ___” must have compressed the statistical pattern linking countries to capitals, whether or not it “knows” what a capital is.</p>
<p>The paradox: optimizing for prediction creates representations that look like understanding. But probe the extremes—ask about events after the training cutoff, request precise citations, demand genuine reasoning—and the illusion breaks. The model follows fluency where truth data is sparse.</p>
</section>
<section id="the-hidden-mechanism" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="the-hidden-mechanism"><span class="header-section-number">2</span> The Hidden Mechanism</h2>
<p>Imagine you want to predict lottery numbers but can’t compute true probabilities. You memorize millions of historical draws. When asked “What comes next?”, you recall similar past sequences and output the most common continuation. You’re not computing probabilities; you’re pattern matching against compressed memory. This is the toy model for how LLMs work.</p>
<p>LLMs function like lossy compression algorithms. To predict “The capital of France is ___,” the model must compress not just the fact (Paris) but the <strong>statistical regularities</strong> governing how facts appear in text—that capitals follow “The capital of,” that France is a country, that countries have capitals. This compression is probabilistic, not factual. The model stores <span class="math inline">P(\text{word}_{n+1} \mid \text{word}_1, \ldots, \text{word}_n)</span>, which words tend to follow which other words in which contexts.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/llm-next-word.gif" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%" alt="A GIF showing how LLMs predict the next word by estimating probability distributions over the vocabulary."></p>
</figure>
</div>
<p>Training feeds the model billions of sentences. For each sentence, the model predicts the next word, compares its prediction to the actual next word, and adjusts its parameters to increase the probability of the correct word. Repeat trillions of times. The result: a compressed representation of how language behaves statistically. The model doesn’t learn “Paris is the capital of France” as a fact; it learns that in contexts matching the pattern <code>[The capital of France is]</code>, the token “Paris” appears with high probability.</p>
<p>This optimization creates <strong>hallucination</strong>, fluent but false outputs. The model optimizes for probability, not truth. If it has seen 1,000 sentences about quantum networks and 10 about quantum community detection, it fabricates plausible results for a non-existent “Smith et al.&nbsp;paper” because that pattern fits academic writing. Truth and fluency correlate in the training data, so the model is mostly truthful. But in the tails—obscure topics, recent events, precise recall—fluency diverges from truth, and the model follows fluency.</p>
<p>Two constraints compound this issue. First, <strong>context limits</strong>: models see only 2,000–8,000 tokens at once, meaning that if you paste 100 abstracts, early ones are mathematically evicted from the model’s working memory. Second, <strong>stochasticity</strong>: the model samples from probability distributions, so the same prompt yields different outputs across runs. Fluency is deterministic; specifics are random.</p>
</section>
<section id="the-strategic-application" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="the-strategic-application"><span class="header-section-number">3</span> The Strategic Application</h2>
<p>Use LLMs to scale pattern recognition, not judgment. They excel where speed trumps precision: summarizing 50 abstracts to identify the 10 worth reading, extracting structured data from unstructured text, reformulating technical concepts, brainstorming research directions. They fail where precision is paramount—verifying citations, making ethical decisions, performing statistical analysis. Think of an LLM as an assistant who has read the internet but remembers imperfectly. You delegate skimming. You verify everything.</p>
<p>The events that matter live in the tail. Most outputs are fluent and useful. But the hallucinated citation that undermines credibility, the missed context that skews analysis—these failures cluster in the tails of the probability distribution. Harvest the center. Defend against the extremes.</p>
</section>
<section id="setting-up-ollama" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="setting-up-ollama"><span class="header-section-number">4</span> Setting Up Ollama</h2>
<p>For this course, we use Ollama, a tool for running LLMs locally, with Gemma 3N, a 4-billion parameter open-source model. Free, private, capable enough for research tasks. Visit <a href="https://ollama.ai">ollama.ai</a>, download the installer, and verify installation:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">ollama</span> <span class="at">--version</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">ollama</span> pull gemma3n:latest</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="ex">ollama</span> run gemma3n:latest <span class="st">"What is a complex system?"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>If you receive a coherent response, install the Python client and send your first prompt:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install ollama</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="5feb3b69" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ollama</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>params_llm <span class="op">=</span> {<span class="st">"model"</span>: <span class="st">"gemma3n:latest"</span>, <span class="st">"options"</span>: {<span class="st">"temperature"</span>: <span class="fl">0.3</span>}}</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> ollama.generate(</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    prompt<span class="op">=</span><span class="st">"Explain emergence in two sentences."</span>,</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>params_llm</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(response.response)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Emergence is when complex patterns and behaviors arise from simpler interactions within a system, where these patterns aren't explicitly programmed into the individual components.  Essentially, the whole becomes greater than the sum of its parts, exhibiting novel properties that couldn't be predicted just by looking at the individual elements.



</code></pre>
</div>
</div>
<p>Running this twice produces different outputs because LLMs sample from probability distributions. The <strong>temperature</strong> parameter controls this randomness—lower values (0.1) make outputs more deterministic; higher values (1.0) increase diversity. You’re controlling how far into the tail of the probability distribution the model samples.</p>
</section>
<section id="research-applications" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="research-applications"><span class="header-section-number">5</span> Research Applications</h2>
<p>The strategy is simple: use LLMs for tasks where speed trumps precision, then verify the outputs that matter. Three workflows demonstrate this pattern.</p>
<p>First, abstract summarization. You collected 50 papers on network science. Which deserve detailed reading? LLMs scan them in seconds:</p>
<div id="13d920d5" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>abstract <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="st">Community detection in networks is a fundamental problem in complex systems.</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="st">While many algorithms exist, most assume static networks. We propose a dynamic</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="st">community detection algorithm that tracks evolving communities over time using</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="st">a temporal smoothness constraint. We evaluate our method on synthetic and real</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="st">temporal networks, showing it outperforms static methods applied to temporal</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="st">snapshots. Our approach reveals how communities merge, split, and persist in</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="st">social networks, biological systems, and transportation networks.</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="ss">f"Summarize this abstract in one sentence:</span><span class="ch">\n\n</span><span class="sc">{</span>abstract<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> ollama.generate(prompt<span class="op">=</span>prompt, <span class="op">**</span>params_llm)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(response.response)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>This paper introduces a novel dynamic community detection algorithm that effectively tracks evolving communities in networks over time, outperforming static methods and revealing community dynamics in various real-world systems.



</code></pre>
</div>
</div>
<p>The model captures the pattern: propose method, evaluate, outperform baselines. It doesn’t understand the paper; it has seen enough academic abstracts to recognize the structure. For multiple abstracts, loop through them:</p>
<div id="5175512d" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, abstract <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="st">"Abstract 1..."</span>, <span class="st">"Abstract 2..."</span>], <span class="dv">1</span>):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> ollama.generate(prompt<span class="op">=</span><span class="ss">f"Summarize:</span><span class="ch">\n\n</span><span class="sc">{</span>abstract<span class="sc">}</span><span class="ss">"</span>, <span class="op">**</span>params_llm)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">. </span><span class="sc">{</span>response<span class="sc">.</span>response<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1. Please provide me with "Abstract 1"! I need the text of the abstract to be able to summarize it for you. 

Just paste the abstract here, and I'll give you a concise summary. 😊 

I'm ready when you are!
2. Please provide me with the content of "Abstract 2"! I need the text of the abstract to be able to summarize it for you. 

Just paste the abstract here, and I'll do my best to give you a concise and accurate summary. 😊 

</code></pre>
</div>
</div>
<p>Local models are slow (2–5 seconds per abstract). For thousands of papers, switch to cloud APIs. But the workflow scales: delegate skimming to the model, retain judgment for yourself.</p>
<p>Second, structured extraction. Turn unstructured text into structured data automatically:</p>
<div id="f67468fa" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>abstract <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="st">We analyze scientific collaboration networks using 5 million papers from</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="st">2000-2020. Using graph neural networks and community detection, we identify</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="st">disciplinary boundaries and interdisciplinary bridges. Interdisciplinarity</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="st">increased 25%, with physics and CS showing strongest cross-connections.</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="ss">f"""Extract: Domain, Methods, Key Finding</span><span class="ch">\n\n</span><span class="sc">{</span>abstract<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">Format:</span><span class="ch">\n</span><span class="ss">Domain:...</span><span class="ch">\n</span><span class="ss">Methods:...</span><span class="ch">\n</span><span class="ss">Key Finding:..."""</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> ollama.generate(prompt<span class="op">=</span>prompt, <span class="op">**</span>params_llm)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(response.response)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Here's the extraction in the requested format:

Domain: Scientific Collaboration Networks
Methods: Graph Neural Networks, Community Detection, Analysis of 5 million papers (2000-2020)
Key Finding: Interdisciplinarity increased by 25% between 2000-2020, with the strongest cross-connections observed between Physics and Computer Science.



</code></pre>
</div>
</div>
<p>Scale this to hundreds of papers for meta-analysis. Always verify—LLMs misinterpret obscure terminology and fabricate plausible-sounding technical details when uncertain.</p>
<p>Third, hypothesis generation. LLMs pattern-match against research questions they’ve encountered in training data:</p>
<div id="d7e31d2f" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>context <span class="op">=</span> <span class="st">"""I study concept spread in citation networks. Highly cited papers</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="st">combine existing concepts novelty. What should I study next?"""</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="ss">f"""Suggest three follow-up research questions:</span><span class="ch">\n\n</span><span class="sc">{</span>context<span class="sc">}</span><span class="ss">"""</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> ollama.generate(prompt<span class="op">=</span>prompt, <span class="op">**</span>params_llm)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(response.response)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Okay, here are three follow-up research questions, building upon your current work on concept spread in citation networks, focusing on highly cited papers and the interplay of existing concepts and novelty.  I've tried to offer a mix of methodological and theoretical directions:

**1.  How does the *type* of novelty (e.g., incremental, radical, convergent) in highly cited papers influence the rate and direction of concept spread?**

*   **Rationale:** You've identified that highly cited papers combine existing concepts with novelty.  However, the *nature* of that novelty likely matters.  Is it a small tweak to an existing idea (incremental), a completely new paradigm (radical), or a synthesis of multiple existing ideas (convergent)?  Different types of novelty might spread differently through the citation network.
*   **Methodology:**
    *   **Concept Extraction:**  Develop a method (potentially combining NLP and manual annotation) to categorize the type of novelty present in highly cited papers.  This could involve identifying keywords, phrases, and arguments that signal incremental, radical, or convergent novelty.
    *   **Network Analysis:**  Analyze the citation network to see if papers with different types of novelty have different citation patterns (e.g., different citation rates, different types of citing papers, different network positions).
    *   **Temporal Analysis:**  Track the spread of concepts over time, looking for differences in the spread patterns of concepts associated with different types of novelty.
*   **Potential Insights:**  This could reveal whether incremental novelty spreads quickly and widely, while radical novelty takes longer to gain traction but can have a more transformative impact.

**2.  To what extent does the *citation context* (how a highly cited paper is cited) mediate the spread of concepts?**

*   **Rationale:**  It's not just *that* a paper is highly cited, but *how* it's cited that matters.  Is it cited for its core argument, a specific method, a critique, or a combination?  The citation context could influence whether the concept is adopted, adapted, or rejected.
*   **Methodology:**
    *   **Citation Context Analysis:**  Develop a method to analyze the text surrounding citations of highly cited papers.  This could involve using NLP techniques to identify the specific arguments or concepts being referenced.
    *   **Network Analysis:**  Create a citation network where nodes are citations and edges represent the relationship between the cited paper and the citing paper.
    *   **Correlation Analysis:**  Correlate the citation context with the subsequent spread of concepts in the network.  Do citations that highlight specific aspects of the paper lead to faster or more widespread concept adoption?
*   **Potential Insights:**  This could reveal the importance of framing and interpretation in the spread of ideas.  It might also highlight the role of debates and critiques in shaping the evolution of concepts.

**3.  Can we identify "concept hubs" within the citation network – papers that act as particularly influential nodes in the spread of concepts from highly cited papers?**

*   **Rationale:**  Some papers are more effective at disseminating concepts than others.  These "concept hubs" might be characterized by their broad citation patterns, their ability to synthesize information from multiple sources, or their engagement with diverse communities.
*   **Methodology:**
    *   **Centrality Measures:**  Apply various network centrality measures (e.g., betweenness centrality, eigenvector centrality, degree centrality) to the citation network.
    *   **Hub Identification:**  Identify papers with high centrality scores as potential concept hubs.
    *   **Case Studies:**  Conduct in-depth case studies of these concept hubs to understand how they contribute to the spread of concepts from highly cited papers.  Analyze their content, citation patterns, and engagement with other researchers.
*   **Potential Insights:**  This could help us understand the mechanisms by which concepts spread through the citation network and identify strategies for promoting the dissemination of important ideas.  It could also reveal the role of specific communities or disciplines in shaping the spread of concepts.



These questions are designed to be relatively focused and address different aspects of your initial research.  They also offer opportunities to combine quantitative network analysis with qualitative case studies.  I hope this helps! Let me know if you'd like me to elaborate on any of these or suggest alternative directions.



</code></pre>
</div>
</div>
<p>Treat the model as a thought partner, not an oracle. It helps structure thinking but doesn’t possess domain expertise. The suggestions reflect patterns in how research questions are framed, not deep knowledge of your field.</p>
</section>
<section id="failure-modes-and-boundaries" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="failure-modes-and-boundaries"><span class="header-section-number">6</span> Failure Modes and Boundaries</h2>
<p>The failure modes follow directly from the mechanism. LLMs fabricate plausibly because they optimize for fluency, not truth. Ask about a non-existent “Smith et al.&nbsp;quantum paper” and receive fluent academic prose describing results that never happened. Always verify citations. The model has seen thousands of papers cited in the format “Smith et al.&nbsp;(2023) demonstrated that…” and generates outputs matching that pattern even when the citation is fictional.</p>
<p>Context limits are architectural. Models see only 2,000–8,000 tokens at once. Paste 100 abstracts and early ones are mathematically evicted from working memory. The model doesn’t “remember” them; they’re gone. Knowledge cutoffs are temporal. Gemma 3N’s training ended early 2024. Ask about recent events and receive outdated information or plausible fabrications constructed from pre-cutoff patterns.</p>
<p>Reasoning is absent. LLMs pattern-match, they don’t reason. Ask “How many r’s in ‘Strawberry’?” and the model might answer correctly via pattern matching against similar questions in training data, not by counting letters. Sometimes right. Often wrong. The model has no internal representation of what counting means.</p>
<p>These aren’t bugs to be fixed. They’re intrinsic to the architecture. Use LLMs to accelerate work, not replace judgment. They excel at summarizing text, extracting structure, reformulating concepts, brainstorming, generating synthetic examples, and translation. They fail at literature reviews without verification, factual claims without sources, statistical analysis, and ethical decisions. Harvest the center of the distribution where fluency and truth correlate. Defend against the tails where they diverge.</p>
</section>
<section id="next" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="next"><span class="header-section-number">7</span> Next</h2>
<p>You’ve seen LLMs in practice—setup, summarization, extraction, limitations. But how do they actually work? What happens inside when you send a prompt?</p>
<p>The rest of this module unboxes the technology: <strong>prompt engineering</strong> (communicating with LLMs), <strong>embeddings</strong> (representing meaning as numbers), <strong>transformers</strong> (the architecture enabling modern NLP), <strong>fundamentals</strong> (from word counts to neural representations).</p>
<p>First, let’s master talking to machines.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../m03-text/overview.html" class="pagination-link" aria-label="Overview">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Overview</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../m03-text/prompt-engineering.html" class="pagination-link" aria-label="Prompt Engineering">
        <span class="nav-page-text">Prompt Engineering</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb13" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Large Language Models in Practice"</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> applsoftcomp</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co">    enabled: true</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co">    cache: true</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>::: {.callout-note appearance="minimal"}</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="fu">## Spoiler</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>Large language models don't understand language—they compress statistical regularities from billions of text samples into probability distributions that generate fluent outputs correlated with truth but not guaranteed to be true.</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Naive Model vs. The Reality</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>If a machine writes coherent essays, debugs code, and answers questions accurately, it must understand language the way humans do. This intuition traces to Turing's 1950 test: if you can't tell it's a machine, treat it as intelligent. The assumption is that fluency requires comprehension.</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>ELIZA, a 1960s chatbot, shattered this assumption. It convinced users it was a therapist using only keyword substitution and reflection—no comprehension, just pattern matching. Large language models are ELIZA scaled by thirteen orders of magnitude. They predict which word comes next in a sequence, nothing more. Yet this simple objective forces them to encode grammar, facts, logic, and context—not because they understand, but because **prediction requires compression of statistical regularities.** The model that best predicts "The capital of France is ___" must have compressed the statistical pattern linking countries to capitals, whether or not it "knows" what a capital is.</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>The paradox: optimizing for prediction creates representations that look like understanding. But probe the extremes—ask about events after the training cutoff, request precise citations, demand genuine reasoning—and the illusion breaks. The model follows fluency where truth data is sparse.</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Hidden Mechanism</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>Imagine you want to predict lottery numbers but can't compute true probabilities. You memorize millions of historical draws. When asked "What comes next?", you recall similar past sequences and output the most common continuation. You're not computing probabilities; you're pattern matching against compressed memory. This is the toy model for how LLMs work.</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>LLMs function like lossy compression algorithms. To predict "The capital of France is ___," the model must compress not just the fact (Paris) but the **statistical regularities** governing how facts appear in text—that capitals follow "The capital of," that France is a country, that countries have capitals. This compression is probabilistic, not factual. The model stores $P(\text{word}_{n+1} \mid \text{word}_1, \ldots, \text{word}_n)$, which words tend to follow which other words in which contexts.</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a><span class="al">![](../figs/llm-next-word.gif)</span>{width=50% fig-alt="A GIF showing how LLMs predict the next word by estimating probability distributions over the vocabulary." fig-align="center"}</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>Training feeds the model billions of sentences. For each sentence, the model predicts the next word, compares its prediction to the actual next word, and adjusts its parameters to increase the probability of the correct word. Repeat trillions of times. The result: a compressed representation of how language behaves statistically. The model doesn't learn "Paris is the capital of France" as a fact; it learns that in contexts matching the pattern <span class="in">`[The capital of France is]`</span>, the token "Paris" appears with high probability.</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>This optimization creates **hallucination**, fluent but false outputs. The model optimizes for probability, not truth. If it has seen 1,000 sentences about quantum networks and 10 about quantum community detection, it fabricates plausible results for a non-existent "Smith et al. paper" because that pattern fits academic writing. Truth and fluency correlate in the training data, so the model is mostly truthful. But in the tails—obscure topics, recent events, precise recall—fluency diverges from truth, and the model follows fluency.</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>Two constraints compound this issue. First, **context limits**: models see only 2,000–8,000 tokens at once, meaning that if you paste 100 abstracts, early ones are mathematically evicted from the model's working memory. Second, **stochasticity**: the model samples from probability distributions, so the same prompt yields different outputs across runs. Fluency is deterministic; specifics are random.</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Strategic Application</span></span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>Use LLMs to scale pattern recognition, not judgment. They excel where speed trumps precision: summarizing 50 abstracts to identify the 10 worth reading, extracting structured data from unstructured text, reformulating technical concepts, brainstorming research directions. They fail where precision is paramount—verifying citations, making ethical decisions, performing statistical analysis. Think of an LLM as an assistant who has read the internet but remembers imperfectly. You delegate skimming. You verify everything.</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>The events that matter live in the tail. Most outputs are fluent and useful. But the hallucinated citation that undermines credibility, the missed context that skews analysis—these failures cluster in the tails of the probability distribution. Harvest the center. Defend against the extremes.</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a><span class="fu">## Setting Up Ollama</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>For this course, we use Ollama, a tool for running LLMs locally, with Gemma 3N, a 4-billion parameter open-source model. Free, private, capable enough for research tasks. Visit <span class="co">[</span><span class="ot">ollama.ai</span><span class="co">](https://ollama.ai)</span>, download the installer, and verify installation:</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a><span class="in">```bash</span></span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a><span class="ex">ollama</span> <span class="at">--version</span></span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a><span class="ex">ollama</span> pull gemma3n:latest</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a><span class="ex">ollama</span> run gemma3n:latest <span class="st">"What is a complex system?"</span></span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>If you receive a coherent response, install the Python client and send your first prompt:</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a><span class="in">```bash</span></span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install ollama</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ollama</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>params_llm <span class="op">=</span> {<span class="st">"model"</span>: <span class="st">"gemma3n:latest"</span>, <span class="st">"options"</span>: {<span class="st">"temperature"</span>: <span class="fl">0.3</span>}}</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> ollama.generate(</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>    prompt<span class="op">=</span><span class="st">"Explain emergence in two sentences."</span>,</span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>params_llm</span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(response.response)</span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a>Running this twice produces different outputs because LLMs sample from probability distributions. The **temperature** parameter controls this randomness—lower values (0.1) make outputs more deterministic; higher values (1.0) increase diversity. You're controlling how far into the tail of the probability distribution the model samples.</span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a><span class="fu">## Research Applications</span></span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>The strategy is simple: use LLMs for tasks where speed trumps precision, then verify the outputs that matter. Three workflows demonstrate this pattern.</span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>First, abstract summarization. You collected 50 papers on network science. Which deserve detailed reading? LLMs scan them in seconds:</span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a>abstract <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a><span class="st">Community detection in networks is a fundamental problem in complex systems.</span></span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a><span class="st">While many algorithms exist, most assume static networks. We propose a dynamic</span></span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a><span class="st">community detection algorithm that tracks evolving communities over time using</span></span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a><span class="st">a temporal smoothness constraint. We evaluate our method on synthetic and real</span></span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a><span class="st">temporal networks, showing it outperforms static methods applied to temporal</span></span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a><span class="st">snapshots. Our approach reveals how communities merge, split, and persist in</span></span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a><span class="st">social networks, biological systems, and transportation networks.</span></span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb13-93"><a href="#cb13-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-94"><a href="#cb13-94" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="ss">f"Summarize this abstract in one sentence:</span><span class="ch">\n\n</span><span class="sc">{</span>abstract<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb13-95"><a href="#cb13-95" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> ollama.generate(prompt<span class="op">=</span>prompt, <span class="op">**</span>params_llm)</span>
<span id="cb13-96"><a href="#cb13-96" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(response.response)</span>
<span id="cb13-97"><a href="#cb13-97" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-98"><a href="#cb13-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-99"><a href="#cb13-99" aria-hidden="true" tabindex="-1"></a>The model captures the pattern: propose method, evaluate, outperform baselines. It doesn't understand the paper; it has seen enough academic abstracts to recognize the structure. For multiple abstracts, loop through them:</span>
<span id="cb13-100"><a href="#cb13-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-103"><a href="#cb13-103" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-104"><a href="#cb13-104" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, abstract <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="st">"Abstract 1..."</span>, <span class="st">"Abstract 2..."</span>], <span class="dv">1</span>):</span>
<span id="cb13-105"><a href="#cb13-105" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> ollama.generate(prompt<span class="op">=</span><span class="ss">f"Summarize:</span><span class="ch">\n\n</span><span class="sc">{</span>abstract<span class="sc">}</span><span class="ss">"</span>, <span class="op">**</span>params_llm)</span>
<span id="cb13-106"><a href="#cb13-106" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">. </span><span class="sc">{</span>response<span class="sc">.</span>response<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-107"><a href="#cb13-107" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-108"><a href="#cb13-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-109"><a href="#cb13-109" aria-hidden="true" tabindex="-1"></a>Local models are slow (2–5 seconds per abstract). For thousands of papers, switch to cloud APIs. But the workflow scales: delegate skimming to the model, retain judgment for yourself.</span>
<span id="cb13-110"><a href="#cb13-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-111"><a href="#cb13-111" aria-hidden="true" tabindex="-1"></a>Second, structured extraction. Turn unstructured text into structured data automatically:</span>
<span id="cb13-112"><a href="#cb13-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-115"><a href="#cb13-115" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-116"><a href="#cb13-116" aria-hidden="true" tabindex="-1"></a>abstract <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb13-117"><a href="#cb13-117" aria-hidden="true" tabindex="-1"></a><span class="st">We analyze scientific collaboration networks using 5 million papers from</span></span>
<span id="cb13-118"><a href="#cb13-118" aria-hidden="true" tabindex="-1"></a><span class="st">2000-2020. Using graph neural networks and community detection, we identify</span></span>
<span id="cb13-119"><a href="#cb13-119" aria-hidden="true" tabindex="-1"></a><span class="st">disciplinary boundaries and interdisciplinary bridges. Interdisciplinarity</span></span>
<span id="cb13-120"><a href="#cb13-120" aria-hidden="true" tabindex="-1"></a><span class="st">increased 25%, with physics and CS showing strongest cross-connections.</span></span>
<span id="cb13-121"><a href="#cb13-121" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb13-122"><a href="#cb13-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-123"><a href="#cb13-123" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="ss">f"""Extract: Domain, Methods, Key Finding</span><span class="ch">\n\n</span><span class="sc">{</span>abstract<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">Format:</span><span class="ch">\n</span><span class="ss">Domain:...</span><span class="ch">\n</span><span class="ss">Methods:...</span><span class="ch">\n</span><span class="ss">Key Finding:..."""</span></span>
<span id="cb13-124"><a href="#cb13-124" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> ollama.generate(prompt<span class="op">=</span>prompt, <span class="op">**</span>params_llm)</span>
<span id="cb13-125"><a href="#cb13-125" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(response.response)</span>
<span id="cb13-126"><a href="#cb13-126" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-127"><a href="#cb13-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-128"><a href="#cb13-128" aria-hidden="true" tabindex="-1"></a>Scale this to hundreds of papers for meta-analysis. Always verify—LLMs misinterpret obscure terminology and fabricate plausible-sounding technical details when uncertain.</span>
<span id="cb13-129"><a href="#cb13-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-130"><a href="#cb13-130" aria-hidden="true" tabindex="-1"></a>Third, hypothesis generation. LLMs pattern-match against research questions they've encountered in training data:</span>
<span id="cb13-131"><a href="#cb13-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-134"><a href="#cb13-134" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-135"><a href="#cb13-135" aria-hidden="true" tabindex="-1"></a>context <span class="op">=</span> <span class="st">"""I study concept spread in citation networks. Highly cited papers</span></span>
<span id="cb13-136"><a href="#cb13-136" aria-hidden="true" tabindex="-1"></a><span class="st">combine existing concepts novelty. What should I study next?"""</span></span>
<span id="cb13-137"><a href="#cb13-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-138"><a href="#cb13-138" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="ss">f"""Suggest three follow-up research questions:</span><span class="ch">\n\n</span><span class="sc">{</span>context<span class="sc">}</span><span class="ss">"""</span></span>
<span id="cb13-139"><a href="#cb13-139" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> ollama.generate(prompt<span class="op">=</span>prompt, <span class="op">**</span>params_llm)</span>
<span id="cb13-140"><a href="#cb13-140" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(response.response)</span>
<span id="cb13-141"><a href="#cb13-141" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-142"><a href="#cb13-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-143"><a href="#cb13-143" aria-hidden="true" tabindex="-1"></a>Treat the model as a thought partner, not an oracle. It helps structure thinking but doesn't possess domain expertise. The suggestions reflect patterns in how research questions are framed, not deep knowledge of your field.</span>
<span id="cb13-144"><a href="#cb13-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-145"><a href="#cb13-145" aria-hidden="true" tabindex="-1"></a><span class="fu">## Failure Modes and Boundaries</span></span>
<span id="cb13-146"><a href="#cb13-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-147"><a href="#cb13-147" aria-hidden="true" tabindex="-1"></a>The failure modes follow directly from the mechanism. LLMs fabricate plausibly because they optimize for fluency, not truth. Ask about a non-existent "Smith et al. quantum paper" and receive fluent academic prose describing results that never happened. Always verify citations. The model has seen thousands of papers cited in the format "Smith et al. (2023) demonstrated that..." and generates outputs matching that pattern even when the citation is fictional.</span>
<span id="cb13-148"><a href="#cb13-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-149"><a href="#cb13-149" aria-hidden="true" tabindex="-1"></a>Context limits are architectural. Models see only 2,000–8,000 tokens at once. Paste 100 abstracts and early ones are mathematically evicted from working memory. The model doesn't "remember" them; they're gone. Knowledge cutoffs are temporal. Gemma 3N's training ended early 2024. Ask about recent events and receive outdated information or plausible fabrications constructed from pre-cutoff patterns.</span>
<span id="cb13-150"><a href="#cb13-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-151"><a href="#cb13-151" aria-hidden="true" tabindex="-1"></a>Reasoning is absent. LLMs pattern-match, they don't reason. Ask "How many r's in 'Strawberry'?" and the model might answer correctly via pattern matching against similar questions in training data, not by counting letters. Sometimes right. Often wrong. The model has no internal representation of what counting means.</span>
<span id="cb13-152"><a href="#cb13-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-153"><a href="#cb13-153" aria-hidden="true" tabindex="-1"></a>These aren't bugs to be fixed. They're intrinsic to the architecture. Use LLMs to accelerate work, not replace judgment. They excel at summarizing text, extracting structure, reformulating concepts, brainstorming, generating synthetic examples, and translation. They fail at literature reviews without verification, factual claims without sources, statistical analysis, and ethical decisions. Harvest the center of the distribution where fluency and truth correlate. Defend against the tails where they diverge.</span>
<span id="cb13-154"><a href="#cb13-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-155"><a href="#cb13-155" aria-hidden="true" tabindex="-1"></a><span class="fu">## Next</span></span>
<span id="cb13-156"><a href="#cb13-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-157"><a href="#cb13-157" aria-hidden="true" tabindex="-1"></a>You've seen LLMs in practice—setup, summarization, extraction, limitations. But how do they actually work? What happens inside when you send a prompt?</span>
<span id="cb13-158"><a href="#cb13-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-159"><a href="#cb13-159" aria-hidden="true" tabindex="-1"></a>The rest of this module unboxes the technology: **prompt engineering** (communicating with LLMs), **embeddings** (representing meaning as numbers), **transformers** (the architecture enabling modern NLP), **fundamentals** (from word counts to neural representations).</span>
<span id="cb13-160"><a href="#cb13-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-161"><a href="#cb13-161" aria-hidden="true" tabindex="-1"></a>First, let's master talking to machines.</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2025, Sadamori Kojaku</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions"><ul><li><a href="https://github.com/skojaku/applied-soft-comp/edit/main/m03-text/llm-intro.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/skojaku/applied-soft-comp/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/skojaku/applied-soft-comp">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>