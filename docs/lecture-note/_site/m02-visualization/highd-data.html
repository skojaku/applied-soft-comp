<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sadamori Kojaku">
<meta name="dcterms.date" content="2025-11-17">

<title>High-Dimensional Data Visualization – Applied Soft Computing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../m02-visualization/networks.html" rel="next">
<link href="../m02-visualization/2d-data.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-0348920b7671f696dc9078d39bff215e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-fee01c958fd55f7b3b50896185ea610a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "|"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../assets/custom.css">
</head>

<body class="nav-sidebar docked nav-fixed slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../logo.jpg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Applied Soft Computing</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-toolkit--workflow" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Toolkit &amp; Workflow</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-toolkit--workflow">    
        <li class="dropdown-header">─── Module 1 ───</li>
        <li>
    <a class="dropdown-item" href="../m01-toolkit/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-toolkit/git-github.html">
 <span class="dropdown-text">Git &amp; GitHub</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-toolkit/tidy-data.html">
 <span class="dropdown-text">Tidy Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-toolkit/data-provenance.html">
 <span class="dropdown-text">Data Provenance</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-toolkit/environments.qmd">
 <span class="dropdown-text">Environments</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-visualization" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Visualization</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-visualization">    
        <li class="dropdown-header">─── Module 2 ───</li>
        <li>
    <a class="dropdown-item" href="../m02-visualization/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-visualization/principles.html">
 <span class="dropdown-text">Principles</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-visualization/dimensionality-reduction.html">
 <span class="dropdown-text">High-Dimensional Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-visualization/networks.html">
 <span class="dropdown-text">Networks</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-visualization/time-series.html">
 <span class="dropdown-text">Time-Series</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-deep-learning" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Deep Learning</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-deep-learning">    
        <li class="dropdown-header">─── Module 3: Text ───</li>
        <li>
    <a class="dropdown-item" href="../m03-text/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m03-text/word2vec.md">
 <span class="dropdown-text">Word2Vec</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m03-text/lstm.md">
 <span class="dropdown-text">RNNs &amp; LSTMs</span></a>
  </li>  
        <li class="dropdown-header">─── Module 4: Images ───</li>
        <li>
    <a class="dropdown-item" href="../m04-images/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m04-images/cnn.md">
 <span class="dropdown-text">CNNs</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m04-images/resnet.md">
 <span class="dropdown-text">ResNet</span></a>
  </li>  
        <li class="dropdown-header">─── Module 5: Graphs ───</li>
        <li>
    <a class="dropdown-item" href="../m05-graphs/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m05-graphs/graph-embedding-w-word2vec.html">
 <span class="dropdown-text">Graph Embeddings</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m05-graphs/graph-convolutional-network.html">
 <span class="dropdown-text">GNNs</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-advanced-topics" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Advanced Topics</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-advanced-topics">    
        <li class="dropdown-header">─── Module 6: LLMs ───</li>
        <li>
    <a class="dropdown-item" href="../m06-llms/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m06-llms/transformers.md">
 <span class="dropdown-text">Transformers</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m06-llms/scaling-emergence.html">
 <span class="dropdown-text">Scaling &amp; Emergence</span></a>
  </li>  
        <li class="dropdown-header">─── Module 7: Self-Supervised ───</li>
        <li>
    <a class="dropdown-item" href="../m07-self-supervised/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m07-self-supervised/contrastive-learning.html">
 <span class="dropdown-text">Contrastive Learning</span></a>
  </li>  
        <li class="dropdown-header">─── Module 8: Explainability ───</li>
        <li>
    <a class="dropdown-item" href="../m08-explainability/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m08-explainability/fairness.html">
 <span class="dropdown-text">Fairness &amp; Ethics</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../m02-visualization/overview.html">Module 2: Visualizing Complexity</a></li><li class="breadcrumb-item"><a href="../m02-visualization/highd-data.html">Visualizing High-Dimensional Data</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Course Information</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/welcome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About Us</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/why-applied-soft-computing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Why applied soft computing?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/discord.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Discord</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/minidora-usage.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Using Minidora</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/how-to-submit-assignment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to submit assignment</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/deliverables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deliverables</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 1: The Data Scientist’s Toolkit</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/git-github.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Version Control with Git &amp; GitHub</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/tidy-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Tidy Data Philosophy</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/data-provenance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Provenance</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-toolkit/reproduceability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Reproducibility</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 2: Visualizing Complexity</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Principles of Effective Visualization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/1d-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing 1D Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/2d-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing 2D Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/highd-data.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Visualizing High-Dimensional Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-visualization/time-series.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing Time-Series</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 3: Deep Learning for Text</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/tf-idf.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">TF-IDF: Bag-of-Words Representation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/word2vec.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word Embeddings (Word2Vec)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/word2vec_plus.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Word2Vec Techniques</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/sem-axis.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Semantic Axes &amp; Historical Bias</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/bias-in-embedding.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bias in Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/doc2vec.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Document Embeddings (Doc2Vec)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/reccurrent-neural-net.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recurrent Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/lstm.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LSTM Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/elmo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ELMo: Contextual Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/seq2seq.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sequence-to-Sequence Models</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 4: Deep Learning for Images</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/image-processing.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Processing Fundamentals</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/cnn.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Convolutional Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/lenet.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LeNet Architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/alexnet.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AlexNet: Deep CNN Revolution</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/vgg.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">VGG Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/inception.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Inception &amp; Multi-Scale Features</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/batch-normalization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Batch Normalization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/resnet.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ResNet &amp; Skip Connections</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 5: Deep Learning for Graphs</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/spectral-embedding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Spectral Graph Embedding</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/graph-embedding-w-word2vec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Graph Embeddings with Word2Vec</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/spectral-vs-neural-embedding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Spectral vs.&nbsp;Neural Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/from-image-to-graph.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">From Images to Graphs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/graph-convolutional-network.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Graph Convolutional Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/popular-gnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Popular GNN Architectures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-graphs/software.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GNN Software &amp; Tools</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 6: Large Language Models &amp; Emergent Behavior</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/transformers.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Transformer Architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/bert.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BERT &amp; Contextual Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/sentence-bert.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sentence-BERT for Semantic Similarity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/gpt.md" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GPT &amp; Generative Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/from-language-model-to-instruction-following.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">From Language Models to Instruction Following</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/prompt-tuning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prompt Engineering &amp; In-Context Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/scaling-emergence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Scaling Laws &amp; Emergent Abilities</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-llms/llms-as-complex-systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LLMs as Complex Systems</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 7: Self-Supervised Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-self-supervised/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-self-supervised/paradigm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Self-Supervised Paradigm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-self-supervised/contrastive-learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Contrastive Learning (SimCLR)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-self-supervised/graphs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Self-Supervised Learning for Graphs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-self-supervised/time-series.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Self-Supervised Learning for Time-Series</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">Module 8: Explainability &amp; Ethics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/need.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Need for Explainability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/attention.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Attention Visualization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/lime-shap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LIME &amp; SHAP</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/fairness.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Algorithmic Fairness &amp; Bias</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-explainability/causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Causality vs.&nbsp;Correlation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Legacy Materials</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/what-to-learn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word &amp; Document Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-text/what-to-learn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recurrent Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-images/what-to-learn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Processing (CNNs)</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../m02-visualization/overview.html">Module 2: Visualizing Complexity</a></li><li class="breadcrumb-item"><a href="../m02-visualization/highd-data.html">Visualizing High-Dimensional Data</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">High-Dimensional Data Visualization</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Sadamori Kojaku </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 17, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>Imagine you’re analyzing data with 50 features per observation: gene expression levels, user behavior metrics, or environmental measurements. You want to understand the patterns in your data. How do different observations relate to each other? Are there clusters? Outliers?</p>
<p>You can’t plot 50 dimensions directly. Our visual system lives in three dimensions (or really, two dimensions on a screen). This creates a fundamental challenge: <strong>how do you visualize data that lives in spaces you cannot see?</strong></p>
<p>The answer is dimensionality reduction—projecting high-dimensional data into 2 or 3 dimensions while preserving important structure. But here’s the critical question: <strong>what structure matters?</strong></p>
<p>Different methods preserve different aspects of your data. Some preserve global structure (how groups relate to each other across the entire dataset). Others preserve local structure (which points are nearest neighbors). Understanding these trade-offs is essential for choosing the right method—and for not being misled by beautiful but misleading visualizations.</p>
<section id="the-curse-of-dimensionality" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> The Curse of Dimensionality</h1>
<p>Before we dive into methods, we need to understand what makes high-dimensional data fundamentally different.</p>
<p>In high dimensions, <strong>everything is far from everything else</strong>. This sounds paradoxical, but it’s mathematically inevitable. As dimensions increase, the volume of space grows exponentially, and data points become increasingly sparse.</p>
<p>Consider this: in 1D, if you have 10 points uniformly distributed in [0, 1], the average distance between neighbors is about 0.1. To maintain the same density in 2D, you need 100 points. In 3D, you need 1,000 points. In 10D, you need 10 billion points.</p>
<p>Even stranger: in high dimensions, <strong>all distances become similar</strong>. The nearest and farthest neighbors become roughly equidistant. This makes many of our intuitions about “closeness” break down.</p>
<div id="f5741fc5" class="cell" data-fig-height="5" data-fig-width="10" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> euclidean_distances</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"white"</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate distance ratio across dimensions</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>dimensions <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>]</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>ratios <span class="op">=</span> []</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> d <span class="kw">in</span> dimensions:</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate random data</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> np.random.randn(n_samples, d)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate all pairwise distances</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    distances <span class="op">=</span> euclidean_distances(X)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For each point, find nearest and farthest (excluding self)</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    np.fill_diagonal(distances, np.inf)  <span class="co"># Ignore self-distance</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    nearest <span class="op">=</span> distances.<span class="bu">min</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For "farthest," ignore inf (self-distance), so set inf entries to -1 and use argmax</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    temp <span class="op">=</span> distances.copy()</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    temp[temp <span class="op">==</span> np.inf] <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>  <span class="co"># Now maximum is truly among finite values</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    farthest <span class="op">=</span> temp.<span class="bu">max</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate ratio</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    ratio <span class="op">=</span> nearest <span class="op">/</span> farthest</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    ratios.append(ratio)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(font_scale<span class="op">=</span><span class="fl">2.0</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"white"</span>)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>blue, red <span class="op">=</span> sns.color_palette(<span class="st">'muted'</span>, <span class="dv">2</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>positions <span class="op">=</span> <span class="bu">range</span>(<span class="bu">len</span>(dimensions))</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>bp <span class="op">=</span> ax.boxplot(ratios, positions<span class="op">=</span>positions, widths<span class="op">=</span><span class="fl">0.6</span>, patch_artist<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>                boxprops<span class="op">=</span><span class="bu">dict</span>(facecolor<span class="op">=</span><span class="st">"#f2f2f2"</span>, alpha<span class="op">=</span><span class="fl">0.7</span>))</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>ax.set_xticklabels(dimensions)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Number of Dimensions'</span>)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Nearest Distance / Farthest Distance'</span>)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'The Curse of Dimensionality: All Points Become Equidistant'</span>)</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>ax.axhline(y<span class="op">=</span><span class="fl">1.0</span>, color<span class="op">=</span>red, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Equal distances'</span>)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>ax.legend(frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>sns.despine()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="highd-data_files/figure-html/cell-2-output-1.png" class="img-fluid figure-img"></p>
<figcaption>As dimensions increase, the ratio of farthest to nearest distance approaches 1</figcaption>
</figure>
</div>
</div>
</div>
<p>In order words, dimensionality reduction is useful not just for visualization, but also for analysis. For example, when you want to cluster data points, every point is equidistant from every other point, so you can’t cluster them. By projecting the data into lower dimensions, you can remedy this curse of dimensionality.</p>
</section>
<section id="pairwise-scatter-plots-the-brute-force-approach" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Pairwise Scatter Plots: The Brute Force Approach</h1>
<p>When you have a <strong>moderate number of dimensions</strong> (roughly 3-10), you can visualize all pairwise relationships using a <strong>scatter plot matrix</strong> (also called a pairs plot or SPLOM).</p>
<div id="28d4b0cf" class="cell" data-fig-height="14" data-fig-width="14" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load classic iris dataset (4 dimensions)</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(font_scale<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"white"</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>iris <span class="op">=</span> load_iris()</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>iris_df <span class="op">=</span> pd.DataFrame(iris.data, columns<span class="op">=</span>iris.feature_names)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>iris_df[<span class="st">'species'</span>] <span class="op">=</span> iris.target</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>iris_df[<span class="st">'species'</span>] <span class="op">=</span> iris_df[<span class="st">'species'</span>].<span class="bu">map</span>({<span class="dv">0</span>: <span class="st">'setosa'</span>, <span class="dv">1</span>: <span class="st">'versicolor'</span>, <span class="dv">2</span>: <span class="st">'virginica'</span>})</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create pairplot</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sns.pairplot(iris_df, hue<span class="op">=</span><span class="st">'species'</span>, diag_kind<span class="op">=</span><span class="st">'kde'</span>,</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>                 plot_kws<span class="op">=</span>{<span class="st">'alpha'</span>: <span class="fl">0.6</span>, <span class="st">'s'</span>: <span class="dv">50</span>, <span class="st">'edgecolor'</span>: <span class="st">'white'</span>, <span class="st">'linewidth'</span>: <span class="fl">0.5</span>},</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>                 diag_kws<span class="op">=</span>{<span class="st">'alpha'</span>: <span class="fl">0.7</span>, <span class="st">'linewidth'</span>: <span class="dv">2</span>})</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>g.fig.suptitle(<span class="st">'Iris Dataset: All Pairwise Relationships'</span>, y<span class="op">=</span><span class="fl">1.01</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="385">
<pre><code>Text(0.5, 1.01, 'Iris Dataset: All Pairwise Relationships')</code></pre>
<p>Scatter plot matrix showing all pairwise relationships in the Iris dataset</p>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="highd-data_files/figure-html/cell-3-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The scatter plot matrix shows every possible 2D projection. The diagonal shows the univariate distribution of each feature (using KDE here), and off-diagonals show bivariate scatter plots.</p>
<p>The problem: scatter plot matrices don’t scale. With 10 variables, you have 45 unique pairwise plots—manageable but crowded. With 20 variables, you have 190 plots—overwhelming. And you’re still only seeing 2D projections, never the full high-dimensional structure.</p>
<p>This is where dimensionality reduction becomes essential.</p>
</section>
<section id="linear-dimensionality-reduction-pca" class="level1 page-columns page-full" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Linear Dimensionality Reduction: PCA</h1>
<p><strong>Principal Component Analysis (PCA)</strong> is a linear dimensionality reduction method that finds the directions of maximum variance in your data.</p>
<p>Imagine you have a cloud of points in high-dimensional space. PCA asks: “What direction captures the most variation in the data?” This becomes the first principal component (PC1). Then it asks: “What direction, perpendicular to the first, captures the most remaining variation?” This becomes PC2. And so on.</p>
<p>Mathematically, PCA finds the eigenvectors of the covariance matrix. But conceptually, it’s rotating your coordinate system to align with the the highest variance directions of your data.</p>
<div id="a13fb021" class="cell" data-fig-height="6" data-fig-width="10" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate correlated 2D data (for visualization)</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>cov <span class="op">=</span> [[<span class="dv">3</span>, <span class="dv">2</span>], [<span class="dv">2</span>, <span class="dv">2</span>]]</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>data_2d <span class="op">=</span> np.random.multivariate_normal(mean, cov, <span class="dv">300</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit PCA</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>pca.fit(data_2d)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">"#f2f2f2"</span>, sns.color_palette(<span class="st">'muted'</span>)[<span class="dv">0</span>], sns.color_palette(<span class="st">'muted'</span>)[<span class="dv">3</span>]]</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot original data with principal components</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>ax.scatter(data_2d[:, <span class="dv">0</span>], data_2d[:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.9</span>, s<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span>colors[<span class="dv">0</span>], edgecolors<span class="op">=</span><span class="st">'k'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw principal components as arrows</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>origin <span class="op">=</span> pca.mean_</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (component, variance) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(pca.components_, pca.explained_variance_)):</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    direction <span class="op">=</span> component <span class="op">*</span> np.sqrt(variance) <span class="op">*</span> <span class="dv">3</span>  <span class="co"># Scale for visibility</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    ax.arrow(origin[<span class="dv">0</span>], origin[<span class="dv">1</span>], direction[<span class="dv">0</span>], direction[<span class="dv">1</span>],</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>             head_width<span class="op">=</span><span class="fl">0.3</span>, head_length<span class="op">=</span><span class="fl">0.3</span>, fc<span class="op">=</span>colors[i<span class="op">+</span><span class="dv">1</span>], ec<span class="op">=</span>colors[i<span class="op">+</span><span class="dv">1</span>], linewidth<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>             label<span class="op">=</span><span class="ss">f'PC</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>variance<span class="op">/</span>pca<span class="sc">.</span>explained_variance_<span class="sc">.</span><span class="bu">sum</span>()<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%)'</span>)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Original X'</span>)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Original Y'</span>)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Principal Components: Directions of Maximum Variance'</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>ax.axis(<span class="st">'equal'</span>)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>sns.despine()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="highd-data_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></p>
<figcaption>PCA finds directions of maximum variance. PC1 captures the most variation, PC2 the next most (perpendicular to PC1).</figcaption>
</figure>
</div>
</div>
</div>
<p>PC1 (orange arrow) points along the direction of greatest spread. PC2 (green arrow) is perpendicular and captures the remaining variation.</p>
<p>The percentage in parentheses shows how much variance each component explains. If PC1 explains 90% of variance, then projecting onto just PC1 preserves most of your data’s structure.</p>
<section id="applying-pca-to-iris" class="level2 page-columns page-full" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="applying-pca-to-iris"><span class="header-section-number">3.1</span> Applying PCA to Iris</h2>
<p>Let’s apply PCA to the 4-dimensional Iris dataset:</p>
<div id="d3a0d6cd" class="cell" data-fig-height="6" data-fig-width="14" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> iris.data</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> iris.target</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize (important for PCA!)</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PCA</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X_scaled)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataFrame for plotting</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>pca_df <span class="op">=</span> pd.DataFrame(X_pca, columns<span class="op">=</span>[<span class="st">'PC1'</span>, <span class="st">'PC2'</span>])</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>pca_df[<span class="st">'species'</span>] <span class="op">=</span> iris.target_names[y]</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">6</span>))</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Left: PCA projection</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> species, color <span class="kw">in</span> <span class="bu">zip</span>([<span class="st">'setosa'</span>, <span class="st">'versicolor'</span>, <span class="st">'virginica'</span>], sns.color_palette(<span class="st">'muted'</span>, <span class="dv">3</span>)):</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> pca_df[<span class="st">'species'</span>] <span class="op">==</span> species</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].scatter(pca_df.loc[mask, <span class="st">'PC1'</span>], pca_df.loc[mask, <span class="st">'PC2'</span>],</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>                   label<span class="op">=</span>species, alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span>color, edgecolors<span class="op">=</span><span class="st">'white'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="ss">f'PC1 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">0</span>]<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">% variance)'</span>)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="ss">f'PC2 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">1</span>]<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">% variance)'</span>)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'PCA Projection of Iris Dataset'</span>)</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Right: Variance explained</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>variances <span class="op">=</span> pca.explained_variance_ratio_</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].bar([<span class="dv">1</span>, <span class="dv">2</span>], variances, color<span class="op">=</span>sns.color_palette(<span class="st">'muted'</span>, <span class="dv">2</span>), alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Principal Component'</span>)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Variance Explained'</span>)</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Variance Explained by Each Component'</span>)</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xticks([<span class="dv">1</span>, <span class="dv">2</span>])</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xticklabels([<span class="st">'PC1'</span>, <span class="st">'PC2'</span>])</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, v <span class="kw">in</span> <span class="bu">enumerate</span>(variances):</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].text(i<span class="op">+</span><span class="dv">1</span>, v<span class="op">+</span><span class="fl">0.01</span>, <span class="ss">f'</span><span class="sc">{</span>v<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="highd-data_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
<figcaption>PCA projection of Iris dataset to 2D preserves the separation between species</figcaption>
</figure>
</div>
</div>
</div>
<p>PC1 and PC2 together explain over 95% of the variance in the 4D dataset. The 2D projection preserves the main structure: setosa is well-separated, while versicolor and virginica have some overlap.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Always standardize before PCA!</strong> If features have different units or scales, PCA will be dominated by high-variance features. Standardization (zero mean, unit variance) ensures all features contribute fairly.</p>
</div></div></section>
</section>
<section id="non-linear-dimensionality-reduction" class="level1 page-columns page-full" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Non-Linear Dimensionality Reduction</h1>
<section id="multidimensional-scaling-mds" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="multidimensional-scaling-mds"><span class="header-section-number">4.1</span> Multidimensional Scaling (MDS)</h2>
<p><strong>Multidimensional Scaling (MDS)</strong> takes a different approach: instead of finding directions of maximum variance, it tries to <strong>preserve distances between points</strong>.</p>
<p>You give MDS a distance matrix—the distance between every pair of points in high-dimensional space—and it finds a low-dimensional configuration where those distances are preserved as well as possible.</p>
<p>Think of it like arranging cities on a map. You know the distance between every pair of cities, but not their coordinates. MDS finds positions that preserve those distances.</p>
<p>Mathematically, MDS minimizes <strong>stress</strong>: the difference between high-dimensional distances and low-dimensional distances. Classical MDS has a closed-form solution (like PCA), but more flexible variants use iterative optimization.</p>
<div id="15f5d9e3" class="cell" data-fig-height="6" data-fig-width="14" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> MDS</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Suppress FutureWarning about n_init in MDS</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>mds <span class="op">=</span> MDS(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>X_mds <span class="op">=</span> mds.fit_transform(X_scaled)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PCA</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X_scaled)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataFrame</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>mds_df <span class="op">=</span> pd.DataFrame(X_mds, columns<span class="op">=</span>[<span class="st">'MDS1'</span>, <span class="st">'MDS2'</span>])</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>mds_df[<span class="st">'species'</span>] <span class="op">=</span> iris.target_names[y]</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot both</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">6</span>))</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> species, color <span class="kw">in</span> <span class="bu">zip</span>([<span class="st">'setosa'</span>, <span class="st">'versicolor'</span>, <span class="st">'virginica'</span>], sns.color_palette(<span class="st">'muted'</span>, <span class="dv">3</span>)):</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> pca_df[<span class="st">'species'</span>] <span class="op">==</span> species</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].scatter(pca_df.loc[mask, <span class="st">'PC1'</span>], pca_df.loc[mask, <span class="st">'PC2'</span>],</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>                   label<span class="op">=</span>species, alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span>color, edgecolors<span class="op">=</span><span class="st">'white'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'PC1'</span>)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'PC2'</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'PCA: Maximizes Variance'</span>)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="co"># MDS</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> species, color <span class="kw">in</span> <span class="bu">zip</span>([<span class="st">'setosa'</span>, <span class="st">'versicolor'</span>, <span class="st">'virginica'</span>], sns.color_palette(<span class="st">'muted'</span>, <span class="dv">3</span>)):</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> mds_df[<span class="st">'species'</span>] <span class="op">==</span> species</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].scatter(mds_df.loc[mask, <span class="st">'MDS1'</span>], mds_df.loc[mask, <span class="st">'MDS2'</span>],</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>                   label<span class="op">=</span>species, alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span>color, edgecolors<span class="op">=</span><span class="st">'white'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'MDS1'</span>)</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'MDS2'</span>)</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'MDS: Preserves Distances'</span>)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend()</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="highd-data_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
<figcaption>MDS vs PCA on Iris dataset. MDS preserves distances better but looks similar to PCA for this dataset.</figcaption>
</figure>
</div>
</div>
</div>
<p>For the Iris dataset, PCA and MDS look very similar. This is because Iris data is fairly linear—the relationships between features don’t involve complex curves or non-linear structures.</p>
</section>
<section id="isomap" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="isomap"><span class="header-section-number">4.2</span> Isomap</h2>
<p>MDS preserves Euclidean distances—straight-line distances through space. But for curved manifolds, what matters is the <strong>geodesic distance</strong>: the distance along the surface.</p>
<p><strong>Isomap</strong> (Isometric Mapping) addresses this by approximating geodesic distances using the neighborhood graph:</p>
<ol type="1">
<li><strong>Build a neighborhood graph</strong>: Connect each point to its k nearest neighbors</li>
<li><strong>Compute shortest paths</strong>: The geodesic distance between points is approximated by the shortest path through this graph</li>
<li><strong>Apply classical MDS</strong>: Use MDS on these geodesic distances instead of Euclidean distances</li>
</ol>
<p>Think of it like this: MDS measures distance “as the crow flies,” while Isomap measures distance “as you walk along the surface.”</p>
<div id="e88969d2" class="cell" data-fig-height="6" data-fig-width="14" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> Isomap</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_s_curve</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate S-curve data (a 2D manifold embedded in 3D)</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>X_scurve, color <span class="op">=</span> make_s_curve(n_samples, noise<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply Isomap</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>isomap <span class="op">=</span> Isomap(n_components<span class="op">=</span><span class="dv">2</span>, n_neighbors<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>X_scurve_isomap <span class="op">=</span> isomap.fit_transform(X_scurve)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PCA</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>X_scurve_pca <span class="op">=</span> pca.fit_transform(X_scurve)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply MDS</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>mds <span class="op">=</span> MDS(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>X_scurve_mds <span class="op">=</span> mds.fit_transform(X_scurve)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot MDS vs Isomap vs PCA</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">6</span>))</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(X_scurve_pca[:, <span class="dv">0</span>], X_scurve_pca[:, <span class="dv">1</span>], c<span class="op">=</span>color,</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>                cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'PC1'</span>)</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'PC2'</span>)</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'PCA: Global Variance'</span>)</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a><span class="co"># MDS</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(X_scurve_mds[:, <span class="dv">0</span>], X_scurve_mds[:, <span class="dv">1</span>], c<span class="op">=</span>color,</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>                cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'MDS1'</span>)</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'MDS2'</span>)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'MDS: Global Distances'</span>)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Isomap</span></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].scatter(X_scurve_isomap[:, <span class="dv">0</span>], X_scurve_isomap[:, <span class="dv">1</span>], c<span class="op">=</span>color,</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>                cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">'Isomap1'</span>)</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylabel(<span class="st">'Isomap2'</span>)</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'Isomap: Geodesic Distances'</span>)</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">2</span>])</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="highd-data_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
<figcaption>Isomap uses geodesic distances (along the surface) instead of Euclidean distances (through space), better recovering the S-curve structure</figcaption>
</figure>
</div>
</div>
</div>
<p>Isomap successfully “straightens” the S-curve because it respects the manifold structure. By computing distances along the neighborhood graph, it avoids the shortcuts across the bend that confused MDS.</p>
</section>
<section id="t-sne" class="level2 page-columns page-full" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="t-sne"><span class="header-section-number">4.3</span> t-SNE</h2>
<p><strong>t-SNE</strong> (t-Distributed Stochastic Neighbor Embedding) takes a middle ground between MDS’s global approach and Isomap’s geodesic approach: it <strong>prioritizes local structure</strong> while allowing some flexibility in global positioning.</p>
<p>The key insight: for visualization, we often care most about <strong>which points are neighbors</strong>. Whether distant clusters are placed left vs right, or how far apart they are, matters less than preserving the local neighborhood relationships within and between clusters.</p>
<p>t-SNE converts distances into similarity probabilities and preserves these local relationships:</p>
<ol type="1">
<li><strong>In high dimensions</strong>: Define probability <span class="math inline">p_{ij}</span> that point <span class="math inline">i</span> picks point <span class="math inline">j</span> as a neighbor (based on Gaussian distance)</li>
<li><strong>In low dimensions</strong>: Define similar probability <span class="math inline">q_{ij}</span> using a t-distribution with heavy tails</li>
<li><strong>Optimize</strong>: Move points in 2D to make <span class="math inline">q_{ij}</span> match <span class="math inline">p_{ij}</span> (minimize KL divergence)</li>
</ol>
<p>The t-distribution’s heavy tails are clever: they let well-separated clusters spread out in 2D without overlapping, while keeping local neighborhoods tight.</p>
<div id="c19405a9" class="cell" data-fig-height="5" data-fig-width="15" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply t-SNE</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, perplexity<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>X_scurve_tsne <span class="op">=</span> tsne.fit_transform(X_scurve)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot all three methods</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># MDS - Global Euclidean distances</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(X_scurve_pca[:, <span class="dv">0</span>], X_scurve_pca[:, <span class="dv">1</span>], c<span class="op">=</span>color,</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>                cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'PC1'</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'PC2'</span>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'PCA: Global Variance'</span>)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Isomap - Geodesic distances</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(X_scurve_isomap[:, <span class="dv">0</span>], X_scurve_isomap[:, <span class="dv">1</span>], c<span class="op">=</span>color,</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>                cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Isomap1'</span>)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Isomap2'</span>)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Isomap: Geodesic Distances'</span>)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a><span class="co"># t-SNE - Local neighborhoods</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].scatter(X_scurve_tsne[:, <span class="dv">0</span>], X_scurve_tsne[:, <span class="dv">1</span>], c<span class="op">=</span>color,</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>                cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">'t-SNE1'</span>)</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylabel(<span class="st">'t-SNE2'</span>)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'t-SNE: Local Structure'</span>)</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">2</span>])</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="highd-data_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
<figcaption>Comparing global, geodesic, and local approaches on the S-curve</figcaption>
</figure>
</div>
</div>
</div>
<p>All three methods successfully straighten the S-curve, but through different philosophies: MDS compromises between all distances, Isomap follows the manifold globally, and t-SNE focuses on preserving neighborhoods.</p>
<p><strong>Perplexity</strong> (typically 30-50) controls the effective neighborhood size. Too low fragments clusters; too high loses local detail.</p>
<p>t-SNE is powerful but has important limitations.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Don’t over-interpret t-SNE!
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>You cannot conclude</strong> from a t-SNE plot:</p>
<ul>
<li>“Cluster A is twice as far from B as from C” (distances are not preserved)</li>
<li>“Cluster A is twice the size of B” (sizes are not preserved)</li>
<li>“The data has exactly 5 clusters” (apparent clusters may be visualization artifacts)</li>
</ul>
<p><strong>You can conclude:</strong></p>
<ul>
<li>“These points form a distinct group separate from others”</li>
<li>“These points are more similar to each other than to distant points”</li>
<li>“The data has local structure and is not uniformly random”</li>
</ul>
</div>
</div>
<p>Let’s apply t-SNE to a more realistic high-dimensional dataset—the MNIST digits dataset, which has 784 dimensions (28�28 pixel images):</p>
<div id="fdac9a19" class="cell" data-fig-height="10" data-fig-width="12" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_digits</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load digits dataset (8x8 images, 64 dimensions - a smaller version of MNIST)</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>digits <span class="op">=</span> load_digits()</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>X_digits <span class="op">=</span> digits.data</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>y_digits <span class="op">=</span> digits.target</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Take a subset for speed (t-SNE is slow on large datasets)</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> np.random.choice(<span class="bu">len</span>(X_digits), size<span class="op">=</span><span class="dv">1000</span>, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>X_subset <span class="op">=</span> X_digits[indices]</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>y_subset <span class="op">=</span> y_digits[indices]</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply t-SNE</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>tsne_digits <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, perplexity<span class="op">=</span><span class="dv">40</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>X_digits_tsne <span class="op">=</span> tsne_digits.fit_transform(X_subset)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> ax.scatter(X_digits_tsne[:, <span class="dv">0</span>], X_digits_tsne[:, <span class="dv">1</span>],</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>                     c<span class="op">=</span>y_subset, cmap<span class="op">=</span><span class="st">'tab10'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'t-SNE1'</span>)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'t-SNE2'</span>)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'t-SNE Visualization of Handwritten Digits (64D � 2D)'</span>)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>cbar <span class="op">=</span> plt.colorbar(scatter, ax<span class="op">=</span>ax, ticks<span class="op">=</span><span class="bu">range</span>(<span class="dv">10</span>))</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>cbar.set_label(<span class="st">'Digit Class'</span>)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>sns.despine()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/skojaku-admin/miniforge3/envs/advnetsci/lib/python3.11/site-packages/IPython/core/events.py:82: UserWarning: Glyph 65533 (\N{REPLACEMENT CHARACTER}) missing from font(s) Arial.
  func(*args, **kwargs)
/Users/skojaku-admin/miniforge3/envs/advnetsci/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 65533 (\N{REPLACEMENT CHARACTER}) missing from font(s) Arial.
  fig.canvas.print_figure(bytes_io, **kw)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="highd-data_files/figure-html/cell-9-output-2.png" class="img-fluid figure-img"></p>
<figcaption>t-SNE visualization of MNIST digits (784 dimensions x 2D). Each color represents a digit class.</figcaption>
</figure>
</div>
</div>
</div>
<p>The t-SNE projection beautifully separates most digit classes. Digits that look similar (like 3, 5, and 8, or 4 and 9) cluster near each other, while visually distinct digits (like 0 and 1) are well separated.</p>
<p>This demonstrates t-SNE’s power: from 64 dimensions with no explicit information about what makes digits similar, t-SNE discovers the perceptual structure of handwritten digits.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>t-SNE is stochastic</strong>: Different runs produce different layouts (though cluster structure remains consistent). Always check multiple runs with different random seeds, especially for important scientific conclusions.</p>
</div></div></section>
<section id="umap" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="umap"><span class="header-section-number">4.4</span> UMAP</h2>
<p><strong>Uniform Manifold Approximation and Projection (UMAP)</strong> is a newer method (2018) that has become popular as an alternative to t-SNE. Like t-SNE, UMAP preserves local structure, but it’s based on different mathematical foundations (manifold learning and topological data analysis).</p>
<div id="181e3dd8" class="cell" data-fig-height="6" data-fig-width="14" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> umap</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply UMAP</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>umap_model <span class="op">=</span> umap.UMAP(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, n_neighbors<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>X_digits_umap <span class="op">=</span> umap_model.fit_transform(X_subset)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot comparison</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">6</span>))</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co"># t-SNE</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> axes[<span class="dv">0</span>].scatter(X_digits_tsne[:, <span class="dv">0</span>], X_digits_tsne[:, <span class="dv">1</span>],</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>                          c<span class="op">=</span>y_subset, cmap<span class="op">=</span><span class="st">'tab10'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'t-SNE1'</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'t-SNE2'</span>)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'t-SNE'</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="co"># UMAP</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> axes[<span class="dv">1</span>].scatter(X_digits_umap[:, <span class="dv">0</span>], X_digits_umap[:, <span class="dv">1</span>],</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>                          c<span class="op">=</span>y_subset, cmap<span class="op">=</span><span class="st">'tab10'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'UMAP1'</span>)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'UMAP2'</span>)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'UMAP'</span>)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>cbar <span class="op">=</span> plt.colorbar(scatter, ax<span class="op">=</span>axes[<span class="dv">1</span>], ticks<span class="op">=</span><span class="bu">range</span>(<span class="dv">10</span>))</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>cbar.set_label(<span class="st">'Digit Class'</span>)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/skojaku-admin/miniforge3/envs/advnetsci/lib/python3.11/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="highd-data_files/figure-html/cell-10-output-2.png" class="img-fluid figure-img"></p>
<figcaption>UMAP vs t-SNE on digits dataset. UMAP often preserves more global structure while being much faster.</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="the-bigger-picture" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> The Bigger Picture</h1>
<p>Dimensionality reduction is not a one-size-fits-all solution. Different methods make different trade-offs:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 21%">
<col style="width: 13%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Preserves</th>
<th>Speed</th>
<th>Scalability</th>
<th>When to use</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Scatter plot matrix</strong></td>
<td>Everything (2D projections)</td>
<td>Fast</td>
<td>3-10 dimensions</td>
<td>Exploring moderate-dimensional data</td>
</tr>
<tr class="even">
<td><strong>PCA</strong></td>
<td>Global variance</td>
<td>Very fast</td>
<td>Excellent (1000s of dims)</td>
<td>Linear structure, interpretability needed</td>
</tr>
<tr class="odd">
<td><strong>MDS</strong></td>
<td>All distances</td>
<td>Slow</td>
<td>Poor (100s of points)</td>
<td>Distance preservation critical</td>
</tr>
<tr class="even">
<td><strong>t-SNE</strong></td>
<td>Local structure</td>
<td>Slow</td>
<td>Moderate (10,000s of points)</td>
<td>Revealing clusters, local relationships</td>
</tr>
<tr class="odd">
<td><strong>UMAP</strong></td>
<td>Local + some global</td>
<td>Fast</td>
<td>Excellent (millions of points)</td>
<td>Large datasets, faster alternative to t-SNE</td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Beware of visualization artifacts
</div>
</div>
<div class="callout-body-container callout-body">
<p>Dimensionality reduction can create apparent patterns that don’t exist in the original data:</p>
<ul>
<li><strong>Spurious clusters</strong>: t-SNE can split continuous data into false clusters</li>
<li><strong>Missing relationships</strong>: Two clusters might be connected in high dimensions but appear separated in 2D</li>
<li><strong>Misleading distances</strong>: Distance and size in t-SNE/UMAP are not meaningful</li>
</ul>
<p><strong>Always validate</strong> important findings with statistical tests or domain knowledge. A beautiful t-SNE plot is a starting point for investigation, not a final conclusion.</p>
</div>
</div>
<p>Visualizing high-dimensional data is as much art as science. The goal is not to find “the true projection”—there is no single true way to flatten high-dimensional space onto a page. The goal is to <strong>reveal structure that helps you understand your data and ask better questions</strong>.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../m02-visualization/2d-data.html" class="pagination-link" aria-label="Visualizing 2D Data">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Visualizing 2D Data</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../m02-visualization/networks.html" class="pagination-link" aria-label="Visualizing Networks">
        <span class="nav-page-text">Visualizing Networks</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb13" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "High-Dimensional Data Visualization"</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> advnetsci</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co">    enabled: true</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>Imagine you're analyzing data with 50 features per observation: gene expression levels, user behavior metrics, or environmental measurements. You want to understand the patterns in your data. How do different observations relate to each other? Are there clusters? Outliers?</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>You can't plot 50 dimensions directly. Our visual system lives in three dimensions (or really, two dimensions on a screen). This creates a fundamental challenge: **how do you visualize data that lives in spaces you cannot see?**</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>The answer is dimensionality reduction---projecting high-dimensional data into 2 or 3 dimensions while preserving important structure. But here's the critical question: **what structure matters?**</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>Different methods preserve different aspects of your data. Some preserve global structure (how groups relate to each other across the entire dataset). Others preserve local structure (which points are nearest neighbors). Understanding these trade-offs is essential for choosing the right method---and for not being misled by beautiful but misleading visualizations.</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="fu"># The Curse of Dimensionality</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>Before we dive into methods, we need to understand what makes high-dimensional data fundamentally different.</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>In high dimensions, **everything is far from everything else**. This sounds paradoxical, but it's mathematically inevitable. As dimensions increase, the volume of space grows exponentially, and data points become increasingly sparse.</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>Consider this: in 1D, if you have 10 points uniformly distributed in <span class="co">[</span><span class="ot">0, 1</span><span class="co">]</span>, the average distance between neighbors is about 0.1. To maintain the same density in 2D, you need 100 points. In 3D, you need 1,000 points. In 10D, you need 10 billion points.</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>Even stranger: in high dimensions, **all distances become similar**. The nearest and farthest neighbors become roughly equidistant. This makes many of our intuitions about "closeness" break down.</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "As dimensions increase, the ratio of farthest to nearest distance approaches 1"</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 10</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> euclidean_distances</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"white"</span>)</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate distance ratio across dimensions</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>dimensions <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>]</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>ratios <span class="op">=</span> []</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> d <span class="kw">in</span> dimensions:</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate random data</span></span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> np.random.randn(n_samples, d)</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate all pairwise distances</span></span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>    distances <span class="op">=</span> euclidean_distances(X)</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For each point, find nearest and farthest (excluding self)</span></span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>    np.fill_diagonal(distances, np.inf)  <span class="co"># Ignore self-distance</span></span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>    nearest <span class="op">=</span> distances.<span class="bu">min</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For "farthest," ignore inf (self-distance), so set inf entries to -1 and use argmax</span></span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>    temp <span class="op">=</span> distances.copy()</span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>    temp[temp <span class="op">==</span> np.inf] <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>  <span class="co"># Now maximum is truly among finite values</span></span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>    farthest <span class="op">=</span> temp.<span class="bu">max</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate ratio</span></span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>    ratio <span class="op">=</span> nearest <span class="op">/</span> farthest</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>    ratios.append(ratio)</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(font_scale<span class="op">=</span><span class="fl">2.0</span>)</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"white"</span>)</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>blue, red <span class="op">=</span> sns.color_palette(<span class="st">'muted'</span>, <span class="dv">2</span>)</span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>positions <span class="op">=</span> <span class="bu">range</span>(<span class="bu">len</span>(dimensions))</span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>bp <span class="op">=</span> ax.boxplot(ratios, positions<span class="op">=</span>positions, widths<span class="op">=</span><span class="fl">0.6</span>, patch_artist<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a>                boxprops<span class="op">=</span><span class="bu">dict</span>(facecolor<span class="op">=</span><span class="st">"#f2f2f2"</span>, alpha<span class="op">=</span><span class="fl">0.7</span>))</span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a>ax.set_xticklabels(dimensions)</span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Number of Dimensions'</span>)</span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Nearest Distance / Farthest Distance'</span>)</span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'The Curse of Dimensionality: All Points Become Equidistant'</span>)</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>ax.axhline(y<span class="op">=</span><span class="fl">1.0</span>, color<span class="op">=</span>red, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Equal distances'</span>)</span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a>ax.legend(frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>sns.despine()</span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a>In order words, dimensionality reduction is useful not just for visualization, but also for analysis. For example, when you want to cluster data points, every point is equidistant from every other point, so you can't cluster them. By projecting the data into lower dimensions, you can remedy this curse of dimensionality.</span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a><span class="fu"># Pairwise Scatter Plots: The Brute Force Approach</span></span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a>When you have a **moderate number of dimensions** (roughly 3-10), you can visualize all pairwise relationships using a **scatter plot matrix** (also called a pairs plot or SPLOM).</span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Scatter plot matrix showing all pairwise relationships in the Iris dataset"</span></span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 14</span></span>
<span id="cb13-93"><a href="#cb13-93" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 14</span></span>
<span id="cb13-94"><a href="#cb13-94" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb13-95"><a href="#cb13-95" aria-hidden="true" tabindex="-1"></a><span class="co"># Load classic iris dataset (4 dimensions)</span></span>
<span id="cb13-96"><a href="#cb13-96" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb13-97"><a href="#cb13-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-98"><a href="#cb13-98" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(font_scale<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb13-99"><a href="#cb13-99" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"white"</span>)</span>
<span id="cb13-100"><a href="#cb13-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-101"><a href="#cb13-101" aria-hidden="true" tabindex="-1"></a>iris <span class="op">=</span> load_iris()</span>
<span id="cb13-102"><a href="#cb13-102" aria-hidden="true" tabindex="-1"></a>iris_df <span class="op">=</span> pd.DataFrame(iris.data, columns<span class="op">=</span>iris.feature_names)</span>
<span id="cb13-103"><a href="#cb13-103" aria-hidden="true" tabindex="-1"></a>iris_df[<span class="st">'species'</span>] <span class="op">=</span> iris.target</span>
<span id="cb13-104"><a href="#cb13-104" aria-hidden="true" tabindex="-1"></a>iris_df[<span class="st">'species'</span>] <span class="op">=</span> iris_df[<span class="st">'species'</span>].<span class="bu">map</span>({<span class="dv">0</span>: <span class="st">'setosa'</span>, <span class="dv">1</span>: <span class="st">'versicolor'</span>, <span class="dv">2</span>: <span class="st">'virginica'</span>})</span>
<span id="cb13-105"><a href="#cb13-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-106"><a href="#cb13-106" aria-hidden="true" tabindex="-1"></a><span class="co"># Create pairplot</span></span>
<span id="cb13-107"><a href="#cb13-107" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sns.pairplot(iris_df, hue<span class="op">=</span><span class="st">'species'</span>, diag_kind<span class="op">=</span><span class="st">'kde'</span>,</span>
<span id="cb13-108"><a href="#cb13-108" aria-hidden="true" tabindex="-1"></a>                 plot_kws<span class="op">=</span>{<span class="st">'alpha'</span>: <span class="fl">0.6</span>, <span class="st">'s'</span>: <span class="dv">50</span>, <span class="st">'edgecolor'</span>: <span class="st">'white'</span>, <span class="st">'linewidth'</span>: <span class="fl">0.5</span>},</span>
<span id="cb13-109"><a href="#cb13-109" aria-hidden="true" tabindex="-1"></a>                 diag_kws<span class="op">=</span>{<span class="st">'alpha'</span>: <span class="fl">0.7</span>, <span class="st">'linewidth'</span>: <span class="dv">2</span>})</span>
<span id="cb13-110"><a href="#cb13-110" aria-hidden="true" tabindex="-1"></a>g.fig.suptitle(<span class="st">'Iris Dataset: All Pairwise Relationships'</span>, y<span class="op">=</span><span class="fl">1.01</span>)</span>
<span id="cb13-111"><a href="#cb13-111" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-112"><a href="#cb13-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-113"><a href="#cb13-113" aria-hidden="true" tabindex="-1"></a>The scatter plot matrix shows every possible 2D projection. The diagonal shows the univariate distribution of each feature (using KDE here), and off-diagonals show bivariate scatter plots.</span>
<span id="cb13-114"><a href="#cb13-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-115"><a href="#cb13-115" aria-hidden="true" tabindex="-1"></a>The problem: scatter plot matrices don't scale. With 10 variables, you have 45 unique pairwise plots---manageable but crowded. With 20 variables, you have 190 plots---overwhelming. And you're still only seeing 2D projections, never the full high-dimensional structure.</span>
<span id="cb13-116"><a href="#cb13-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-117"><a href="#cb13-117" aria-hidden="true" tabindex="-1"></a>This is where dimensionality reduction becomes essential.</span>
<span id="cb13-118"><a href="#cb13-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-119"><a href="#cb13-119" aria-hidden="true" tabindex="-1"></a><span class="fu"># Linear Dimensionality Reduction: PCA</span></span>
<span id="cb13-120"><a href="#cb13-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-121"><a href="#cb13-121" aria-hidden="true" tabindex="-1"></a>**Principal Component Analysis (PCA)** is a linear dimensionality reduction method that finds the directions of maximum variance in your data.</span>
<span id="cb13-122"><a href="#cb13-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-123"><a href="#cb13-123" aria-hidden="true" tabindex="-1"></a>Imagine you have a cloud of points in high-dimensional space. PCA asks: "What direction captures the most variation in the data?" This becomes the first principal component (PC1). Then it asks: "What direction, perpendicular to the first, captures the most remaining variation?" This becomes PC2. And so on.</span>
<span id="cb13-124"><a href="#cb13-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-125"><a href="#cb13-125" aria-hidden="true" tabindex="-1"></a>Mathematically, PCA finds the eigenvectors of the covariance matrix. But conceptually, it's rotating your coordinate system to align with the the highest variance directions of your data.</span>
<span id="cb13-126"><a href="#cb13-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-129"><a href="#cb13-129" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-130"><a href="#cb13-130" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "PCA finds directions of maximum variance. PC1 captures the most variation, PC2 the next most (perpendicular to PC1)."</span></span>
<span id="cb13-131"><a href="#cb13-131" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 10</span></span>
<span id="cb13-132"><a href="#cb13-132" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 6</span></span>
<span id="cb13-133"><a href="#cb13-133" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb13-134"><a href="#cb13-134" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb13-135"><a href="#cb13-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-136"><a href="#cb13-136" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate correlated 2D data (for visualization)</span></span>
<span id="cb13-137"><a href="#cb13-137" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb13-138"><a href="#cb13-138" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb13-139"><a href="#cb13-139" aria-hidden="true" tabindex="-1"></a>cov <span class="op">=</span> [[<span class="dv">3</span>, <span class="dv">2</span>], [<span class="dv">2</span>, <span class="dv">2</span>]]</span>
<span id="cb13-140"><a href="#cb13-140" aria-hidden="true" tabindex="-1"></a>data_2d <span class="op">=</span> np.random.multivariate_normal(mean, cov, <span class="dv">300</span>)</span>
<span id="cb13-141"><a href="#cb13-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-142"><a href="#cb13-142" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit PCA</span></span>
<span id="cb13-143"><a href="#cb13-143" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-144"><a href="#cb13-144" aria-hidden="true" tabindex="-1"></a>pca.fit(data_2d)</span>
<span id="cb13-145"><a href="#cb13-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-146"><a href="#cb13-146" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">"#f2f2f2"</span>, sns.color_palette(<span class="st">'muted'</span>)[<span class="dv">0</span>], sns.color_palette(<span class="st">'muted'</span>)[<span class="dv">3</span>]]</span>
<span id="cb13-147"><a href="#cb13-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-148"><a href="#cb13-148" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot original data with principal components</span></span>
<span id="cb13-149"><a href="#cb13-149" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb13-150"><a href="#cb13-150" aria-hidden="true" tabindex="-1"></a>ax.scatter(data_2d[:, <span class="dv">0</span>], data_2d[:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.9</span>, s<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span>colors[<span class="dv">0</span>], edgecolors<span class="op">=</span><span class="st">'k'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb13-151"><a href="#cb13-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-152"><a href="#cb13-152" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw principal components as arrows</span></span>
<span id="cb13-153"><a href="#cb13-153" aria-hidden="true" tabindex="-1"></a>origin <span class="op">=</span> pca.mean_</span>
<span id="cb13-154"><a href="#cb13-154" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (component, variance) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(pca.components_, pca.explained_variance_)):</span>
<span id="cb13-155"><a href="#cb13-155" aria-hidden="true" tabindex="-1"></a>    direction <span class="op">=</span> component <span class="op">*</span> np.sqrt(variance) <span class="op">*</span> <span class="dv">3</span>  <span class="co"># Scale for visibility</span></span>
<span id="cb13-156"><a href="#cb13-156" aria-hidden="true" tabindex="-1"></a>    ax.arrow(origin[<span class="dv">0</span>], origin[<span class="dv">1</span>], direction[<span class="dv">0</span>], direction[<span class="dv">1</span>],</span>
<span id="cb13-157"><a href="#cb13-157" aria-hidden="true" tabindex="-1"></a>             head_width<span class="op">=</span><span class="fl">0.3</span>, head_length<span class="op">=</span><span class="fl">0.3</span>, fc<span class="op">=</span>colors[i<span class="op">+</span><span class="dv">1</span>], ec<span class="op">=</span>colors[i<span class="op">+</span><span class="dv">1</span>], linewidth<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb13-158"><a href="#cb13-158" aria-hidden="true" tabindex="-1"></a>             label<span class="op">=</span><span class="ss">f'PC</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>variance<span class="op">/</span>pca<span class="sc">.</span>explained_variance_<span class="sc">.</span><span class="bu">sum</span>()<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%)'</span>)</span>
<span id="cb13-159"><a href="#cb13-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-160"><a href="#cb13-160" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Original X'</span>)</span>
<span id="cb13-161"><a href="#cb13-161" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Original Y'</span>)</span>
<span id="cb13-162"><a href="#cb13-162" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Principal Components: Directions of Maximum Variance'</span>)</span>
<span id="cb13-163"><a href="#cb13-163" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb13-164"><a href="#cb13-164" aria-hidden="true" tabindex="-1"></a>ax.axis(<span class="st">'equal'</span>)</span>
<span id="cb13-165"><a href="#cb13-165" aria-hidden="true" tabindex="-1"></a>sns.despine()</span>
<span id="cb13-166"><a href="#cb13-166" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-167"><a href="#cb13-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-168"><a href="#cb13-168" aria-hidden="true" tabindex="-1"></a>PC1 (orange arrow) points along the direction of greatest spread. PC2 (green arrow) is perpendicular and captures the remaining variation.</span>
<span id="cb13-169"><a href="#cb13-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-170"><a href="#cb13-170" aria-hidden="true" tabindex="-1"></a>The percentage in parentheses shows how much variance each component explains. If PC1 explains 90% of variance, then projecting onto just PC1 preserves most of your data's structure.</span>
<span id="cb13-171"><a href="#cb13-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-172"><a href="#cb13-172" aria-hidden="true" tabindex="-1"></a><span class="fu">## Applying PCA to Iris</span></span>
<span id="cb13-173"><a href="#cb13-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-174"><a href="#cb13-174" aria-hidden="true" tabindex="-1"></a>Let's apply PCA to the 4-dimensional Iris dataset:</span>
<span id="cb13-175"><a href="#cb13-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-178"><a href="#cb13-178" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-179"><a href="#cb13-179" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "PCA projection of Iris dataset to 2D preserves the separation between species"</span></span>
<span id="cb13-180"><a href="#cb13-180" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 14</span></span>
<span id="cb13-181"><a href="#cb13-181" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 6</span></span>
<span id="cb13-182"><a href="#cb13-182" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb13-183"><a href="#cb13-183" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data</span></span>
<span id="cb13-184"><a href="#cb13-184" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> iris.data</span>
<span id="cb13-185"><a href="#cb13-185" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> iris.target</span>
<span id="cb13-186"><a href="#cb13-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-187"><a href="#cb13-187" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize (important for PCA!)</span></span>
<span id="cb13-188"><a href="#cb13-188" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb13-189"><a href="#cb13-189" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb13-190"><a href="#cb13-190" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb13-191"><a href="#cb13-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-192"><a href="#cb13-192" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PCA</span></span>
<span id="cb13-193"><a href="#cb13-193" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-194"><a href="#cb13-194" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X_scaled)</span>
<span id="cb13-195"><a href="#cb13-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-196"><a href="#cb13-196" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataFrame for plotting</span></span>
<span id="cb13-197"><a href="#cb13-197" aria-hidden="true" tabindex="-1"></a>pca_df <span class="op">=</span> pd.DataFrame(X_pca, columns<span class="op">=</span>[<span class="st">'PC1'</span>, <span class="st">'PC2'</span>])</span>
<span id="cb13-198"><a href="#cb13-198" aria-hidden="true" tabindex="-1"></a>pca_df[<span class="st">'species'</span>] <span class="op">=</span> iris.target_names[y]</span>
<span id="cb13-199"><a href="#cb13-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-200"><a href="#cb13-200" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb13-201"><a href="#cb13-201" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">6</span>))</span>
<span id="cb13-202"><a href="#cb13-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-203"><a href="#cb13-203" aria-hidden="true" tabindex="-1"></a><span class="co"># Left: PCA projection</span></span>
<span id="cb13-204"><a href="#cb13-204" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> species, color <span class="kw">in</span> <span class="bu">zip</span>([<span class="st">'setosa'</span>, <span class="st">'versicolor'</span>, <span class="st">'virginica'</span>], sns.color_palette(<span class="st">'muted'</span>, <span class="dv">3</span>)):</span>
<span id="cb13-205"><a href="#cb13-205" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> pca_df[<span class="st">'species'</span>] <span class="op">==</span> species</span>
<span id="cb13-206"><a href="#cb13-206" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].scatter(pca_df.loc[mask, <span class="st">'PC1'</span>], pca_df.loc[mask, <span class="st">'PC2'</span>],</span>
<span id="cb13-207"><a href="#cb13-207" aria-hidden="true" tabindex="-1"></a>                   label<span class="op">=</span>species, alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span>color, edgecolors<span class="op">=</span><span class="st">'white'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb13-208"><a href="#cb13-208" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="ss">f'PC1 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">0</span>]<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">% variance)'</span>)</span>
<span id="cb13-209"><a href="#cb13-209" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="ss">f'PC2 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">1</span>]<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">% variance)'</span>)</span>
<span id="cb13-210"><a href="#cb13-210" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'PCA Projection of Iris Dataset'</span>)</span>
<span id="cb13-211"><a href="#cb13-211" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb13-212"><a href="#cb13-212" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb13-213"><a href="#cb13-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-214"><a href="#cb13-214" aria-hidden="true" tabindex="-1"></a><span class="co"># Right: Variance explained</span></span>
<span id="cb13-215"><a href="#cb13-215" aria-hidden="true" tabindex="-1"></a>variances <span class="op">=</span> pca.explained_variance_ratio_</span>
<span id="cb13-216"><a href="#cb13-216" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].bar([<span class="dv">1</span>, <span class="dv">2</span>], variances, color<span class="op">=</span>sns.color_palette(<span class="st">'muted'</span>, <span class="dv">2</span>), alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb13-217"><a href="#cb13-217" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Principal Component'</span>)</span>
<span id="cb13-218"><a href="#cb13-218" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Variance Explained'</span>)</span>
<span id="cb13-219"><a href="#cb13-219" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Variance Explained by Each Component'</span>)</span>
<span id="cb13-220"><a href="#cb13-220" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xticks([<span class="dv">1</span>, <span class="dv">2</span>])</span>
<span id="cb13-221"><a href="#cb13-221" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xticklabels([<span class="st">'PC1'</span>, <span class="st">'PC2'</span>])</span>
<span id="cb13-222"><a href="#cb13-222" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, v <span class="kw">in</span> <span class="bu">enumerate</span>(variances):</span>
<span id="cb13-223"><a href="#cb13-223" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].text(i<span class="op">+</span><span class="dv">1</span>, v<span class="op">+</span><span class="fl">0.01</span>, <span class="ss">f'</span><span class="sc">{</span>v<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb13-224"><a href="#cb13-224" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb13-225"><a href="#cb13-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-226"><a href="#cb13-226" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb13-227"><a href="#cb13-227" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-228"><a href="#cb13-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-229"><a href="#cb13-229" aria-hidden="true" tabindex="-1"></a>PC1 and PC2 together explain over 95% of the variance in the 4D dataset. The 2D projection preserves the main structure: setosa is well-separated, while versicolor and virginica have some overlap.</span>
<span id="cb13-230"><a href="#cb13-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-231"><a href="#cb13-231" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb13-232"><a href="#cb13-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-233"><a href="#cb13-233" aria-hidden="true" tabindex="-1"></a>**Always standardize before PCA!** If features have different units or scales, PCA will be dominated by high-variance features. Standardization (zero mean, unit variance) ensures all features contribute fairly.</span>
<span id="cb13-234"><a href="#cb13-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-235"><a href="#cb13-235" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb13-236"><a href="#cb13-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-237"><a href="#cb13-237" aria-hidden="true" tabindex="-1"></a><span class="fu"># Non-Linear Dimensionality Reduction</span></span>
<span id="cb13-238"><a href="#cb13-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-239"><a href="#cb13-239" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multidimensional Scaling (MDS)</span></span>
<span id="cb13-240"><a href="#cb13-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-241"><a href="#cb13-241" aria-hidden="true" tabindex="-1"></a>**Multidimensional Scaling (MDS)** takes a different approach: instead of finding directions of maximum variance, it tries to **preserve distances between points**.</span>
<span id="cb13-242"><a href="#cb13-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-243"><a href="#cb13-243" aria-hidden="true" tabindex="-1"></a>You give MDS a distance matrix---the distance between every pair of points in high-dimensional space---and it finds a low-dimensional configuration where those distances are preserved as well as possible.</span>
<span id="cb13-244"><a href="#cb13-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-245"><a href="#cb13-245" aria-hidden="true" tabindex="-1"></a>Think of it like arranging cities on a map. You know the distance between every pair of cities, but not their coordinates. MDS finds positions that preserve those distances.</span>
<span id="cb13-246"><a href="#cb13-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-247"><a href="#cb13-247" aria-hidden="true" tabindex="-1"></a>Mathematically, MDS minimizes **stress**: the difference between high-dimensional distances and low-dimensional distances. Classical MDS has a closed-form solution (like PCA), but more flexible variants use iterative optimization.</span>
<span id="cb13-248"><a href="#cb13-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-251"><a href="#cb13-251" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-252"><a href="#cb13-252" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "MDS vs PCA on Iris dataset. MDS preserves distances better but looks similar to PCA for this dataset."</span></span>
<span id="cb13-253"><a href="#cb13-253" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 14</span></span>
<span id="cb13-254"><a href="#cb13-254" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 6</span></span>
<span id="cb13-255"><a href="#cb13-255" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb13-256"><a href="#cb13-256" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> MDS</span>
<span id="cb13-257"><a href="#cb13-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-258"><a href="#cb13-258" aria-hidden="true" tabindex="-1"></a><span class="co"># Suppress FutureWarning about n_init in MDS</span></span>
<span id="cb13-259"><a href="#cb13-259" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb13-260"><a href="#cb13-260" aria-hidden="true" tabindex="-1"></a>mds <span class="op">=</span> MDS(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-261"><a href="#cb13-261" aria-hidden="true" tabindex="-1"></a>X_mds <span class="op">=</span> mds.fit_transform(X_scaled)</span>
<span id="cb13-262"><a href="#cb13-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-263"><a href="#cb13-263" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PCA</span></span>
<span id="cb13-264"><a href="#cb13-264" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-265"><a href="#cb13-265" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X_scaled)</span>
<span id="cb13-266"><a href="#cb13-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-267"><a href="#cb13-267" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataFrame</span></span>
<span id="cb13-268"><a href="#cb13-268" aria-hidden="true" tabindex="-1"></a>mds_df <span class="op">=</span> pd.DataFrame(X_mds, columns<span class="op">=</span>[<span class="st">'MDS1'</span>, <span class="st">'MDS2'</span>])</span>
<span id="cb13-269"><a href="#cb13-269" aria-hidden="true" tabindex="-1"></a>mds_df[<span class="st">'species'</span>] <span class="op">=</span> iris.target_names[y]</span>
<span id="cb13-270"><a href="#cb13-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-271"><a href="#cb13-271" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot both</span></span>
<span id="cb13-272"><a href="#cb13-272" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">6</span>))</span>
<span id="cb13-273"><a href="#cb13-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-274"><a href="#cb13-274" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA</span></span>
<span id="cb13-275"><a href="#cb13-275" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> species, color <span class="kw">in</span> <span class="bu">zip</span>([<span class="st">'setosa'</span>, <span class="st">'versicolor'</span>, <span class="st">'virginica'</span>], sns.color_palette(<span class="st">'muted'</span>, <span class="dv">3</span>)):</span>
<span id="cb13-276"><a href="#cb13-276" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> pca_df[<span class="st">'species'</span>] <span class="op">==</span> species</span>
<span id="cb13-277"><a href="#cb13-277" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].scatter(pca_df.loc[mask, <span class="st">'PC1'</span>], pca_df.loc[mask, <span class="st">'PC2'</span>],</span>
<span id="cb13-278"><a href="#cb13-278" aria-hidden="true" tabindex="-1"></a>                   label<span class="op">=</span>species, alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span>color, edgecolors<span class="op">=</span><span class="st">'white'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb13-279"><a href="#cb13-279" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'PC1'</span>)</span>
<span id="cb13-280"><a href="#cb13-280" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'PC2'</span>)</span>
<span id="cb13-281"><a href="#cb13-281" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'PCA: Maximizes Variance'</span>)</span>
<span id="cb13-282"><a href="#cb13-282" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb13-283"><a href="#cb13-283" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb13-284"><a href="#cb13-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-285"><a href="#cb13-285" aria-hidden="true" tabindex="-1"></a><span class="co"># MDS</span></span>
<span id="cb13-286"><a href="#cb13-286" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> species, color <span class="kw">in</span> <span class="bu">zip</span>([<span class="st">'setosa'</span>, <span class="st">'versicolor'</span>, <span class="st">'virginica'</span>], sns.color_palette(<span class="st">'muted'</span>, <span class="dv">3</span>)):</span>
<span id="cb13-287"><a href="#cb13-287" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> mds_df[<span class="st">'species'</span>] <span class="op">==</span> species</span>
<span id="cb13-288"><a href="#cb13-288" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].scatter(mds_df.loc[mask, <span class="st">'MDS1'</span>], mds_df.loc[mask, <span class="st">'MDS2'</span>],</span>
<span id="cb13-289"><a href="#cb13-289" aria-hidden="true" tabindex="-1"></a>                   label<span class="op">=</span>species, alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span>color, edgecolors<span class="op">=</span><span class="st">'white'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb13-290"><a href="#cb13-290" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'MDS1'</span>)</span>
<span id="cb13-291"><a href="#cb13-291" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'MDS2'</span>)</span>
<span id="cb13-292"><a href="#cb13-292" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'MDS: Preserves Distances'</span>)</span>
<span id="cb13-293"><a href="#cb13-293" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend()</span>
<span id="cb13-294"><a href="#cb13-294" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb13-295"><a href="#cb13-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-296"><a href="#cb13-296" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb13-297"><a href="#cb13-297" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-298"><a href="#cb13-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-299"><a href="#cb13-299" aria-hidden="true" tabindex="-1"></a>For the Iris dataset, PCA and MDS look very similar. This is because Iris data is fairly linear---the relationships between features don't involve complex curves or non-linear structures.</span>
<span id="cb13-300"><a href="#cb13-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-301"><a href="#cb13-301" aria-hidden="true" tabindex="-1"></a><span class="fu">## Isomap</span></span>
<span id="cb13-302"><a href="#cb13-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-303"><a href="#cb13-303" aria-hidden="true" tabindex="-1"></a>MDS preserves Euclidean distances---straight-line distances through space. But for curved manifolds, what matters is the **geodesic distance**: the distance along the surface.</span>
<span id="cb13-304"><a href="#cb13-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-305"><a href="#cb13-305" aria-hidden="true" tabindex="-1"></a>**Isomap** (Isometric Mapping) addresses this by approximating geodesic distances using the neighborhood graph:</span>
<span id="cb13-306"><a href="#cb13-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-307"><a href="#cb13-307" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Build a neighborhood graph**: Connect each point to its k nearest neighbors</span>
<span id="cb13-308"><a href="#cb13-308" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Compute shortest paths**: The geodesic distance between points is approximated by the shortest path through this graph</span>
<span id="cb13-309"><a href="#cb13-309" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Apply classical MDS**: Use MDS on these geodesic distances instead of Euclidean distances</span>
<span id="cb13-310"><a href="#cb13-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-311"><a href="#cb13-311" aria-hidden="true" tabindex="-1"></a>Think of it like this: MDS measures distance "as the crow flies," while Isomap measures distance "as you walk along the surface."</span>
<span id="cb13-312"><a href="#cb13-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-315"><a href="#cb13-315" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-316"><a href="#cb13-316" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Isomap uses geodesic distances (along the surface) instead of Euclidean distances (through space), better recovering the S-curve structure"</span></span>
<span id="cb13-317"><a href="#cb13-317" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 14</span></span>
<span id="cb13-318"><a href="#cb13-318" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 6</span></span>
<span id="cb13-319"><a href="#cb13-319" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb13-320"><a href="#cb13-320" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> Isomap</span>
<span id="cb13-321"><a href="#cb13-321" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_s_curve</span>
<span id="cb13-322"><a href="#cb13-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-323"><a href="#cb13-323" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate S-curve data (a 2D manifold embedded in 3D)</span></span>
<span id="cb13-324"><a href="#cb13-324" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb13-325"><a href="#cb13-325" aria-hidden="true" tabindex="-1"></a>X_scurve, color <span class="op">=</span> make_s_curve(n_samples, noise<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb13-326"><a href="#cb13-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-327"><a href="#cb13-327" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply Isomap</span></span>
<span id="cb13-328"><a href="#cb13-328" aria-hidden="true" tabindex="-1"></a>isomap <span class="op">=</span> Isomap(n_components<span class="op">=</span><span class="dv">2</span>, n_neighbors<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb13-329"><a href="#cb13-329" aria-hidden="true" tabindex="-1"></a>X_scurve_isomap <span class="op">=</span> isomap.fit_transform(X_scurve)</span>
<span id="cb13-330"><a href="#cb13-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-331"><a href="#cb13-331" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PCA</span></span>
<span id="cb13-332"><a href="#cb13-332" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-333"><a href="#cb13-333" aria-hidden="true" tabindex="-1"></a>X_scurve_pca <span class="op">=</span> pca.fit_transform(X_scurve)</span>
<span id="cb13-334"><a href="#cb13-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-335"><a href="#cb13-335" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply MDS</span></span>
<span id="cb13-336"><a href="#cb13-336" aria-hidden="true" tabindex="-1"></a>mds <span class="op">=</span> MDS(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-337"><a href="#cb13-337" aria-hidden="true" tabindex="-1"></a>X_scurve_mds <span class="op">=</span> mds.fit_transform(X_scurve)</span>
<span id="cb13-338"><a href="#cb13-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-339"><a href="#cb13-339" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot MDS vs Isomap vs PCA</span></span>
<span id="cb13-340"><a href="#cb13-340" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">6</span>))</span>
<span id="cb13-341"><a href="#cb13-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-342"><a href="#cb13-342" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA</span></span>
<span id="cb13-343"><a href="#cb13-343" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(X_scurve_pca[:, <span class="dv">0</span>], X_scurve_pca[:, <span class="dv">1</span>], c<span class="op">=</span>color,</span>
<span id="cb13-344"><a href="#cb13-344" aria-hidden="true" tabindex="-1"></a>                cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb13-345"><a href="#cb13-345" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'PC1'</span>)</span>
<span id="cb13-346"><a href="#cb13-346" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'PC2'</span>)</span>
<span id="cb13-347"><a href="#cb13-347" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'PCA: Global Variance'</span>)</span>
<span id="cb13-348"><a href="#cb13-348" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb13-349"><a href="#cb13-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-350"><a href="#cb13-350" aria-hidden="true" tabindex="-1"></a><span class="co"># MDS</span></span>
<span id="cb13-351"><a href="#cb13-351" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(X_scurve_mds[:, <span class="dv">0</span>], X_scurve_mds[:, <span class="dv">1</span>], c<span class="op">=</span>color,</span>
<span id="cb13-352"><a href="#cb13-352" aria-hidden="true" tabindex="-1"></a>                cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb13-353"><a href="#cb13-353" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'MDS1'</span>)</span>
<span id="cb13-354"><a href="#cb13-354" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'MDS2'</span>)</span>
<span id="cb13-355"><a href="#cb13-355" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'MDS: Global Distances'</span>)</span>
<span id="cb13-356"><a href="#cb13-356" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb13-357"><a href="#cb13-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-358"><a href="#cb13-358" aria-hidden="true" tabindex="-1"></a><span class="co"># Isomap</span></span>
<span id="cb13-359"><a href="#cb13-359" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].scatter(X_scurve_isomap[:, <span class="dv">0</span>], X_scurve_isomap[:, <span class="dv">1</span>], c<span class="op">=</span>color,</span>
<span id="cb13-360"><a href="#cb13-360" aria-hidden="true" tabindex="-1"></a>                cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb13-361"><a href="#cb13-361" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">'Isomap1'</span>)</span>
<span id="cb13-362"><a href="#cb13-362" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylabel(<span class="st">'Isomap2'</span>)</span>
<span id="cb13-363"><a href="#cb13-363" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'Isomap: Geodesic Distances'</span>)</span>
<span id="cb13-364"><a href="#cb13-364" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">2</span>])</span>
<span id="cb13-365"><a href="#cb13-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-366"><a href="#cb13-366" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb13-367"><a href="#cb13-367" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-368"><a href="#cb13-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-369"><a href="#cb13-369" aria-hidden="true" tabindex="-1"></a>Isomap successfully "straightens" the S-curve because it respects the manifold structure. By computing distances along the neighborhood graph, it avoids the shortcuts across the bend that confused MDS.</span>
<span id="cb13-370"><a href="#cb13-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-371"><a href="#cb13-371" aria-hidden="true" tabindex="-1"></a><span class="fu">## t-SNE</span></span>
<span id="cb13-372"><a href="#cb13-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-373"><a href="#cb13-373" aria-hidden="true" tabindex="-1"></a>**t-SNE** (t-Distributed Stochastic Neighbor Embedding) takes a middle ground between MDS's global approach and Isomap's geodesic approach: it **prioritizes local structure** while allowing some flexibility in global positioning.</span>
<span id="cb13-374"><a href="#cb13-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-375"><a href="#cb13-375" aria-hidden="true" tabindex="-1"></a>The key insight: for visualization, we often care most about **which points are neighbors**. Whether distant clusters are placed left vs right, or how far apart they are, matters less than preserving the local neighborhood relationships within and between clusters.</span>
<span id="cb13-376"><a href="#cb13-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-377"><a href="#cb13-377" aria-hidden="true" tabindex="-1"></a>t-SNE converts distances into similarity probabilities and preserves these local relationships:</span>
<span id="cb13-378"><a href="#cb13-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-379"><a href="#cb13-379" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**In high dimensions**: Define probability $p_{ij}$ that point $i$ picks point $j$ as a neighbor (based on Gaussian distance)</span>
<span id="cb13-380"><a href="#cb13-380" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**In low dimensions**: Define similar probability $q_{ij}$ using a t-distribution with heavy tails</span>
<span id="cb13-381"><a href="#cb13-381" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Optimize**: Move points in 2D to make $q_{ij}$ match $p_{ij}$ (minimize KL divergence)</span>
<span id="cb13-382"><a href="#cb13-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-383"><a href="#cb13-383" aria-hidden="true" tabindex="-1"></a>The t-distribution's heavy tails are clever: they let well-separated clusters spread out in 2D without overlapping, while keeping local neighborhoods tight.</span>
<span id="cb13-384"><a href="#cb13-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-387"><a href="#cb13-387" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-388"><a href="#cb13-388" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Comparing global, geodesic, and local approaches on the S-curve"</span></span>
<span id="cb13-389"><a href="#cb13-389" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 15</span></span>
<span id="cb13-390"><a href="#cb13-390" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb13-391"><a href="#cb13-391" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb13-392"><a href="#cb13-392" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb13-393"><a href="#cb13-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-394"><a href="#cb13-394" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply t-SNE</span></span>
<span id="cb13-395"><a href="#cb13-395" aria-hidden="true" tabindex="-1"></a>tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, perplexity<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb13-396"><a href="#cb13-396" aria-hidden="true" tabindex="-1"></a>X_scurve_tsne <span class="op">=</span> tsne.fit_transform(X_scurve)</span>
<span id="cb13-397"><a href="#cb13-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-398"><a href="#cb13-398" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot all three methods</span></span>
<span id="cb13-399"><a href="#cb13-399" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb13-400"><a href="#cb13-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-401"><a href="#cb13-401" aria-hidden="true" tabindex="-1"></a><span class="co"># MDS - Global Euclidean distances</span></span>
<span id="cb13-402"><a href="#cb13-402" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(X_scurve_pca[:, <span class="dv">0</span>], X_scurve_pca[:, <span class="dv">1</span>], c<span class="op">=</span>color,</span>
<span id="cb13-403"><a href="#cb13-403" aria-hidden="true" tabindex="-1"></a>                cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb13-404"><a href="#cb13-404" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'PC1'</span>)</span>
<span id="cb13-405"><a href="#cb13-405" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'PC2'</span>)</span>
<span id="cb13-406"><a href="#cb13-406" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'PCA: Global Variance'</span>)</span>
<span id="cb13-407"><a href="#cb13-407" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb13-408"><a href="#cb13-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-409"><a href="#cb13-409" aria-hidden="true" tabindex="-1"></a><span class="co"># Isomap - Geodesic distances</span></span>
<span id="cb13-410"><a href="#cb13-410" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(X_scurve_isomap[:, <span class="dv">0</span>], X_scurve_isomap[:, <span class="dv">1</span>], c<span class="op">=</span>color,</span>
<span id="cb13-411"><a href="#cb13-411" aria-hidden="true" tabindex="-1"></a>                cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb13-412"><a href="#cb13-412" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Isomap1'</span>)</span>
<span id="cb13-413"><a href="#cb13-413" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Isomap2'</span>)</span>
<span id="cb13-414"><a href="#cb13-414" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Isomap: Geodesic Distances'</span>)</span>
<span id="cb13-415"><a href="#cb13-415" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb13-416"><a href="#cb13-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-417"><a href="#cb13-417" aria-hidden="true" tabindex="-1"></a><span class="co"># t-SNE - Local neighborhoods</span></span>
<span id="cb13-418"><a href="#cb13-418" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].scatter(X_scurve_tsne[:, <span class="dv">0</span>], X_scurve_tsne[:, <span class="dv">1</span>], c<span class="op">=</span>color,</span>
<span id="cb13-419"><a href="#cb13-419" aria-hidden="true" tabindex="-1"></a>                cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb13-420"><a href="#cb13-420" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">'t-SNE1'</span>)</span>
<span id="cb13-421"><a href="#cb13-421" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylabel(<span class="st">'t-SNE2'</span>)</span>
<span id="cb13-422"><a href="#cb13-422" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'t-SNE: Local Structure'</span>)</span>
<span id="cb13-423"><a href="#cb13-423" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">2</span>])</span>
<span id="cb13-424"><a href="#cb13-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-425"><a href="#cb13-425" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb13-426"><a href="#cb13-426" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-427"><a href="#cb13-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-428"><a href="#cb13-428" aria-hidden="true" tabindex="-1"></a>All three methods successfully straighten the S-curve, but through different philosophies: MDS compromises between all distances, Isomap follows the manifold globally, and t-SNE focuses on preserving neighborhoods.</span>
<span id="cb13-429"><a href="#cb13-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-430"><a href="#cb13-430" aria-hidden="true" tabindex="-1"></a>**Perplexity** (typically 30-50) controls the effective neighborhood size. Too low fragments clusters; too high loses local detail.</span>
<span id="cb13-431"><a href="#cb13-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-432"><a href="#cb13-432" aria-hidden="true" tabindex="-1"></a>t-SNE is powerful but has important limitations.</span>
<span id="cb13-433"><a href="#cb13-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-434"><a href="#cb13-434" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb13-435"><a href="#cb13-435" aria-hidden="true" tabindex="-1"></a><span class="fu">## Don't over-interpret t-SNE!</span></span>
<span id="cb13-436"><a href="#cb13-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-437"><a href="#cb13-437" aria-hidden="true" tabindex="-1"></a>**You cannot conclude** from a t-SNE plot:</span>
<span id="cb13-438"><a href="#cb13-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-439"><a href="#cb13-439" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"Cluster A is twice as far from B as from C" (distances are not preserved)</span>
<span id="cb13-440"><a href="#cb13-440" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"Cluster A is twice the size of B" (sizes are not preserved)</span>
<span id="cb13-441"><a href="#cb13-441" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"The data has exactly 5 clusters" (apparent clusters may be visualization artifacts)</span>
<span id="cb13-442"><a href="#cb13-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-443"><a href="#cb13-443" aria-hidden="true" tabindex="-1"></a>**You can conclude:**</span>
<span id="cb13-444"><a href="#cb13-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-445"><a href="#cb13-445" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"These points form a distinct group separate from others"</span>
<span id="cb13-446"><a href="#cb13-446" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"These points are more similar to each other than to distant points"</span>
<span id="cb13-447"><a href="#cb13-447" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"The data has local structure and is not uniformly random"</span>
<span id="cb13-448"><a href="#cb13-448" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb13-449"><a href="#cb13-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-450"><a href="#cb13-450" aria-hidden="true" tabindex="-1"></a>Let's apply t-SNE to a more realistic high-dimensional dataset---the MNIST digits dataset, which has 784 dimensions (28�28 pixel images):</span>
<span id="cb13-451"><a href="#cb13-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-454"><a href="#cb13-454" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-455"><a href="#cb13-455" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "t-SNE visualization of MNIST digits (784 dimensions x 2D). Each color represents a digit class."</span></span>
<span id="cb13-456"><a href="#cb13-456" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 12</span></span>
<span id="cb13-457"><a href="#cb13-457" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 10</span></span>
<span id="cb13-458"><a href="#cb13-458" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb13-459"><a href="#cb13-459" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_digits</span>
<span id="cb13-460"><a href="#cb13-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-461"><a href="#cb13-461" aria-hidden="true" tabindex="-1"></a><span class="co"># Load digits dataset (8x8 images, 64 dimensions - a smaller version of MNIST)</span></span>
<span id="cb13-462"><a href="#cb13-462" aria-hidden="true" tabindex="-1"></a>digits <span class="op">=</span> load_digits()</span>
<span id="cb13-463"><a href="#cb13-463" aria-hidden="true" tabindex="-1"></a>X_digits <span class="op">=</span> digits.data</span>
<span id="cb13-464"><a href="#cb13-464" aria-hidden="true" tabindex="-1"></a>y_digits <span class="op">=</span> digits.target</span>
<span id="cb13-465"><a href="#cb13-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-466"><a href="#cb13-466" aria-hidden="true" tabindex="-1"></a><span class="co"># Take a subset for speed (t-SNE is slow on large datasets)</span></span>
<span id="cb13-467"><a href="#cb13-467" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb13-468"><a href="#cb13-468" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> np.random.choice(<span class="bu">len</span>(X_digits), size<span class="op">=</span><span class="dv">1000</span>, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-469"><a href="#cb13-469" aria-hidden="true" tabindex="-1"></a>X_subset <span class="op">=</span> X_digits[indices]</span>
<span id="cb13-470"><a href="#cb13-470" aria-hidden="true" tabindex="-1"></a>y_subset <span class="op">=</span> y_digits[indices]</span>
<span id="cb13-471"><a href="#cb13-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-472"><a href="#cb13-472" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply t-SNE</span></span>
<span id="cb13-473"><a href="#cb13-473" aria-hidden="true" tabindex="-1"></a>tsne_digits <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, perplexity<span class="op">=</span><span class="dv">40</span>)</span>
<span id="cb13-474"><a href="#cb13-474" aria-hidden="true" tabindex="-1"></a>X_digits_tsne <span class="op">=</span> tsne_digits.fit_transform(X_subset)</span>
<span id="cb13-475"><a href="#cb13-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-476"><a href="#cb13-476" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb13-477"><a href="#cb13-477" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb13-478"><a href="#cb13-478" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> ax.scatter(X_digits_tsne[:, <span class="dv">0</span>], X_digits_tsne[:, <span class="dv">1</span>],</span>
<span id="cb13-479"><a href="#cb13-479" aria-hidden="true" tabindex="-1"></a>                     c<span class="op">=</span>y_subset, cmap<span class="op">=</span><span class="st">'tab10'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb13-480"><a href="#cb13-480" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'t-SNE1'</span>)</span>
<span id="cb13-481"><a href="#cb13-481" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'t-SNE2'</span>)</span>
<span id="cb13-482"><a href="#cb13-482" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'t-SNE Visualization of Handwritten Digits (64D � 2D)'</span>)</span>
<span id="cb13-483"><a href="#cb13-483" aria-hidden="true" tabindex="-1"></a>cbar <span class="op">=</span> plt.colorbar(scatter, ax<span class="op">=</span>ax, ticks<span class="op">=</span><span class="bu">range</span>(<span class="dv">10</span>))</span>
<span id="cb13-484"><a href="#cb13-484" aria-hidden="true" tabindex="-1"></a>cbar.set_label(<span class="st">'Digit Class'</span>)</span>
<span id="cb13-485"><a href="#cb13-485" aria-hidden="true" tabindex="-1"></a>sns.despine()</span>
<span id="cb13-486"><a href="#cb13-486" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-487"><a href="#cb13-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-488"><a href="#cb13-488" aria-hidden="true" tabindex="-1"></a>The t-SNE projection beautifully separates most digit classes. Digits that look similar (like 3, 5, and 8, or 4 and 9) cluster near each other, while visually distinct digits (like 0 and 1) are well separated.</span>
<span id="cb13-489"><a href="#cb13-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-490"><a href="#cb13-490" aria-hidden="true" tabindex="-1"></a>This demonstrates t-SNE's power: from 64 dimensions with no explicit information about what makes digits similar, t-SNE discovers the perceptual structure of handwritten digits.</span>
<span id="cb13-491"><a href="#cb13-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-492"><a href="#cb13-492" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb13-493"><a href="#cb13-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-494"><a href="#cb13-494" aria-hidden="true" tabindex="-1"></a>**t-SNE is stochastic**: Different runs produce different layouts (though cluster structure remains consistent). Always check multiple runs with different random seeds, especially for important scientific conclusions.</span>
<span id="cb13-495"><a href="#cb13-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-496"><a href="#cb13-496" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb13-497"><a href="#cb13-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-498"><a href="#cb13-498" aria-hidden="true" tabindex="-1"></a><span class="fu">## UMAP</span></span>
<span id="cb13-499"><a href="#cb13-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-500"><a href="#cb13-500" aria-hidden="true" tabindex="-1"></a>**Uniform Manifold Approximation and Projection (UMAP)** is a newer method (2018) that has become popular as an alternative to t-SNE. Like t-SNE, UMAP preserves local structure, but it's based on different mathematical foundations (manifold learning and topological data analysis).</span>
<span id="cb13-501"><a href="#cb13-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-504"><a href="#cb13-504" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-505"><a href="#cb13-505" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "UMAP vs t-SNE on digits dataset. UMAP often preserves more global structure while being much faster."</span></span>
<span id="cb13-506"><a href="#cb13-506" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 14</span></span>
<span id="cb13-507"><a href="#cb13-507" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 6</span></span>
<span id="cb13-508"><a href="#cb13-508" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb13-509"><a href="#cb13-509" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> umap</span>
<span id="cb13-510"><a href="#cb13-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-511"><a href="#cb13-511" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply UMAP</span></span>
<span id="cb13-512"><a href="#cb13-512" aria-hidden="true" tabindex="-1"></a>umap_model <span class="op">=</span> umap.UMAP(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, n_neighbors<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb13-513"><a href="#cb13-513" aria-hidden="true" tabindex="-1"></a>X_digits_umap <span class="op">=</span> umap_model.fit_transform(X_subset)</span>
<span id="cb13-514"><a href="#cb13-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-515"><a href="#cb13-515" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot comparison</span></span>
<span id="cb13-516"><a href="#cb13-516" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">6</span>))</span>
<span id="cb13-517"><a href="#cb13-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-518"><a href="#cb13-518" aria-hidden="true" tabindex="-1"></a><span class="co"># t-SNE</span></span>
<span id="cb13-519"><a href="#cb13-519" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> axes[<span class="dv">0</span>].scatter(X_digits_tsne[:, <span class="dv">0</span>], X_digits_tsne[:, <span class="dv">1</span>],</span>
<span id="cb13-520"><a href="#cb13-520" aria-hidden="true" tabindex="-1"></a>                          c<span class="op">=</span>y_subset, cmap<span class="op">=</span><span class="st">'tab10'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb13-521"><a href="#cb13-521" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'t-SNE1'</span>)</span>
<span id="cb13-522"><a href="#cb13-522" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'t-SNE2'</span>)</span>
<span id="cb13-523"><a href="#cb13-523" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'t-SNE'</span>)</span>
<span id="cb13-524"><a href="#cb13-524" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb13-525"><a href="#cb13-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-526"><a href="#cb13-526" aria-hidden="true" tabindex="-1"></a><span class="co"># UMAP</span></span>
<span id="cb13-527"><a href="#cb13-527" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> axes[<span class="dv">1</span>].scatter(X_digits_umap[:, <span class="dv">0</span>], X_digits_umap[:, <span class="dv">1</span>],</span>
<span id="cb13-528"><a href="#cb13-528" aria-hidden="true" tabindex="-1"></a>                          c<span class="op">=</span>y_subset, cmap<span class="op">=</span><span class="st">'tab10'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb13-529"><a href="#cb13-529" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'UMAP1'</span>)</span>
<span id="cb13-530"><a href="#cb13-530" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'UMAP2'</span>)</span>
<span id="cb13-531"><a href="#cb13-531" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'UMAP'</span>)</span>
<span id="cb13-532"><a href="#cb13-532" aria-hidden="true" tabindex="-1"></a>cbar <span class="op">=</span> plt.colorbar(scatter, ax<span class="op">=</span>axes[<span class="dv">1</span>], ticks<span class="op">=</span><span class="bu">range</span>(<span class="dv">10</span>))</span>
<span id="cb13-533"><a href="#cb13-533" aria-hidden="true" tabindex="-1"></a>cbar.set_label(<span class="st">'Digit Class'</span>)</span>
<span id="cb13-534"><a href="#cb13-534" aria-hidden="true" tabindex="-1"></a>sns.despine(ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb13-535"><a href="#cb13-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-536"><a href="#cb13-536" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb13-537"><a href="#cb13-537" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-538"><a href="#cb13-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-539"><a href="#cb13-539" aria-hidden="true" tabindex="-1"></a><span class="fu"># The Bigger Picture</span></span>
<span id="cb13-540"><a href="#cb13-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-541"><a href="#cb13-541" aria-hidden="true" tabindex="-1"></a>Dimensionality reduction is not a one-size-fits-all solution. Different methods make different trade-offs:</span>
<span id="cb13-542"><a href="#cb13-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-543"><a href="#cb13-543" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Method <span class="pp">|</span> Preserves <span class="pp">|</span> Speed <span class="pp">|</span> Scalability <span class="pp">|</span> When to use <span class="pp">|</span></span>
<span id="cb13-544"><a href="#cb13-544" aria-hidden="true" tabindex="-1"></a><span class="pp">|--------|-----------|-------|-------------|-------------|</span></span>
<span id="cb13-545"><a href="#cb13-545" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Scatter plot matrix** <span class="pp">|</span> Everything (2D projections) <span class="pp">|</span> Fast <span class="pp">|</span> 3-10 dimensions <span class="pp">|</span> Exploring moderate-dimensional data <span class="pp">|</span></span>
<span id="cb13-546"><a href="#cb13-546" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **PCA** <span class="pp">|</span> Global variance <span class="pp">|</span> Very fast <span class="pp">|</span> Excellent (1000s of dims) <span class="pp">|</span> Linear structure, interpretability needed <span class="pp">|</span></span>
<span id="cb13-547"><a href="#cb13-547" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **MDS** <span class="pp">|</span> All distances <span class="pp">|</span> Slow <span class="pp">|</span> Poor (100s of points) <span class="pp">|</span> Distance preservation critical <span class="pp">|</span></span>
<span id="cb13-548"><a href="#cb13-548" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **t-SNE** <span class="pp">|</span> Local structure <span class="pp">|</span> Slow <span class="pp">|</span> Moderate (10,000s of points) <span class="pp">|</span> Revealing clusters, local relationships <span class="pp">|</span></span>
<span id="cb13-549"><a href="#cb13-549" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **UMAP** <span class="pp">|</span> Local + some global <span class="pp">|</span> Fast <span class="pp">|</span> Excellent (millions of points) <span class="pp">|</span> Large datasets, faster alternative to t-SNE <span class="pp">|</span></span>
<span id="cb13-550"><a href="#cb13-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-551"><a href="#cb13-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-552"><a href="#cb13-552" aria-hidden="true" tabindex="-1"></a>::: {.callout-important}</span>
<span id="cb13-553"><a href="#cb13-553" aria-hidden="true" tabindex="-1"></a><span class="fu">## Beware of visualization artifacts</span></span>
<span id="cb13-554"><a href="#cb13-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-555"><a href="#cb13-555" aria-hidden="true" tabindex="-1"></a>Dimensionality reduction can create apparent patterns that don't exist in the original data:</span>
<span id="cb13-556"><a href="#cb13-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-557"><a href="#cb13-557" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Spurious clusters**: t-SNE can split continuous data into false clusters</span>
<span id="cb13-558"><a href="#cb13-558" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Missing relationships**: Two clusters might be connected in high dimensions but appear separated in 2D</span>
<span id="cb13-559"><a href="#cb13-559" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Misleading distances**: Distance and size in t-SNE/UMAP are not meaningful</span>
<span id="cb13-560"><a href="#cb13-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-561"><a href="#cb13-561" aria-hidden="true" tabindex="-1"></a>**Always validate** important findings with statistical tests or domain knowledge. A beautiful t-SNE plot is a starting point for investigation, not a final conclusion.</span>
<span id="cb13-562"><a href="#cb13-562" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb13-563"><a href="#cb13-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-564"><a href="#cb13-564" aria-hidden="true" tabindex="-1"></a>Visualizing high-dimensional data is as much art as science. The goal is not to find "the true projection"---there is no single true way to flatten high-dimensional space onto a page. The goal is to **reveal structure that helps you understand your data and ask better questions**.</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2025, Sadamori Kojaku</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions"><ul><li><a href="https://github.com/skojaku/applied-soft-comp/edit/main/m02-visualization/highd-data.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/skojaku/applied-soft-comp/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/skojaku/applied-soft-comp">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>