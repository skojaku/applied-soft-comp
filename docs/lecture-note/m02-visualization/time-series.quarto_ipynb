{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Time Series Visualization\"\n",
        "jupyter: advnetsci\n",
        "execute:\n",
        "    enabled: true\n",
        "---\n",
        "\n",
        "In March 2020, news outlets worldwide showed charts of COVID-19 cases rising exponentially. Some charts showed linear y-axes with curves shooting upward dramatically. Others used logarithmic y-axes where the same data appeared as straight lines. Politicians cherry-picked time windows to show \"flattening curves.\" The same data told vastly different stories depending on how it was visualized.\n",
        "\n",
        "Or consider stock market charts: show the last month, and a 10% drop looks catastrophic. Zoom out to show the last decade, and the same drop becomes a minor blip barely visible on the chart.\n",
        "\n",
        "Time series data\u0014observations ordered by time\u0014is everywhere. But time is special. Unlike other variables, it flows in one direction, has natural rhythms (daily, seasonal, cyclical), and carries momentum. **Your visualization choices can reveal genuine patterns or create misleading narratives.**\n",
        "\n",
        "The key principle to keep in mind:\n",
        "\n",
        "**Time is special\u0014show how your data changes over time honestly and clearly.**\n",
        "\n",
        "# Why Time Series Visualization Matters\n",
        "\n",
        "Time series visualizations are perhaps the most common type of chart in news media, scientific papers, and business dashboards. They answer fundamental questions: Is this trend going up or down? Are there cycles? When did something change?\n",
        "\n",
        "But they're also easy to manipulate. By selecting the time window, changing the y-axis scale, or choosing different aggregation levels, the same data can support contradictory conclusions.\n",
        "\n",
        "Consider these common pitfalls:\n",
        "- **Truncated y-axes** that exaggerate small changes\n",
        "- **Cherry-picked time windows** that hide long-term trends\n",
        "- **Inappropriate scales** (linear vs. log) that obscure or inflate patterns\n",
        "- **Over-smoothing** that removes real variation\n",
        "- **Under-smoothing** that shows only noise\n",
        "\n",
        "Good time series visualization is about making honest choices that reveal the actual patterns in your data.\n",
        "\n",
        "# Basic Time Series: Line Plots\n",
        "\n",
        "The most fundamental time series visualization is the **line plot**: time on the x-axis, values on the y-axis, points connected by lines."
      ],
      "id": "4aafb6a7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 12,
        "fig-height": 5
      },
      "source": [
        "#| fig-cap: Basic line plot showing a time series with trend and seasonality\n",
        "#| code-fold: true\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"white\")\n",
        "sns.set(font_scale=1.2)\n",
        "\n",
        "# Generate synthetic time series with trend and seasonality\n",
        "np.random.seed(42)\n",
        "n_points = 365\n",
        "dates = pd.date_range('2023-01-01', periods=n_points, freq='D')\n",
        "trend = np.linspace(100, 150, n_points)\n",
        "seasonal = 10 * np.sin(2 * np.pi * np.arange(n_points) / 365 * 4)  # Quarterly seasonality\n",
        "noise = np.random.normal(0, 3, n_points)\n",
        "values = trend + seasonal + noise\n",
        "\n",
        "df = pd.DataFrame({'date': dates, 'value': values})\n",
        "\n",
        "# Create line plot\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "ax.plot(df['date'], df['value'], linewidth=1.5, color=sns.color_palette()[0])\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Value')\n",
        "ax.set_title('Daily Time Series: Line Plot Shows Trend and Seasonality')\n",
        "ax.grid(True, alpha=0.3)\n",
        "sns.despine()"
      ],
      "id": "af5c4651",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The line connecting points implies **continuity**\u0014that values exist between measurements. This is appropriate for continuous processes (temperature, stock prices, heart rate) but not for discrete events or counts measured at intervals.\n",
        "\n",
        "When should you **not** connect the dots? When your data represents discrete events or when measurements are too sparse to imply continuity."
      ],
      "id": "dbfdde48"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 14,
        "fig-height": 5
      },
      "source": [
        "#| fig-cap: 'Line plot vs scatter plot: connecting points implies continuity'\n",
        "#| code-fold: true\n",
        "# Generate sparse discrete event data\n",
        "np.random.seed(123)\n",
        "event_dates = pd.to_datetime(['2023-01-15', '2023-03-10', '2023-05-22',\n",
        "                               '2023-07-08', '2023-09-30', '2023-11-15'])\n",
        "event_values = np.random.randint(20, 80, len(event_dates))\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Line plot (implies continuity - misleading for discrete events)\n",
        "axes[0].plot(event_dates, event_values, marker='o', linewidth=2, markersize=8)\n",
        "axes[0].set_xlabel('Date')\n",
        "axes[0].set_ylabel('Event Count')\n",
        "axes[0].set_title('Line Plot: Implies Values Between Events (Misleading)')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Scatter plot (appropriate for discrete events)\n",
        "axes[1].scatter(event_dates, event_values, s=100, alpha=0.7)\n",
        "axes[1].set_xlabel('Date')\n",
        "axes[1].set_ylabel('Event Count')\n",
        "axes[1].set_title('Scatter Plot: Shows Only Observed Events (Honest)')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "for ax in axes:\n",
        "    sns.despine(ax=ax)\n",
        "\n",
        "plt.tight_layout()"
      ],
      "id": "fe8bd67f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For discrete events, stick with scatter plots or bar charts. Don't imply continuity where none exists.\n",
        "\n",
        "# Comparing Multiple Time Series\n",
        "\n",
        "Often you need to compare several time series. The natural approach is to overlay them on the same plot."
      ],
      "id": "c18f3f7f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 12,
        "fig-height": 6
      },
      "source": [
        "#| fig-cap: Multiple time series overlaid with different colors\n",
        "#| code-fold: true\n",
        "# Generate three related time series\n",
        "np.random.seed(42)\n",
        "dates = pd.date_range('2023-01-01', periods=200, freq='D')\n",
        "\n",
        "series_a = 100 + np.linspace(0, 30, 200) + np.random.normal(0, 5, 200)\n",
        "series_b = 95 + np.linspace(0, 20, 200) + np.random.normal(0, 4, 200)\n",
        "series_c = 110 + np.linspace(0, 10, 200) + np.random.normal(0, 6, 200)\n",
        "\n",
        "df_multi = pd.DataFrame({\n",
        "    'date': dates,\n",
        "    'Product A': series_a,\n",
        "    'Product B': series_b,\n",
        "    'Product C': series_c\n",
        "})\n",
        "\n",
        "# Overlay plot\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "for column in ['Product A', 'Product B', 'Product C']:\n",
        "    ax.plot(df_multi['date'], df_multi[column], linewidth=2, label=column, alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Sales')\n",
        "ax.set_title('Multiple Time Series: Overlaid Comparison')\n",
        "ax.legend(loc='upper left')\n",
        "ax.grid(True, alpha=0.3)\n",
        "sns.despine()"
      ],
      "id": "b2cd5af1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This works well for 2-4 series. Beyond that, you risk creating a **spaghetti plot**\u0014a tangled mess where individual series become impossible to follow.\n",
        "\n",
        "When you have many time series, use **small multiples** (faceting): separate plots arranged in a grid, each with the same axes for easy comparison."
      ],
      "id": "9bc90d7a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 14,
        "fig-height": 8
      },
      "source": [
        "#| fig-cap: Small multiples avoid spaghetti plots when comparing many time series\n",
        "#| code-fold: true\n",
        "# Generate multiple time series\n",
        "np.random.seed(42)\n",
        "n_series = 6\n",
        "dates = pd.date_range('2023-01-01', periods=150, freq='D')\n",
        "\n",
        "data_list = []\n",
        "for i in range(n_series):\n",
        "    values = 50 + np.random.randn(150).cumsum() + 10 * np.sin(2 * np.pi * np.arange(150) / 30)\n",
        "    data_list.append(pd.DataFrame({\n",
        "        'date': dates,\n",
        "        'value': values,\n",
        "        'series': f'Region {i+1}'\n",
        "    }))\n",
        "\n",
        "df_many = pd.concat(data_list, ignore_index=True)\n",
        "\n",
        "# Small multiples using seaborn FacetGrid\n",
        "g = sns.FacetGrid(df_many, col='series', col_wrap=3, height=3, aspect=1.5, sharey=True)\n",
        "g.map_dataframe(sns.lineplot, x='date', y='value', linewidth=2, color=sns.color_palette()[0])\n",
        "g.set_axis_labels('Date', 'Value')\n",
        "g.set_titles('Region {col_name}')\n",
        "for ax in g.axes.flat:\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    sns.despine(ax=ax)\n",
        "\n",
        "plt.tight_layout()"
      ],
      "id": "888f4584",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Small multiples let you see each series clearly while maintaining comparability through shared axes.\n",
        "\n",
        "# The Power of Scale: Linear vs. Logarithmic\n",
        "\n",
        "Perhaps the most consequential choice in time series visualization is the **y-axis scale**. The same data looks completely different on linear vs. logarithmic scales.\n",
        "\n",
        "When should you use a log scale?\n",
        "- When your data spans **multiple orders of magnitude** (e.g., 10 to 10,000)\n",
        "- When you care about **percentage changes** rather than absolute changes\n",
        "- When visualizing **exponential growth or decay**"
      ],
      "id": "2a2c48c3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 14,
        "fig-height": 5
      },
      "source": [
        "#| fig-cap: The same exponential growth looks different on linear vs. log scales\n",
        "#| code-fold: true\n",
        "# Generate exponential growth data (e.g., epidemic spread)\n",
        "np.random.seed(42)\n",
        "days = np.arange(0, 100)\n",
        "cases = 10 * np.exp(0.05 * days) * (1 + np.random.normal(0, 0.1, len(days)))\n",
        "\n",
        "df_exp = pd.DataFrame({'day': days, 'cases': cases})\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Linear scale\n",
        "axes[0].plot(df_exp['day'], df_exp['cases'], linewidth=2, color=sns.color_palette()[0])\n",
        "axes[0].set_xlabel('Days')\n",
        "axes[0].set_ylabel('Cases')\n",
        "axes[0].set_title('Linear Scale: Exponential Growth Looks Explosive')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Log scale\n",
        "axes[1].plot(df_exp['day'], df_exp['cases'], linewidth=2, color=sns.color_palette()[1])\n",
        "axes[1].set_xlabel('Days')\n",
        "axes[1].set_ylabel('Cases (log scale)')\n",
        "axes[1].set_yscale('log')\n",
        "axes[1].set_title('Log Scale: Exponential Growth Appears Linear')\n",
        "axes[1].grid(True, alpha=0.3, which='both')\n",
        "\n",
        "for ax in axes:\n",
        "    sns.despine(ax=ax)\n",
        "\n",
        "plt.tight_layout()"
      ],
      "id": "d21c9d6b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On a **linear scale**, exponential growth appears as a dramatic upward curve\u0014most growth happens at the end. On a **log scale**, exponential growth becomes a straight line, making it easy to see if the growth rate is constant, accelerating, or decelerating.\n",
        "\n",
        "::: {.callout-warning}\n",
        "## Log Scales Can Hide Magnitude\n",
        "\n",
        "While log scales are essential for percentage changes and exponential processes, they can **downplay the absolute magnitude** of changes. A jump from 10,000 to 100,000 cases looks the same as a jump from 100 to 1,000\u0014both are one order of magnitude. But in human terms, 90,000 additional cases is far more significant than 900.\n",
        "\n",
        "**Always consider your audience and what you want to emphasize**: relative changes (use log) or absolute numbers (use linear).\n",
        ":::\n",
        "\n",
        "# Smoothing and Trends\n",
        "\n",
        "Real time series data is often noisy. **Smoothing** helps reveal underlying trends by averaging out short-term fluctuations.\n",
        "\n",
        "The most common approach is a **moving average**: replace each point with the average of nearby points."
      ],
      "id": "f1912707"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 12,
        "fig-height": 6
      },
      "source": [
        "#| fig-cap: Moving averages smooth noise to reveal underlying trends\n",
        "#| code-fold: true\n",
        "# Generate noisy time series\n",
        "np.random.seed(42)\n",
        "dates = pd.date_range('2023-01-01', periods=200, freq='D')\n",
        "trend = 50 + 0.2 * np.arange(200)\n",
        "seasonal = 8 * np.sin(2 * np.pi * np.arange(200) / 30)\n",
        "noise = np.random.normal(0, 5, 200)\n",
        "values = trend + seasonal + noise\n",
        "\n",
        "df_noisy = pd.DataFrame({'date': dates, 'value': values})\n",
        "\n",
        "# Calculate moving averages\n",
        "df_noisy['MA_7'] = df_noisy['value'].rolling(window=7, center=True).mean()\n",
        "df_noisy['MA_30'] = df_noisy['value'].rolling(window=30, center=True).mean()\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "ax.plot(df_noisy['date'], df_noisy['value'], linewidth=0.8, alpha=0.3, label='Raw Data', color='gray')\n",
        "ax.plot(df_noisy['date'], df_noisy['MA_7'], linewidth=2, label='7-Day Moving Average', color=sns.color_palette()[0])\n",
        "ax.plot(df_noisy['date'], df_noisy['MA_30'], linewidth=2, label='30-Day Moving Average', color=sns.color_palette()[1])\n",
        "\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Value')\n",
        "ax.set_title('Moving Averages Reveal Trends by Smoothing Noise')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "sns.despine()"
      ],
      "id": "d41eab95",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The smoothing window creates a trade-off:\n",
        "- **Short windows** (e.g., 7 days) preserve more detail but still show fluctuations\n",
        "- **Long windows** (e.g., 30 days) reveal long-term trends but may over-smooth and miss real changes\n",
        "\n",
        "::: {.callout-note}\n",
        "## Choosing the Right Window\n",
        "\n",
        "The appropriate smoothing window depends on your data's frequency and the patterns you care about:\n",
        "- **Daily stock prices**: 5-20 day moving average\n",
        "- **Monthly sales**: 3-6 month moving average\n",
        "- **Annual measurements**: 3-5 year moving average\n",
        "\n",
        "Match your window to the timescale of meaningful variation in your domain.\n",
        ":::\n",
        "\n",
        "# Showing Uncertainty Over Time\n",
        "\n",
        "When forecasting or estimating, you don't just have point predictions\u0014you have **uncertainty**. Showing this uncertainty is crucial for honest communication.\n",
        "\n",
        "Use **ribbon plots** (also called envelope plots) to show confidence intervals or prediction intervals around your estimates."
      ],
      "id": "a03bf54a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 12,
        "fig-height": 6
      },
      "source": [
        "#| fig-cap: Ribbon plots show uncertainty bands around predictions\n",
        "#| code-fold: true\n",
        "# Generate data with trend\n",
        "np.random.seed(42)\n",
        "n = 150\n",
        "x = np.arange(n)\n",
        "true_trend = 50 + 0.3 * x\n",
        "observed = true_trend + np.random.normal(0, 5, n)\n",
        "\n",
        "# Simple linear forecast\n",
        "from scipy import stats\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(x[:100], observed[:100])\n",
        "\n",
        "# Forecast period\n",
        "x_future = np.arange(100, 150)\n",
        "y_pred = slope * x_future + intercept\n",
        "\n",
        "# Estimate prediction interval (simplified)\n",
        "residuals = observed[:100] - (slope * x[:100] + intercept)\n",
        "std_residual = np.std(residuals)\n",
        "margin = 1.96 * std_residual  # 95% prediction interval\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Historical data\n",
        "ax.plot(x[:100], observed[:100], linewidth=2, label='Historical Data', color=sns.color_palette()[0])\n",
        "\n",
        "# Forecast with uncertainty\n",
        "ax.plot(x_future, y_pred, linewidth=2, label='Forecast', color=sns.color_palette()[1], linestyle='--')\n",
        "ax.fill_between(x_future, y_pred - margin, y_pred + margin,\n",
        "                alpha=0.3, color=sns.color_palette()[1], label='95% Prediction Interval')\n",
        "\n",
        "# Actual future (for comparison)\n",
        "ax.plot(x_future, observed[100:], linewidth=1.5, alpha=0.5, label='Actual (for comparison)',\n",
        "        color='gray', linestyle=':')\n",
        "\n",
        "ax.axvline(x=100, color='black', linestyle=':', alpha=0.5, label='Forecast Start')\n",
        "ax.set_xlabel('Time')\n",
        "ax.set_ylabel('Value')\n",
        "ax.set_title('Time Series Forecast with Uncertainty Bands')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "sns.despine()"
      ],
      "id": "16b93754",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ribbon makes it clear that predictions further into the future are more uncertain. Without showing this uncertainty, forecasts can appear deceptively precise.\n",
        "\n",
        "# Temporal Aggregation: Choosing Your Time Scale\n",
        "\n",
        "How you aggregate time can dramatically change what patterns emerge. The same data aggregated hourly, daily, or monthly reveals different stories.\n",
        "\n",
        "**Heat maps** are excellent for visualizing patterns across two time dimensions\u0014say, hour of day vs. day of week."
      ],
      "id": "9f1506f4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 12,
        "fig-height": 8
      },
      "source": [
        "#| fig-cap: Heat map reveals daily and weekly patterns in temporal data\n",
        "#| code-fold: true\n",
        "# Generate synthetic hourly data with daily and weekly patterns\n",
        "np.random.seed(42)\n",
        "hours = pd.date_range('2023-01-01', periods=24*7*4, freq='H')  # 4 weeks\n",
        "\n",
        "# Patterns: higher activity during business hours and weekdays\n",
        "hour_of_day = hours.hour\n",
        "day_of_week = hours.dayofweek\n",
        "\n",
        "# Activity pattern\n",
        "base_activity = 20\n",
        "hour_effect = 30 * np.exp(-((hour_of_day - 14)**2) / 20)  # Peak at 2 PM\n",
        "weekday_effect = np.where(day_of_week < 5, 20, -10)  # Weekdays higher\n",
        "noise = np.random.normal(0, 5, len(hours))\n",
        "\n",
        "activity = base_activity + hour_effect + weekday_effect + noise\n",
        "\n",
        "df_hourly = pd.DataFrame({\n",
        "    'datetime': hours,\n",
        "    'activity': activity,\n",
        "    'hour': hour_of_day,\n",
        "    'day_name': hours.day_name(),\n",
        "    'week': (hours.day // 7) + 1\n",
        "})\n",
        "\n",
        "# Take first week for heatmap\n",
        "df_week = df_hourly[df_hourly['week'] == 1].copy()\n",
        "\n",
        "# Pivot for heatmap\n",
        "heatmap_data = df_week.pivot_table(values='activity',\n",
        "                                     index='hour',\n",
        "                                     columns='day_name',\n",
        "                                     aggfunc='mean')\n",
        "\n",
        "# Reorder columns to start with Monday\n",
        "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "heatmap_data = heatmap_data[[day for day in day_order if day in heatmap_data.columns]]\n",
        "\n",
        "# Plot heatmap\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "sns.heatmap(heatmap_data, cmap='YlOrRd', annot=False, fmt='.0f',\n",
        "            cbar_kws={'label': 'Activity Level'}, ax=ax)\n",
        "ax.set_xlabel('Day of Week')\n",
        "ax.set_ylabel('Hour of Day')\n",
        "ax.set_title('Temporal Heatmap: Activity by Hour and Day of Week')\n",
        "plt.tight_layout()"
      ],
      "id": "2158fe6c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Heat maps immediately reveal patterns like \"high activity on weekday afternoons\" that would be invisible in a simple line plot.\n",
        "\n",
        "::: {.column-margin}\n",
        "![](https://raw.githubusercontent.com/scottlepp/plot-widget/master/resources/heatmap.png)\n",
        "\n",
        "Calendar heatmaps are widely used for visualizing GitHub contributions, showing commit activity over time in a compact, pattern-revealing format.\n",
        ":::\n",
        "\n",
        "# Visualizing Cycles and Seasonality\n",
        "\n",
        "Many time series have **seasonal patterns**: daily cycles, weekly patterns, annual seasons. **Cycle plots** decompose time series by season to reveal these patterns."
      ],
      "id": "4427a439"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 14,
        "fig-height": 6
      },
      "source": [
        "#| fig-cap: Cycle plot reveals seasonal patterns by separating each cycle\n",
        "#| code-fold: true\n",
        "# Generate monthly data with strong annual seasonality\n",
        "np.random.seed(42)\n",
        "months = pd.date_range('2020-01-01', periods=48, freq='M')\n",
        "month_num = np.tile(np.arange(1, 13), 4)  # 4 years of monthly data\n",
        "\n",
        "# Seasonal pattern (higher in summer, lower in winter)\n",
        "seasonal_effect = 20 * np.sin(2 * np.pi * (month_num - 3) / 12)\n",
        "trend_effect = 0.5 * np.arange(48)\n",
        "noise = np.random.normal(0, 3, 48)\n",
        "\n",
        "values = 50 + seasonal_effect + trend_effect + noise\n",
        "\n",
        "df_seasonal = pd.DataFrame({\n",
        "    'date': months,\n",
        "    'value': values,\n",
        "    'month': month_num,\n",
        "    'year': months.year,\n",
        "    'month_name': months.month_name()\n",
        "})\n",
        "\n",
        "# Create cycle plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Traditional time series\n",
        "axes[0].plot(df_seasonal['date'], df_seasonal['value'], marker='o', linewidth=2)\n",
        "axes[0].set_xlabel('Date')\n",
        "axes[0].set_ylabel('Value')\n",
        "axes[0].set_title('Traditional Time Series: Seasonality Repeats')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Cycle plot\n",
        "month_names_short = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "                     'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "for year in df_seasonal['year'].unique():\n",
        "    year_data = df_seasonal[df_seasonal['year'] == year]\n",
        "    axes[1].plot(year_data['month'], year_data['value'], marker='o',\n",
        "                linewidth=2, label=str(year), alpha=0.7)\n",
        "\n",
        "axes[1].set_xlabel('Month')\n",
        "axes[1].set_ylabel('Value')\n",
        "axes[1].set_xticks(range(1, 13))\n",
        "axes[1].set_xticklabels(month_names_short)\n",
        "axes[1].set_title('Cycle Plot: Each Year Overlaid to Show Seasonal Pattern')\n",
        "axes[1].legend(title='Year')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "for ax in axes:\n",
        "    sns.despine(ax=ax)\n",
        "\n",
        "plt.tight_layout()"
      ],
      "id": "e9eb6a7f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By overlaying each year's cycle, the cycle plot makes it obvious that values peak in summer (months 6-8) and dip in winter (months 12-2), while also showing year-over-year trends.\n",
        "\n",
        "# Advanced: Lag Plots for Autocorrelation\n",
        "\n",
        "Time series data often exhibits **autocorrelation**: values depend on previous values. A **lag plot** helps visualize this by plotting each value against the previous value (lag-1) or earlier values."
      ],
      "id": "88380577"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 14,
        "fig-height": 5
      },
      "source": [
        "#| fig-cap: Lag plots reveal autocorrelation structure in time series\n",
        "#| code-fold: true\n",
        "# Generate time series with autocorrelation\n",
        "np.random.seed(42)\n",
        "n = 200\n",
        "\n",
        "# AR(1) process: strong autocorrelation\n",
        "ar_series = np.zeros(n)\n",
        "ar_series[0] = np.random.normal(0, 1)\n",
        "for i in range(1, n):\n",
        "    ar_series[i] = 0.7 * ar_series[i-1] + np.random.normal(0, 1)\n",
        "\n",
        "# Random walk: perfect autocorrelation at lag 1\n",
        "random_walk = np.random.normal(0, 1, n).cumsum()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Lag-1 plot for AR(1) series\n",
        "axes[0].scatter(ar_series[:-1], ar_series[1:], alpha=0.6, s=30)\n",
        "axes[0].set_xlabel('Value at time t')\n",
        "axes[0].set_ylabel('Value at time t+1')\n",
        "axes[0].set_title('Lag-1 Plot: Strong Autocorrelation (AR Process)')\n",
        "axes[0].plot([-3, 3], [-3, 3], 'r--', alpha=0.5, linewidth=1)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Lag-1 plot for random walk\n",
        "axes[1].scatter(random_walk[:-1], random_walk[1:], alpha=0.6, s=30, color=sns.color_palette()[1])\n",
        "axes[1].set_xlabel('Value at time t')\n",
        "axes[1].set_ylabel('Value at time t+1')\n",
        "axes[1].set_title('Lag-1 Plot: Perfect Autocorrelation (Random Walk)')\n",
        "axes[1].plot([random_walk.min(), random_walk.max()],\n",
        "            [random_walk.min(), random_walk.max()], 'r--', alpha=0.5, linewidth=1)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "for ax in axes:\n",
        "    sns.despine(ax=ax)\n",
        "\n",
        "plt.tight_layout()"
      ],
      "id": "09972362",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A strong linear pattern in a lag plot indicates high autocorrelation\u0014knowing the current value helps predict the next value. Random, scattered points suggest no autocorrelation (e.g., white noise).\n",
        "\n",
        "# The Bigger Picture\n",
        "\n",
        "Time series visualization is about making choices that honestly represent temporal patterns while avoiding common pitfalls:\n",
        "\n",
        "**Key principles to remember:**\n",
        "\n",
        "1. **Choose the right scale**: Linear for absolute changes, log for relative/percentage changes\n",
        "2. **Show uncertainty**: Predictions without confidence intervals are misleading\n",
        "3. **Avoid spaghetti plots**: Use small multiples when comparing many series\n",
        "4. **Match aggregation to your question**: Daily, weekly, monthly aggregation reveals different patterns\n",
        "5. **Be transparent about time windows**: The time range you show matters enormously\n",
        "6. **Smooth appropriately**: Balance between preserving detail and revealing trends\n",
        "\n",
        "**Common pitfalls to avoid:**\n",
        "\n",
        "- Truncating the y-axis to exaggerate small changes\n",
        "- Cherry-picking time windows to support a narrative\n",
        "- Using line plots for discrete events (implies false continuity)\n",
        "- Over-smoothing to hide inconvenient variation\n",
        "- Mixing scales when comparing series (e.g., comparing growth rates on linear scale)\n",
        "\n",
        "Time series visualization is powerful because time is a dimension we all understand intuitively. But that familiarity also makes us vulnerable to manipulation. By following principled visualization practices, you ensure your temporal data tells its true story\u0014not the story you wish it told."
      ],
      "id": "93570a0c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "advnetsci",
      "language": "python",
      "display_name": "Python (advnetsci)",
      "path": "/Users/skojaku-admin/Library/Jupyter/kernels/advnetsci"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}