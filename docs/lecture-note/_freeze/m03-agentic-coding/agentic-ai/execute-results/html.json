{
  "hash": "61327bd49d4e15a5f390ca9b2dfb0a7b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"From ChatBot to Agentic AI\"\nexecute:\n    enabled: true\n---\n\n::: {.callout-note appearance=\"simple\"}\n**Spoiler**: Agents don't \"think\" in the human sense. They loop. They are state machines that use an LLM to decide the next transition.\n:::\n\n## The Mechanism\n\n![ReAct Loop](../figs/react.png){width=\"70%\" fig-align=\"center\"}\n\nThe naive view is that agents are \"smarter\" chatbots. They aren't. They're a core component wrapped in a control loop. A chatbot generates text and stops. An agent generates text, parses it for actionable commands, executes those commands in the real world, observes the results, and feeds those results back into the next prompt. The intelligence doesn't come from the model---it comes from the **feedback loop**.\n\nThis is the **ReAct Pattern** (Reason + Act). A standard chatbot is a pure function: $\\text{Output} = \\text{Model}(\\text{Input})$. An agent is a state machine:\n\n```python\nwhile not task_complete:\n    observation = get_environment_state()\n    thought = model(observation)\n    action = parse_action(thought)\n    result = execute(action)\n    observation = result  # Feedback loop\n```\n\nThe critical insight is the feedback loop. If the agent tries to import a missing library (Action) and receives `ModuleNotFoundError` (Observation), the next iteration's Thought will be \"I need to install this library,\" rather than hallucinating success. The model corrects itself not through introspection, but through collision with reality.\n\nReAct framework is proposed by [@yao2022react]. The core idea is to prompt the LLM to generate both reasoning traces and task-specific actions in an interleaved manner. Specifically, the prompt structure follows a sequence: `Thought` $\\rightarrow$ `Action` $\\rightarrow$ `Observation`.\n\n1.  **Thought**: The model reasons about the current state and what needs to be done.\n2.  **Action**: The model outputs a specific command to interact with an external environment (e.g., `Search[Apple]`).\n3.  **Observation**: The environment executes the action and returns the result (e.g., search results for \"Apple\").\n\nThis cycle repeats until the task is solved.\n\n## The ReAct Framework with `langgraph`\n\nLet's build an agent that can explore and analyze a real dataset. We'll use **LangGraph**—a framework from LangChain that models agents as state machines. Unlike simple loops, LangGraph lets you define explicit control flow: decision nodes, parallel execution, conditional branching, and state persistence.\n\n\n::: {.column-margin}\n\nInstall LangGraph and LangChain:\n\n```bash\npip install langgraph langchain langchain-ollama\n```\n\n:::\n\n### Creating a Tool: A Fish Market Dataset\n\nLet's build an agent that can explore and analyze a real dataset. We'll use the Fish Market dataset from Hugging Face—a collection of measurements from different fish species. First, load the data:\n\n::: {#368fb4eb .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n\n# Load the Fish dataset\ndf = pd.read_csv(\"hf://datasets/scikit-learn/Fish/Fish.csv\")\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Species</th>\n      <th>Weight</th>\n      <th>Length1</th>\n      <th>Length2</th>\n      <th>Length3</th>\n      <th>Height</th>\n      <th>Width</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bream</td>\n      <td>242.0</td>\n      <td>23.2</td>\n      <td>25.4</td>\n      <td>30.0</td>\n      <td>11.5200</td>\n      <td>4.0200</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bream</td>\n      <td>290.0</td>\n      <td>24.0</td>\n      <td>26.3</td>\n      <td>31.2</td>\n      <td>12.4800</td>\n      <td>4.3056</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bream</td>\n      <td>340.0</td>\n      <td>23.9</td>\n      <td>26.5</td>\n      <td>31.1</td>\n      <td>12.3778</td>\n      <td>4.6961</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bream</td>\n      <td>363.0</td>\n      <td>26.3</td>\n      <td>29.0</td>\n      <td>33.5</td>\n      <td>12.7300</td>\n      <td>4.4555</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bream</td>\n      <td>430.0</td>\n      <td>26.5</td>\n      <td>29.0</td>\n      <td>34.0</td>\n      <td>12.4440</td>\n      <td>5.1340</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNow we'll create tools that let the agent query this data. In LangGraph, tools are standard Python functions decorated with `@tool`. The function signature and docstring tell the LLM everything it needs.\n\n::: {.column-margin}\n**@tool**: Decorator that converts a function into a LangChain tool. The docstring becomes the tool description; parameter names and type hints define the schema.\n\n**Args section**: Must be explicitly documented for each parameter. LangGraph parses this to generate the JSON schema the LLM sees.\n:::\n\n::: {#2cc46adc .cell execution_count=2}\n``` {.python .cell-code}\nimport io\nfrom langchain_core.tools import tool\nfrom pandasql import sqldf\n\n@tool\ndef inspect_data() -> str:\n    \"\"\"Get a concise summary of the dataset's structure, including column names, non-null values, and data types.\"\"\"\n    buffer = io.StringIO()\n    df.info(buf=buffer)\n    return buffer.getvalue()\n```\n:::\n\n\nThe structure is minimal. LangGraph infers everything from the function:\n\n1. **Name**: Derived from function name (`inspect_data`)\n2. **Description**: Extracted from the docstring\n3. **Parameters**: Inferred from type hints and docstring Args section\n4. **Return type**: Inferred from return type hint\n\nThis tool takes no inputs and returns the dataset schema. The agent calls it to discover column names and types before writing queries.\n\nLet's add three more tools to give the agent more analytical capabilities:\n\n::: {#2f11ba2b .cell execution_count=3}\n``` {.python .cell-code code-fold=\"true\"}\n@tool\ndef query_data(sql_query: str) -> str:\n    \"\"\"Query the fish dataset using SQL. The table is called 'df'. Use inspect_data first to see available columns. Use find_correlations to find correlations between columns.\n\n    Args:\n        sql_query: SQL query to execute (use 'df' as table name)\n    \"\"\"\n    result = sqldf(sql_query, globals())\n    return result.to_string()\n\n@tool\ndef find_correlations(columns: list[str]) -> str:\n    \"\"\"Calculate the correlation matrix for a list of numeric columns in the fish dataset.\n\n    Args:\n        columns: A list of column names to calculate correlations for.\n    \"\"\"\n    numeric_df = df[columns].select_dtypes(include=['number'])\n    corr_matrix = numeric_df.corr()\n    return corr_matrix.to_string()\n\n@tool\ndef get_stats(column: str, species: str = None) -> str:\n    \"\"\"Get statistical summary (count, mean, std, min, max) for a specific column and optionally filter by species.\n\n    Args:\n        column: Column name to analyze\n        species: Species to filter by (optional)\n    \"\"\"\n    data = df\n    if species:\n        data = df[df[\"Species\"] == species]\n\n    stats = data[column].describe()\n    prefix = f\"Stats for {column}\"\n    if species:\n        prefix += f\" (Species: {species})\"\n    return f\"{prefix}:\\n{stats.to_string()}\"\n```\n:::\n\n\nNow create the agent. LangGraph is centered on a **state graph**—a directed graph where nodes are functions and edges define transitions. This gives you explicit control over the ReAct loop.\n\n::: {.column-margin}\n**ChatOllama**: LangChain's Ollama integration. Supports tool calling via the model's native API.\n\n**create_react_agent**: Factory function that builds a standard ReAct graph. It defines three nodes: (1) call the LLM, (2) execute tools, (3) check if done.\n\n**recursion_limit**: Maximum graph iterations. Equivalent to `max_steps` in smolagents.\n:::\n\n::: {#c89e59b0 .cell execution_count=4}\n``` {.python .cell-code}\nfrom langchain_ollama import ChatOllama\nfrom langgraph.prebuilt import create_react_agent\n\nmodel = ChatOllama(\n    model=\"glm-4.6:cloud\",\n    base_url=\"http://localhost:11434\"\n)\n\ntools = [\n    inspect_data,\n    query_data,\n    find_correlations,\n    get_stats\n]\n\nagent = create_react_agent(model, tools)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/j7/9dgqq5g53vnbsbmvh2yqtckr0000gr/T/ipykernel_89772/1185369839.py:16: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n  agent = create_react_agent(model, tools)\n```\n:::\n:::\n\n\nRun the agent and watch it autonomously choose which tools to use.\n\n::: {#95e78119 .cell execution_count=5}\n``` {.python .cell-code}\nquery = \"Which fish species has the highest average weight?\"\ninputs = {\"messages\": [(\"user\", query)]}\n\nresult = agent.invoke(inputs)\n```\n:::\n\n\n::: {#e0d21c2c .cell execution_count=6}\n``` {.python .cell-code code-fold=\"true\"}\nfor message in result[\"messages\"]:\n    print(message.content)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWhich fish species has the highest average weight?\nI'll help you find which fish species has the highest average weight. Let me first examine the dataset structure to see what columns are available.\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 159 entries, 0 to 158\nData columns (total 7 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   Species  159 non-null    object \n 1   Weight   159 non-null    float64\n 2   Length1  159 non-null    float64\n 3   Length2  159 non-null    float64\n 4   Length3  159 non-null    float64\n 5   Height   159 non-null    float64\n 6   Width    159 non-null    float64\ndtypes: float64(6), object(1)\nmemory usage: 8.8+ KB\n\n\n     Species   AvgWeight\n0       Pike  718.705882\n1      Bream  617.828571\n2  Whitefish  531.000000\n3      Perch  382.239286\n4     Parkki  154.818182\n5      Roach  152.050000\n6      Smelt   11.178571\nThe fish species with the highest average weight is **Pike**, with an average weight of approximately 718.71 grams.\n\nHere are all the species ranked by average weight from highest to lowest:\n1. Pike: 718.71 grams\n2. Bream: 617.83 grams\n3. Whitefish: 531.00 grams\n4. Perch: 382.24 grams\n5. Parkki: 154.82 grams\n6. Roach: 152.05 grams\n7. Smelt: 11.18 grams\n```\n:::\n:::\n\n\nThe agent executes a ReAct loop. It reads the question \"Which fish species has the highest average weight?\" and realizes it needs to use SQL to group by species and calculate averages. LangGraph streams each step—you see the LLM's reasoning, the tool calls, and the observations in real time.\n\nLet's try another query that requires multiple steps:\n\n::: {#bba65ee9 .cell execution_count=7}\n``` {.python .cell-code}\nquery = \"What distinctive physical characteristics stand out to identify Pike?\"\ninputs = {\"messages\": [(\"user\", query)]}\n\nresult = agent.invoke(inputs)\n```\n:::\n\n\n::: {#c46d762e .cell execution_count=8}\n``` {.python .cell-code code-fold=\"true\"}\nfor message in result[\"messages\"]:\n    print(message.content)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWhat distinctive physical characteristics stand out to identify Pike?\nI'll help you identify the distinctive physical characteristics of Pike from the dataset. Let me first explore the dataset structure to understand what information is available.\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 159 entries, 0 to 158\nData columns (total 7 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   Species  159 non-null    object \n 1   Weight   159 non-null    float64\n 2   Length1  159 non-null    float64\n 3   Length2  159 non-null    float64\n 4   Length3  159 non-null    float64\n 5   Height   159 non-null    float64\n 6   Width    159 non-null    float64\ndtypes: float64(6), object(1)\nmemory usage: 8.8+ KB\n\n\n   Species  Weight  Length1  Length2  Length3   Height   Width\n0     Pike   200.0     30.0     32.3     34.8   5.5680  3.3756\n1     Pike   300.0     31.7     34.0     37.8   5.7078  4.1580\n2     Pike   300.0     32.7     35.0     38.8   5.9364  4.3844\n3     Pike   300.0     34.8     37.3     39.8   6.2884  4.0198\n4     Pike   430.0     35.5     38.0     40.5   7.2900  4.5765\n5     Pike   345.0     36.0     38.5     41.0   6.3960  3.9770\n6     Pike   456.0     40.0     42.5     45.5   7.2800  4.3225\n7     Pike   510.0     40.0     42.5     45.5   6.8250  4.4590\n8     Pike   540.0     40.1     43.0     45.8   7.7860  5.1296\n9     Pike   500.0     42.0     45.0     48.0   6.9600  4.8960\n10    Pike   567.0     43.2     46.0     48.7   7.7920  4.8700\n11    Pike   770.0     44.8     48.0     51.2   7.6800  5.3760\n12    Pike   950.0     48.3     51.7     55.1   8.9262  6.1712\n13    Pike  1250.0     52.0     56.0     59.7  10.6863  6.9849\n14    Pike  1600.0     56.0     60.0     64.0   9.6000  6.1440\n15    Pike  1550.0     56.0     60.0     64.0   9.6000  6.1440\n16    Pike  1650.0     59.0     63.4     68.0  10.8120  7.4800\n\n     Species\n0      Bream\n1      Roach\n2  Whitefish\n3     Parkki\n4      Perch\n5       Pike\n6      Smelt\n\nStats for Weight (Species: Pike):\ncount      17.000000\nmean      718.705882\nstd       494.140765\nmin       200.000000\n25%       345.000000\n50%       510.000000\n75%       950.000000\nmax      1650.000000\n\nStats for Height (Species: Pike):\ncount    17.000000\nmean      7.713771\nstd       1.664228\nmin       5.568000\n25%       6.396000\n50%       7.290000\n75%       8.926200\nmax      10.812000\n\nStats for Width (Species: Pike):\ncount    17.000000\nmean      5.086382\nstd       1.140269\nmin       3.375600\n25%       4.322500\n50%       4.870000\n75%       6.144000\nmax       7.480000\n\nStats for Length1 (Species: Pike):\ncount    17.000000\nmean     42.476471\nstd       9.029087\nmin      30.000000\n25%      35.500000\n50%      40.100000\n75%      48.300000\nmax      59.000000\n\nStats for Height:\ncount    159.000000\nmean       8.970994\nstd        4.286208\nmin        1.728400\n25%        5.944800\n50%        7.786000\n75%       12.365900\nmax       18.957000\n\n     Species  AvgHeight  AvgWidth  AvgLength1  Count\n0      Bream  15.183211  5.427614   30.305714     35\n1  Whitefish  10.027167  5.473050   28.800000      6\n2     Parkki   8.962427  3.220736   18.727273     11\n3      Perch   7.861870  4.745723   25.735714     56\n4       Pike   7.713771  5.086382   42.476471     17\n5      Roach   6.694795  3.657850   20.645000     20\n6      Smelt   2.209371  1.340093   11.257143     14\n\n     Species  AvgWidth\n0  Whitefish  5.473050\n1      Bream  5.427614\n2       Pike  5.086382\n3      Perch  4.745723\n4      Roach  3.657850\n5     Parkki  3.220736\n6      Smelt  1.340093\nBased on the fish dataset analysis, I can identify several distinctive physical characteristics that stand out for Pike compared to other species:\n\n## Key Distinguishing Characteristics of Pike:\n\n**1. Length: Pike are significantly longer than most other species**\n- Average Length1: 42.48 cm (highest among all species)\n- Range: 30-59 cm\n- This makes them the longest fish in the dataset\n\n**2. Weight-to-Length Ratio: Pike are relatively lightweight for their length**\n- Despite being the longest, their average weight (718.7g) is lower than Bream's average (626g) \n- This suggests a more slender, streamlined body shape\n\n**3. Height: Moderately tall body**\n- Average Height: 7.71 cm (middle range among species)\n- Less height than Bream (15.18 cm) and Whitefish (10.03 cm)\n- More height than Perch (7.86 cm) and smaller species\n\n**4. Width: Relatively wide body for their size**\n- Average Width: 5.09 cm (3rd highest after Whitefish and Bream)\n- This, combined with their great length, gives them a distinctive elongated but robust body shape\n\n## Summary of Pike's Distinctive Profile:\n- **Very elongated body** (longest species)\n- **Streamlined but substantial** (good width relative to other species)\n- **Moderately tall** (not as flat as some species, not as deep-bodied as others)\n- **Light for their length** (suggests a slender, predatory body shape)\n\nThe most distinctive characteristics that would help identify Pike are their exceptional length combined with substantial width, creating a long, powerful-looking predator fish - which aligns well with real Pike characteristics as elongated predatory fish.\n```\n:::\n:::\n\n\nThis demonstrates the power of the ReAct loop—the agent chains multiple observations together, building a solution step-by-step rather than attempting everything in one shot. Unlike smolagents' opaque loop, LangGraph exposes every state transition, making debugging straightforward.\n\n::: {.callout-note collapse=\"true\"}\n## Why not more complex queries?\n\nYou might notice we're using simpler queries than you'd expect. This is intentional. Real-world agentic systems face reliability challenges:\n\n- **JSON parsing errors**: Models sometimes generate malformed JSON or multiple JSON objects in one response\n- **SQL limitations**: pandasql uses SQLite, which lacks advanced functions like `CORR()` for per-group correlations\n- **Max steps**: Complex queries can hit iteration limits before completing\n\nProduction systems like Claude Code and Cursor handle these issues through better error recovery, more sophisticated prompting, and custom tool implementations. For learning purposes, we focus on simple queries that reliably demonstrate the ReAct pattern.\n:::\n\n# The Takeaway\n\nThis is the entire architecture of Google Antigravity, Claude Code, and Cursor—just scaled with better tools (file editing, terminal commands, web browsing) and better orchestration (parallel agents, verification artifacts).\n\n",
    "supporting": [
      "agentic-ai_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}