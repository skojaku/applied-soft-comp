{
  "hash": "66f9b8f1e356a90de64e3f8e7de6c070",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"From ChatBot to Agentic AI\"\nexecute:\n    enabled: true\n---\n\n::: {.callout-note title=\"What you'll learn in this module\"}\nAgents are not smarter chatbots. They are state machines that loop, using an LLM to decide the next transition. The ReAct pattern (Reason + Act) enables this loop: the agent reasons about the current state, takes an action, observes the result, and feeds that observation back as input. This feedback loop is where intelligence emerges, not from the model itself.\n:::\n\n## The Loop: Where Intelligence Emerges\n\n![ReAct Loop](../figs/react.png){width=\"70%\" fig-align=\"center\"}\n\nLet's shift your attention from what agents are to how they actually work. An agent is not a smarter chatbot. A chatbot generates text and stops. An agent generates text, parses it for actionable commands, executes those commands in the real world, observes the results, and feeds those results back into the next prompt. The intelligence does not come from the model. It comes from the feedback loop.\n\nThis is the **ReAct Pattern**, short for Reason + Act. A chatbot is a pure function: $\\text{Output} = \\text{Model}(\\text{Input})$. An agent is a state machine:\n\n```python\nwhile not task_complete:\n    observation = get_environment_state()\n    thought = model(observation)\n    action = parse_action(thought)\n    result = execute(action)\n    observation = result  # Feedback loop\n```\n\nThe critical insight is the feedback loop. If the agent tries to import a missing library and receives a `ModuleNotFoundError`, the next iteration's thought will be \"I need to install this library.\" It corrects itself not through introspection, but through collision with reality.\n\nThe ReAct framework interleaves reasoning and action in three steps. First, the model reasons about the current state (Thought). Second, it outputs a specific command to interact with the environment (Action). Third, the environment executes that command and returns the result (Observation). This cycle repeats until the task is solved.\n\n## The ReAct Framework with `langgraph`\n\nLet's build an agent that can explore and analyze a real dataset. We'll use **LangGraph**—a framework from LangChain that models agents as state machines. Unlike simple loops, LangGraph lets you define explicit control flow: decision nodes, parallel execution, conditional branching, and state persistence.\n\n\n::: {.callout-note}\n\nInstall LangGraph and LangChain:\n\n```bash\npip install langgraph langchain langchain-ollama\n```\n\n:::\n\n### Creating a Tool: A Fish Market Dataset\n\nLet's build an agent that can explore and analyze a real dataset. We'll use the Fish Market dataset from Hugging Face—a collection of measurements from different fish species. First, load the data:\n\n::: {#905013be .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n\n# Load the Fish dataset\ndf = pd.read_csv(\"hf://datasets/scikit-learn/Fish/Fish.csv\")\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Species</th>\n      <th>Weight</th>\n      <th>Length1</th>\n      <th>Length2</th>\n      <th>Length3</th>\n      <th>Height</th>\n      <th>Width</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bream</td>\n      <td>242.0</td>\n      <td>23.2</td>\n      <td>25.4</td>\n      <td>30.0</td>\n      <td>11.5200</td>\n      <td>4.0200</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bream</td>\n      <td>290.0</td>\n      <td>24.0</td>\n      <td>26.3</td>\n      <td>31.2</td>\n      <td>12.4800</td>\n      <td>4.3056</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bream</td>\n      <td>340.0</td>\n      <td>23.9</td>\n      <td>26.5</td>\n      <td>31.1</td>\n      <td>12.3778</td>\n      <td>4.6961</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bream</td>\n      <td>363.0</td>\n      <td>26.3</td>\n      <td>29.0</td>\n      <td>33.5</td>\n      <td>12.7300</td>\n      <td>4.4555</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bream</td>\n      <td>430.0</td>\n      <td>26.5</td>\n      <td>29.0</td>\n      <td>34.0</td>\n      <td>12.4440</td>\n      <td>5.1340</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNow we'll create tools that let the agent query this data. In LangGraph, tools are standard Python functions decorated with `@tool`. The function signature and docstring tell the LLM everything it needs.\n\n::: {.callout-note}\n**@tool**: Decorator that converts a function into a LangChain tool. The docstring becomes the tool description; parameter names and type hints define the schema.\n\n**Args section**: Must be explicitly documented for each parameter. LangGraph parses this to generate the JSON schema the LLM sees.\n:::\n\n::: {#e9f3677b .cell execution_count=2}\n``` {.python .cell-code}\nimport io\nfrom langchain_core.tools import tool\nfrom pandasql import sqldf\n\n@tool\ndef inspect_data() -> str:\n    \"\"\"Get a concise summary of the dataset's structure, including column names, non-null values, and data types.\"\"\"\n    buffer = io.StringIO()\n    df.info(buf=buffer)\n    return buffer.getvalue()\n```\n:::\n\n\nThe structure is minimal. LangGraph infers everything from the function:\n\n1. **Name**: Derived from function name (`inspect_data`)\n2. **Description**: Extracted from the docstring\n3. **Parameters**: Inferred from type hints and docstring Args section\n4. **Return type**: Inferred from return type hint\n\nThis tool takes no inputs and returns the dataset schema. The agent calls it to discover column names and types before writing queries.\n\nLet's add three more tools to give the agent more analytical capabilities:\n\n::: {#bff7673c .cell execution_count=3}\n``` {.python .cell-code code-fold=\"true\"}\n@tool\ndef query_data(sql_query: str) -> str:\n    \"\"\"Query the fish dataset using SQL. The table is called 'df'. Use inspect_data first to see available columns. Use find_correlations to find correlations between columns.\n\n    Args:\n        sql_query: SQL query to execute (use 'df' as table name)\n    \"\"\"\n    result = sqldf(sql_query, globals())\n    return result.to_string()\n\n@tool\ndef find_correlations(columns: list[str]) -> str:\n    \"\"\"Calculate the correlation matrix for a list of numeric columns in the fish dataset.\n\n    Args:\n        columns: A list of column names to calculate correlations for.\n    \"\"\"\n    numeric_df = df[columns].select_dtypes(include=['number'])\n    corr_matrix = numeric_df.corr()\n    return corr_matrix.to_string()\n\n@tool\ndef get_stats(column: str, species: str = None) -> str:\n    \"\"\"Get statistical summary (count, mean, std, min, max) for a specific column and optionally filter by species.\n\n    Args:\n        column: Column name to analyze\n        species: Species to filter by (optional)\n    \"\"\"\n    data = df\n    if species:\n        data = df[df[\"Species\"] == species]\n\n    stats = data[column].describe()\n    prefix = f\"Stats for {column}\"\n    if species:\n        prefix += f\" (Species: {species})\"\n    return f\"{prefix}:\\n{stats.to_string()}\"\n```\n:::\n\n\nNow create the agent. LangGraph is centered on a **state graph**—a directed graph where nodes are functions and edges define transitions. This gives you explicit control over the ReAct loop.\n\n::: {.callout-note}\n**ChatOllama**: LangChain's Ollama integration. Supports tool calling via the model's native API.\n\n**create_react_agent**: Factory function that builds a standard ReAct graph. It defines three nodes: (1) call the LLM, (2) execute tools, (3) check if done.\n\n**recursion_limit**: Maximum graph iterations. Equivalent to `max_steps` in smolagents.\n:::\n\n::: {#6d68583d .cell execution_count=4}\n``` {.python .cell-code}\nfrom langchain_ollama import ChatOllama\nfrom langgraph.prebuilt import create_react_agent\n\nmodel = ChatOllama(\n    model=\"glm-4.6:cloud\",\n    base_url=\"http://localhost:11434\"\n)\n\ntools = [\n    inspect_data,\n    query_data,\n    find_correlations,\n    get_stats\n]\n\nagent = create_react_agent(model, tools)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/j7/9dgqq5g53vnbsbmvh2yqtckr0000gr/T/ipykernel_7962/1185369839.py:16: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n  agent = create_react_agent(model, tools)\n```\n:::\n:::\n\n\nRun the agent and watch it autonomously choose which tools to use.\n\n::: {#01146c65 .cell execution_count=5}\n``` {.python .cell-code}\nquery = \"Which fish species has the highest average weight?\"\ninputs = {\"messages\": [(\"user\", query)]}\n\nresult = agent.invoke(inputs)\n```\n:::\n\n\n::: {#fd227b1d .cell execution_count=6}\n``` {.python .cell-code code-fold=\"true\"}\nfor message in result[\"messages\"]:\n    print(message.content)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWhich fish species has the highest average weight?\nI'll help you find which fish species has the highest average weight. Let me first examine the dataset structure to understand what columns are available.\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 159 entries, 0 to 158\nData columns (total 7 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   Species  159 non-null    object \n 1   Weight   159 non-null    float64\n 2   Length1  159 non-null    float64\n 3   Length2  159 non-null    float64\n 4   Length3  159 non-null    float64\n 5   Height   159 non-null    float64\n 6   Width    159 non-null    float64\ndtypes: float64(6), object(1)\nmemory usage: 8.8+ KB\n\n\n     Species  avg_weight\n0       Pike  718.705882\n1      Bream  617.828571\n2  Whitefish  531.000000\n3      Perch  382.239286\n4     Parkki  154.818182\n5      Roach  152.050000\n6      Smelt   11.178571\nBased on the data analysis, **Pike** has the highest average weight at 718.71 grams.\n\nHere are all the fish species ranked by average weight:\n\n1. **Pike** - 718.71 grams\n2. **Bream** - 617.83 grams  \n3. **Whitefish** - 531.00 grams\n4. **Perch** - 382.24 grams\n5. **Parkki** - 154.82 grams\n6. **Roach** - 152.05 grams\n7. **Smelt** - 11.18 grams\n\nSo Pike is significantly heavier on average than the other fish species in this dataset.\n```\n:::\n:::\n\n\nThe agent executes a ReAct loop. It reads the question \"Which fish species has the highest average weight?\" and realizes it needs to use SQL to group by species and calculate averages. LangGraph streams each step—you see the LLM's reasoning, the tool calls, and the observations in real time.\n\nLet's try another query that requires multiple steps:\n\n::: {#d1e72a15 .cell execution_count=7}\n``` {.python .cell-code}\nquery = \"What distinctive physical characteristics stand out to identify Pike?\"\ninputs = {\"messages\": [(\"user\", query)]}\n\nresult = agent.invoke(inputs)\n```\n:::\n\n\n::: {#308cd6bc .cell execution_count=8}\n``` {.python .cell-code code-fold=\"true\"}\nfor message in result[\"messages\"]:\n    print(message.content)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWhat distinctive physical characteristics stand out to identify Pike?\nI'll help you identify Pike's distinctive physical characteristics. Let me first explore the fish dataset to see what information is available about Pike and other fish species.\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 159 entries, 0 to 158\nData columns (total 7 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   Species  159 non-null    object \n 1   Weight   159 non-null    float64\n 2   Length1  159 non-null    float64\n 3   Length2  159 non-null    float64\n 4   Length3  159 non-null    float64\n 5   Height   159 non-null    float64\n 6   Width    159 non-null    float64\ndtypes: float64(6), object(1)\nmemory usage: 8.8+ KB\n\n\n```\n:::\n:::\n\n\nThis demonstrates the power of the ReAct loop—the agent chains multiple observations together, building a solution step-by-step rather than attempting everything in one shot. Unlike smolagents' opaque loop, LangGraph exposes every state transition, making debugging straightforward.\n\n::: {.callout-note collapse=\"true\"}\n## Why not more complex queries?\n\nYou might notice we're using simpler queries than you'd expect. This is intentional. Real-world agentic systems face reliability challenges:\n\n- **JSON parsing errors**: Models sometimes generate malformed JSON or multiple JSON objects in one response\n- **SQL limitations**: pandasql uses SQLite, which lacks advanced functions like `CORR()` for per-group correlations\n- **Max steps**: Complex queries can hit iteration limits before completing\n\nProduction systems like Claude Code and Cursor handle these issues through better error recovery, more sophisticated prompting, and custom tool implementations. For learning purposes, we focus on simple queries that reliably demonstrate the ReAct pattern.\n:::\n\n# The Takeaway\n\nThis is the entire architecture of Google Antigravity, Claude Code, and Cursor—just scaled with better tools (file editing, terminal commands, web browsing) and better orchestration (parallel agents, verification artifacts).\n\n",
    "supporting": [
      "agentic-ai_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}