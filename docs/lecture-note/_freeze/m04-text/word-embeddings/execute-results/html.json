{
  "hash": "4f334814f53b674fad961c82933b9dd0",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Word Embeddings\"\njupyter: python3\nexecute:\n    enabled: true\n    cache: true\n---\n\n::: {.callout-note title=\"What you'll learn in this module\"}\nThis module introduces **word embeddings** and the revolutionary Word2Vec algorithm.\n\nYou'll learn:\n\n- How **meaning emerges from relationships** rather than being stored in containers.\n- The technique of **contrastive learning** and how it shapes semantic space through push and pull.\n- How to perform **semantic arithmetic** with vector operations like \"king - man + woman = queen\".\n- The connection between **structural linguistics** and the geometric structure of word embeddings.\n:::\n\n## Words as Relationships, Not Containers\n\nHave you ever wondered where meaning comes from? We intuitively assume words are containers for meaning, that \"Dog\" holds the concept of a canine. This is incorrect. Structural linguistics reveals that a sign is defined solely by its relationships: \"Dog\" means \"dog\" only because it is not \"cat\", \"wolf\", or \"log\". Meaning is differential, not intrinsic.\n\n::: {#fig-structuralism}\n\n![](../figs/word2vec-manga-1.jpg)\n\nGreen is the color that is not non-green (not red, not blue, not yellow, etc.).\n\n:::\n\nWord2Vec, the foundational model grounding modern NLP, learns to map the statistical topology of language. Think of it like mapping a city based purely on traffic data.\n\nYou don't know what a \"school\" is, but you see that \"buses\" and \"children\" congregate there at 8 AM. By placing these entities close together on a map, you reconstruct the city's functional structure. Word2Vec does this for language, turning semantic proximity into geometric distance.\n\n## Exploring Word2Vec\n\nLet's first experience the power of Word2Vec, then understand how it works.\n\nWe'll use a pre-trained model trained on 100 billion words of Google News. We aren't teaching it anything. We're simply inspecting the map it created.\n\n::: {#b1d6d5eb .cell execution_count=2}\n``` {.python .cell-code}\nimport gensim.downloader as api\nimport numpy as np\n\n# Load pre-trained Word2vec embeddings\nprint(\"Loading Word2vec model...\")\nmodel = api.load(\"word2vec-google-news-300\")\nprint(f\"Loaded embeddings for {len(model):,} words.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLoading Word2vec model...\nLoaded embeddings for 3,000,000 words.\n```\n:::\n:::\n\n\nIf the map is accurate, \"dog\" should be surrounded by its semantic kin. We query the nearest neighbors in the vector space.\n\n::: {#437a96f0 .cell execution_count=3}\n``` {.python .cell-code}\nsimilar_to_dog = model.most_similar(\"dog\", topn=10)\n\nprint(\"Words most similar to 'dog':\")\nfor word, similarity in similar_to_dog:\n    print(f\"  {word:20s} {similarity:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWords most similar to 'dog':\n  dogs                 0.868\n  puppy                0.811\n  pit_bull             0.780\n  pooch                0.763\n  cat                  0.761\n  golden_retriever     0.750\n  German_shepherd      0.747\n  Rottweiler           0.744\n  beagle               0.742\n  pup                  0.741\n```\n:::\n:::\n\n\nThe model groups \"dog\" with \"dogs\", \"puppy\", and \"pooch\" not because it knows biology, but because they are statistically interchangeable in sentences.\n\nWhat about semantic arithmetic? Since words are vectors, we can perform arithmetic on meaning. The relationship between \"King\" and \"Man\" is a vector, and if we add that vector to \"Woman\", we should arrive at \"Queen\".\n\n$$ \\vec{\\text{King}} - \\vec{\\text{Man}} + \\vec{\\text{Woman}} \\approx \\vec{\\text{Queen}} $$\n\n::: {#20881f5e .cell execution_count=4}\n``` {.python .cell-code}\nresult = model.most_similar(\n  positive=['king', 'woman'],\n   negative=['man'], topn=5\n)\n\nprint(\"king - man + woman =\")\nfor word, similarity in result:\n    print(f\"  {word:15s} {similarity:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nking - man + woman =\n  queen           0.712\n  monarch         0.619\n  princess        0.590\n  crown_prince    0.550\n  prince          0.538\n```\n:::\n:::\n\n\nHow do we visualize these relationships? We cannot see in 300 dimensions, but we can project the space down to 2D using PCA. This reveals consistent structures like the \"capital city\" relationship that the model has learned.\n\n::: {#035e3f32 .cell fig-height='10' fig-width='12' execution_count=5}\n``` {.python .cell-code code-fold=\"true\"}\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ncountries = [\"Germany\", \"France\", \"Italy\", \"Spain\", \"Portugal\", \"Greece\"]\ncapitals = [\"Berlin\", \"Paris\", \"Rome\", \"Madrid\", \"Lisbon\", \"Athens\"]\n\n# Get embeddings\ncountry_embeddings = np.array([model[country] for country in countries])\ncapital_embeddings = np.array([model[capital] for capital in capitals])\n\n# PCA to 2D\npca = PCA(n_components=2)\nembeddings = np.vstack([country_embeddings, capital_embeddings])\nembeddings_pca = pca.fit_transform(embeddings)\n\n# Create DataFrame\ndf = pd.DataFrame(embeddings_pca, columns=[\"PC1\", \"PC2\"])\ndf[\"Label\"] = countries + capitals\ndf[\"Type\"] = [\"Country\"] * len(countries) + [\"Capital\"] * len(capitals)\n\n# Plot\nfig, ax = plt.subplots(figsize=(12, 10))\n\nfor idx, row in df.iterrows():\n    color = \"#e74c3c\" if row[\"Type\"] == \"Country\" else \"#3498db\"\n    marker = \"o\" if row[\"Type\"] == \"Country\" else \"s\"\n    ax.scatter(\n        row[\"PC1\"],\n        row[\"PC2\"],\n        c=color,\n        marker=marker,\n        s=200,\n        edgecolors=\"black\",\n        linewidth=1.5,\n        alpha=0.7,\n        zorder=3,\n    )\n    ax.text(\n        row[\"PC1\"],\n        row[\"PC2\"] + 0.15,\n        row[\"Label\"],\n        fontsize=12,\n        ha=\"center\",\n        va=\"bottom\",\n        fontweight=\"bold\",\n        bbox=dict(facecolor=\"white\", edgecolor=\"none\", alpha=0.8),\n    )\n\n# Draw arrows\nfor i in range(len(countries)):\n    country_pos = df.iloc[i][[\"PC1\", \"PC2\"]].values\n    capital_pos = df.iloc[i + len(countries)][[\"PC1\", \"PC2\"]].values\n    ax.arrow(\n        country_pos[0],\n        country_pos[1],\n        capital_pos[0] - country_pos[0],\n        capital_pos[1] - country_pos[1],\n        color=\"gray\",\n        alpha=0.6,\n        linewidth=2,\n        head_width=0.15,\n        head_length=0.1,\n        zorder=2,\n    )\n\nax.set_title(\n    'The \"Capital Of\" Relationship as Parallel Transport',\n    fontsize=16,\n    fontweight=\"bold\",\n    pad=20,\n)\nax.grid(alpha=0.3, linestyle=\"--\")\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![The 'Capital Of' relationship appears as a consistent direction in vector space.](word-embeddings_files/figure-html/cell-5-output-1.png){}\n:::\n:::\n\n\n## How Word2Vec Learns Meaning\n\nLet's talk about the mechanism behind the magic. We intuitively treat words as containers that hold meaning, that \"Green\" contains the visual concept of a specific color. This is incorrect. Nature presents us with a messy, continuous spectrum without hard borders, and language is simply the set of arbitrary cuts we make in that continuum to create order.\n\nWord2Vec operationalizes this by treating meaning as a game of contrast, functioning as a pair of linguistic scissors. It does not learn what a word is by looking up a definition. It learns what a word is like by pulling it close to neighbors, and more importantly, it learns what a word is not by pushing it away from random noise.\n\nThe meaning of \"Green\" is simply the geometric region that remains after we have pushed away \"Red\", \"Purple\", and \"Banana\".\n\n::: {#fig-contrastive}\n\n![](../figs/word2vec-manga-2.jpg)\n\nStarting from initially random vectors, word2vec learns iteratively to push away the words that are not related and pull words that are related. The resulting vector space is a map of the relationships between words.\n\n:::\n\nWhat's the underlying technique? This process relies on contrastive learning. We cannot teach the model the exact meaning of each word, but we can let it learn the relationship between words through a binary classification problem: are these two words neighbors, or are they strangers? The training loop provides a positive pair from the text, instructing the model to maximize the similarity between their vectors, while simultaneously grabbing random negative samples (imposters from the vocabulary) and demanding the model minimize their similarity. This push-and-pull mechanic creates the vector space, where the \"Green\" cluster forms not because the model understands color, but because those words are statistically interchangeable when opposed to \"Red\".\n\nHow do we generate training pairs without human labeling? We employ a sliding window technique that moves over the raw text corpus, converting a sequence of words into a system of geometric queries.\n\n::: {#fig-sliding-window}\n\n![](../figs/word2vec-manga-3.jpg)\n\nWithout human labeling, word2vec assumes that words in the same context are related. Context is defined as the words within a window of predefined size. For example, in \"The quick brown fox jumps over the lazy dog\", the context of \"fox\" includes \"brown\", \"jumps\", \"over\", and \"lazy\".\n\n:::\n\nWhat's the neural network architecture? Word2Vec is a simple neural network with one hidden layer. The input is a one-hot encoded vector of a word, which triggers neurons in the hidden layer to fire. The neural connection strength from the neuron representing the word to the neurons in the hidden layer (marked by red arrows) represents the query vector, $u$, while the hidden layer neurons trigger the firing of output layer neurons. The connection strength from an output word neuron to the hidden layer neurons represents the key vector, $v$.\n\n![](../figs/word2vec.jpg)\n\nThe word in the center of the window acts as the Query vector ($u$), broadcasting its position to the surrounding Context words, which act as Keys ($v$). The neural network adjusts its weights to maximize the dot product $u \\cdot v$ for these specific context pairs while suppressing the dot product for the negative samples, making the probability of a word appearing in context a function of their vector alignment.\n\n$$\nP(j \\vert i) = \\frac{P(j) \\exp(u_i \\cdot v_j)}{\\sum_{k=1}^{V} P(k) \\exp(u_i \\cdot v_k)}\n$$\n\nwhere $P(j)$ is the probability of word $j$ appearing in the vocabulary.\n\nWhy do we include $P(j)$ in the formula? The original Word2Vec paper uses a different formulation that omits $P(j)$, which is correct conceptually but not practically. In practice, word2vec is trained with an efficient but biased training algorithm (negative sampling), and the term $P(j)$ enters the $P(j \\vert i)$ when we account for this bias.\n\nThis closes the loop between high-level linguistic philosophy and low-level matrix operations. The machine proves the structuralist hypothesis: that meaning is relational. By mechanically slicing the continuum of language and applying the pressure of negative sampling, the model reconstructs a functional map of human concepts, successfully turning a philosophy of meaning into a runnable algorithm.\n\n::: {#fig-structuralism-loop}\n\n![](../figs/word2vec-manga-4.jpg)\n\n:::\n\n## Key Takeaway\n\nYou don't need to know what a thing is to understand it. You only need to know where it stands relative to everything it isn't.\n\nThere's a nice blog post by Chris McCormick that walks through the inner workings of Word2Vec. See [here](https://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/).\n\n",
    "supporting": [
      "word-embeddings_files"
    ],
    "filters": [],
    "includes": {}
  }
}