{
  "hash": "236ff8458c4736222d8e77f844d631ab",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Network Visualization\"\njupyter: advnetsci\nexecute:\n    enabled: true\n---\n\n::: {.callout-note title=\"What you'll learn in this module\"}\nThis module introduces the art of network visualization. We will explore how to reveal hidden structures using force-directed layouts, examine specific techniques for hierarchical data, and understand how to avoid the dreaded \"hairball\" by matching layout algorithms to your analytical goals.\n:::\n\n## The Art of Structure\n\nYou have probably seen them before: network visualizations that look like tangled balls of yarn, where nodes cluster in impenetrable clumps and edges cross everywhere. These \"hairball diagrams\" are so common in publications that they have become a running joke in network science. The problem isn't that the networks are inherently messy. The problem is that the layout fails to reveal the structure that is actually there.\n\nThe goal of network visualization is not to make pretty pictures. It is to make structure visible. A good layout answers your questions before you even ask them. It shows you if there are communities, if there is a hierarchy, or if certain nodes act as central hubs. A bad layout obscures these answers, no matter how much you adjust the colors or node sizes.\n\nIn this lecture, we will explore how to choose and use network layouts that reveal rather than obscure. We will start with the simplest case of trees, move to general networks with force-directed layouts, and finally explore hierarchical structures that combine both approaches with edge bundling.\n\nThe core principle is simple: Layout is not decoration. It is a hypothesis about what structure matters in your network.\n\n## The Challenge of Position\n\nA network, or graph, is a collection of nodes connected by links. These can represent social relationships, neural connections, or citations between papers. Unlike data points that have inherent positions like latitude and longitude or time stamps, networks have no natural layout. The positions you see in a visualization are entirely constructed by the placement algorithm.\n\nA network $G = (V, E)$ consists of a set of nodes $V = \\{v_1, v_2, ..., v_n\\}$ and a set of edges $E \\subseteq V \\times V$. Edges can be directed (like citations) or undirected (like friendships).\n\nWe visualize networks because topology is hard to grasp from data alone. Looking at an adjacency matrix gives you facts, but it rarely gives you insight. Visualization transforms abstract connectivity into spatial patterns your visual system can process.\n\nChoosing a layout is choosing what to emphasize. Different algorithms can make the same network look completely different, so we must choose wisely.\n\n## Visualizing Trees\n\nThe simplest networks are trees. These are connected networks with no cycles, where every node except the root has exactly one parent. Trees appear everywhere, from biological taxonomies and organizational charts to file systems.\n\nFor trees, the structure is clear and the hierarchy is paramount. The **radial tree layout** makes this hierarchy visible by placing the root at the center and arranging descendants in concentric circles.\n\n::: {#c5659035 .cell fig-height='8' fig-width='8' execution_count=1}\n``` {.python .cell-code code-fold=\"true\"}\nimport graph_tool.all as gt\nimport networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Generate a random tree using NetworkX\nnx_tree = nx.random_labeled_tree(n=50, seed=42)\n\n# Convert to graph-tool\ng = gt.Graph(directed=False)\ng.add_vertex(nx_tree.number_of_nodes())\nfor u, v in nx_tree.edges():\n    g.add_edge(g.vertex(u), g.vertex(v))\n\n# Create radial tree layout\npos = gt.radial_tree_layout(g, g.vertex(0))\n\n# Draw the network (let graph-tool handle rendering directly)\ngt.graph_draw(g, pos=pos,\n              vertex_fill_color=[0.275, 0.510, 0.706, 1],  # steelblue\n              vertex_size=15,\n              edge_color=[0.5, 0.5, 0.5, 1],  # gray\n              edge_pen_width=1.5,\n              output_size=(500, 500),\n              inline=True)\n```\n\n::: {.cell-output .cell-output-display}\n![Radial tree layout of a random tree with 50 nodes. The root is at the center, and descendants are arranged in concentric circles by depth.](networks_files/figure-html/cell-2-output-1.png){width=436 height=500}\n:::\n:::\n\n\nThe radial layout immediately reveals several key properties. It shows the depth of each node, indicating exactly how far it sits from the root. It clarifies the branching structure, highlighting where the tree splits into subtrees. Finally, it exposes the overall balance of the system, instantly showing whether the tree is symmetric or lopsided.\n\n## Force-Directed Layouts\n\nMost networks are not trees. They have cycles, cross-links, and complex connectivity patterns. For these networks, we need algorithms that can handle arbitrary topology. The most common approach is the **force-directed layout**.\n\nThe idea is intuitive. We treat nodes as charged particles that repel each other, and edges as springs that pull connected nodes together. We let the system simulate physics until it reaches equilibrium. Nodes that are closely connected end up near each other, while unconnected parts spread apart.\n\nThe **Fruchterman-Reingold algorithm** is one of the most widely used force-directed methods. It balances the repulsive force between all pairs of nodes against the attractive force of the edges connecting them.\n\nLet's see it in action on the Zachary Karate Club, a famous social network of 34 members of a karate club that eventually split into two factions.\n\n::: {#1856801f .cell fig-height='6' fig-width='14' execution_count=2}\n``` {.python .cell-code code-fold=\"true\"}\nimport graph_tool.all as gt\nimport networkx as nx\nimport numpy as np\n\nnp.random.seed(42)\n\n# Generate a random tree using NetworkX\nnx_tree = nx.random_labeled_tree(n=50, seed=42)\n\n# Convert to graph-tool\ng = gt.Graph(directed=False)\ng.add_vertex(nx_tree.number_of_nodes())\nfor u, v in nx_tree.edges():\n    g.add_edge(g.vertex(u), g.vertex(v))\n\n# Force-directed layout (Fruchterman-Reingold)\npos_force = gt.fruchterman_reingold_layout(g, n_iter=1000)\n\n# Draw force-directed layout inline\ngt.graph_draw(\n    g,\n    pos=pos_force,\n    vertex_fill_color=[1.0, 0.498, 0.314, 1],  # coral\n    vertex_size=15,\n    edge_color=[0.5, 0.5, 0.5, 1],  # gray\n    edge_pen_width=1.5,\n    output_size=(500, 500),\n    inline=True\n)\n```\n\n::: {.cell-output .cell-output-display}\n![Comparison of radial layout (left) vs. force-directed layout (right) for the same tree. The radial layout emphasizes hierarchy, while force-directed layout treats all edges equally.](networks_files/figure-html/cell-3-output-1.png){width=311 height=500}\n:::\n:::\n\n\n::: {#0861840b .cell fig-height='8' fig-width='10' execution_count=3}\n``` {.python .cell-code code-fold=\"true\"}\nimport graph_tool.all as gt\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load the karate club network\ng = gt.collection.data[\"karate\"]\n\n# Get community labels (the two groups that split)\n# We'll use blockmodel inference with 2 communities\nstate = gt.minimize_blockmodel_dl(g, state_args=dict(B=2))\ncommunity = state.get_blocks()\n\n# Create Fruchterman-Reingold layout\npos = gt.fruchterman_reingold_layout(g, n_iter=1000)\n\n# Map communities to colors (RGB tuples)\ncolor_map = {0: [0.906, 0.298, 0.235, 1],  # Red\n             1: [0.204, 0.596, 0.859, 1]}  # Blue\n\n# Create vertex property map for colors\nvertex_color = g.new_vertex_property(\"vector<double>\")\nfor v in g.vertices():\n    vertex_color[v] = color_map[community[v]]\n\n# Draw the network\ngt.graph_draw(g, pos=pos,\n              vertex_fill_color=vertex_color,\n              vertex_size=20,\n              edge_color=[0.584, 0.647, 0.651, 1],\n              edge_pen_width=2,\n              output_size=(1000, 800),\n              inline=True)\n```\n\n::: {.cell-output .cell-output-display}\n![Zachary Karate Club network with Fruchterman-Reingold layout. Node colors indicate the two groups that formed after the club split. The layout naturally separates the two communities.](networks_files/figure-html/cell-4-output-1.png){width=1000 height=476}\n:::\n:::\n\n\nThe Karate Club dataset comes from a study by Wayne Zachary (1977). It documents the split of a university karate club into two factions and remains one of the most famous benchmarks in network science.\n\nThe layout does something remarkable here. Even though we didn't tell the algorithm about the two groups, it naturally separates them in space. This happens because nodes within each group are densely connected, creating a strong attractive pull, while connections between groups are sparse, leading to a weaker pull across the boundary.\n\n### Tuning the Physics\n\nForce-directed algorithms rely on simulation, effectively running a physics engine to find a stable state. The most critical parameter is the **number of iterations**, which dictates how long the simulation runs before stopping.\n\n::: {#2c3eb951 .cell fig-height='4' fig-width='14' execution_count=4}\n``` {.python .cell-code code-fold=\"true\"}\nimport graph_tool.all as gt\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ng = gt.collection.data[\"karate\"]\nstate = gt.minimize_blockmodel_dl(g, state_args=dict(B=2))\ncommunity = state.get_blocks()\ncolor_map = {0: [0.906, 0.298, 0.235, 1],  # Red\n             1: [0.204, 0.596, 0.859, 1]}  # Blue\n\n# Create vertex property map for colors\nvertex_color = g.new_vertex_property(\"vector<double>\")\nfor v in g.vertices():\n    vertex_color[v] = color_map[community[v]]\n\n# Different iteration counts - show progression\nprint(\"50 iterations:\")\npos = gt.fruchterman_reingold_layout(g, n_iter=50)\ngt.graph_draw(g, pos=pos,\n              vertex_fill_color=vertex_color,\n              vertex_size=15,\n              edge_color=[0.584, 0.647, 0.651, 1],\n              edge_pen_width=1.5,\n              output_size=(400, 400),\n              inline=True)\n\nprint(\"\\n500 iterations:\")\npos = gt.fruchterman_reingold_layout(g, n_iter=500)\ngt.graph_draw(g, pos=pos,\n              vertex_fill_color=vertex_color,\n              vertex_size=15,\n              edge_color=[0.584, 0.647, 0.651, 1],\n              edge_pen_width=1.5,\n              output_size=(400, 400),\n              inline=True)\n\nprint(\"\\n5000 iterations:\")\npos = gt.fruchterman_reingold_layout(g, n_iter=5000)\ngt.graph_draw(g, pos=pos,\n              vertex_fill_color=vertex_color,\n              vertex_size=15,\n              edge_color=[0.584, 0.647, 0.651, 1],\n              edge_pen_width=1.5,\n              output_size=(400, 400),\n              inline=True)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n50 iterations:\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Effect of iteration count on force-directed layout quality. Too few iterations (left) produce cramped layouts; optimal iterations (middle) balance clarity and structure; excessive iterations (right) offer minimal improvement.](networks_files/figure-html/cell-5-output-2.png){width=400 height=191}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n500 iterations:\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](networks_files/figure-html/cell-5-output-4.png){width=400 height=241}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n5000 iterations:\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](networks_files/figure-html/cell-5-output-6.png){width=206 height=400}\n:::\n:::\n\n\nWith only 50 iterations, the nodes are still cramped near their initial positions because they haven't had time to spread out. Increasing this to 500 iterations allows the structure to emerge clearly. Pushing to 5000 iterations yields diminishing returns. The layout looks similar, but the computation time increases.\n\nHere is a practical rule of thumb. For small networks (< 100 nodes), try 500-1000 iterations. For medium networks (100-1000 nodes), aim for 1000-2000. For anything larger, you need a different approach.\n\n## Scaling Up with SFDP\n\nThe standard Fruchterman-Reingold algorithm hits a wall as networks grow because it computes forces between every single pair of nodes. For larger networks, we need efficiency. This is where **SFDP (Scalable Force-Directed Placement)** comes in. It uses a multilevel approach, similar to the Barnes-Hut algorithm in physics simulations, to approximate forces efficiently.\n\n::: {#4f0c85fc .cell fig-height='6' fig-width='14' execution_count=5}\n``` {.python .cell-code code-fold=\"true\"}\nimport graph_tool.all as gt\nimport networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\n\n# Generate a larger scale-free network using NetworkX\nnp.random.seed(123)\nnx_g = nx.barabasi_albert_graph(n=500, m=2, seed=123)\n\n# Convert to graph-tool\ng = gt.Graph(directed=False)\ng.add_vertex(nx_g.number_of_nodes())\nfor u, v in nx_g.edges():\n    g.add_edge(g.vertex(u), g.vertex(v))\n\n# Fruchterman-Reingold layout\nprint(\"Fruchterman-Reingold layout:\")\nstart = time.time()\npos_fr = gt.fruchterman_reingold_layout(g, n_iter=500)\ntime_fr = time.time() - start\nprint(f\"Time: {time_fr:.2f}s\")\n\ngt.graph_draw(g, pos=pos_fr,\n              vertex_fill_color=[0.275, 0.510, 0.706, 1],  # steelblue\n              vertex_size=5,\n              edge_color=[0.584, 0.647, 0.651, 1],\n              edge_pen_width=0.5,\n              output_size=(600, 600),\n              inline=True)\n\n# SFDP layout\nprint(\"\\nSFDP layout:\")\nstart = time.time()\npos_sfdp = gt.sfdp_layout(g)\ntime_sfdp = time.time() - start\nprint(f\"Time: {time_sfdp:.2f}s\")\n\ngt.graph_draw(g, pos=pos_sfdp,\n              vertex_fill_color=[1.0, 0.498, 0.314, 1],  # coral\n              vertex_size=5,\n              edge_color=[0.584, 0.647, 0.651, 1],\n              edge_pen_width=0.5,\n              output_size=(600, 600),\n              inline=True)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFruchterman-Reingold layout:\nTime: 9.13s\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Comparison of Fruchterman-Reingold (left) vs. SFDP (right) on a larger network (500 nodes, scale-free topology). SFDP is much faster while producing comparable layouts.](networks_files/figure-html/cell-6-output-2.png){width=552 height=600}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSFDP layout:\nTime: 0.43s\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](networks_files/figure-html/cell-6-output-4.png){width=600 height=585}\n:::\n:::\n\n\nSFDP is often orders of magnitude faster for large networks while producing layouts of comparable quality. Once your network exceeds a few hundred nodes, SFDP should be your default choice.\n\nIt is important to remember that force-directed layouts are non-deterministic. They start from random positions and settle into a local equilibrium, so different runs can produce different orientations. If you need reproducible figures for a paper, always set a random seed. The layout reveals *a* valid structure, not *the* structure.\n\n## Visualizing Hierarchical Structure\n\nMany real-world networks—such as biological systems or large organizations—exhibit hierarchical community structure. This means they have groups nested within groups. Standard force-directed layouts can reveal the primary communities, but they often obscure the nested relationships between them. For this, we use **circular hierarchy layouts with edge bundling**.\n\n### The Nested Block Model\n\nThe first step is to identify the hierarchy. We use the **nested stochastic block model** to partition nodes into communities, then group those communities into super-communities, and so on. This creates a multi-level map of the network's organization.\n\nLet's look at the C. elegans neural network, which maps the complete wiring diagram of a nematode's nervous system.\n\n::: {#0d957063 .cell fig-height='12' fig-width='12' execution_count=6}\n``` {.python .cell-code code-fold=\"true\"}\nimport graph_tool.all as gt\nimport matplotlib.pyplot as plt\n\n# Load C. elegans neural network\ng = gt.collection.data[\"celegansneural\"]\n\n# Infer hierarchical community structure\nstate = gt.minimize_nested_blockmodel_dl(g)\n\n# Draw hierarchy with edge bundling\ngt.draw_hierarchy(state,\n                  beta=0.8,  # Edge bundling strength\n                  output_size=(1200, 1200),\n                  inline=True)\n```\n\n::: {.cell-output .cell-output-display}\n![Hierarchical structure of the C. elegans neural network revealed through nested block model visualization with edge bundling. Inner rings represent higher-level communities, outer ring shows individual neurons. Edge bundling (beta=0.8) reduces visual clutter by routing edges through the hierarchy.](networks_files/figure-html/cell-7-output-1.png){width=1200 height=1196}\n:::\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n(<VertexPropertyMap object with value type 'vector<double>', for Graph 0x33a1d0b90, at 0x107152290>,\n <GraphView object, directed, with 314 vertices and 313 edges, edges filtered by (<EdgePropertyMap object with value type 'bool', for Graph 0x347234250, at 0x34724a150>, False), vertices filtered by (<VertexPropertyMap object with value type 'bool', for Graph 0x347234250, at 0x3472a9710>, False), at 0x347234250>,\n <VertexPropertyMap object with value type 'vector<double>', for Graph 0x347234250, at 0x3470f7810>)\n```\n:::\n:::\n\n\nDanny Holten (2006) introduced hierarchical edge bundling to visualize adjacency relations in hierarchical data. The technique routes edges through their lowest common ancestor in the hierarchy tree, acting like cables tied together to reduce clutter.\n\nThis visualization packs an enormous amount of information into a single image. The concentric rings represent levels of the hierarchy, from coarse inner groups to fine outer details. The colored wedges visually separate different communities. Most importantly, edge bundling acts as a visual compressor. By routing edges through the hierarchy tree, it creates bundled \"highways\" that reveal large-scale connectivity patterns.\n\nWithout edge bundling, this network would look like an incomprehensible hairball. With it, we can see that most connections occur within communities or between closely related ones, exactly what we expect in a modular biological system.\n\n### Tuning Edge Bundling\n\nThe appearance of these plots depends heavily on **beta**, the edge bundling strength. This parameter ranges from 0 (straight lines) to 1 (tightly bundled curves that follow the hierarchy exactly).\n\n::: {#aea04da9 .cell fig-height='6' fig-width='14' execution_count=7}\n``` {.python .cell-code code-fold=\"true\"}\nimport graph_tool.all as gt\nimport matplotlib.pyplot as plt\n\n# Use a smaller network for clearer comparison\ng = gt.collection.data[\"karate\"]\nstate = gt.minimize_nested_blockmodel_dl(g)\n\n# Beta = 0.3 (low bundling)\nprint(\"Beta = 0.3:\")\ngt.draw_hierarchy(state,\n                  beta=0.3,\n                  output_size=(600, 600),\n                  inline=True)\n\n# Beta = 0.9 (high bundling)\nprint(\"\\nBeta = 0.9:\")\ngt.draw_hierarchy(state,\n                  beta=0.9,\n                  output_size=(600, 600),\n                  inline=True)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBeta = 0.3:\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Effect of edge bundling strength (beta) on hierarchical network visualization. Low beta (left) shows individual edges but creates clutter; high beta (right) emphasizes hierarchical structure but may obscure detailed connectivity.](networks_files/figure-html/cell-8-output-2.png){width=600 height=595}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nBeta = 0.9:\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](networks_files/figure-html/cell-8-output-4.png){width=600 height=595}\n:::\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n(<VertexPropertyMap object with value type 'vector<double>', for Graph 0x34720dad0, at 0x347207850>,\n <GraphView object, directed, with 35 vertices and 34 edges, edges filtered by (<EdgePropertyMap object with value type 'bool', for Graph 0x10717ae50, at 0x3472c5b50>, False), vertices filtered by (<VertexPropertyMap object with value type 'bool', for Graph 0x10717ae50, at 0x3472c4850>, False), at 0x10717ae50>,\n <VertexPropertyMap object with value type 'vector<double>', for Graph 0x10717ae50, at 0x34724f350>)\n```\n:::\n:::\n\n\nA low beta value like 0.3 preserves individual edge information but creates visual clutter. A high beta value like 0.9 emphasizes the hierarchical flow of connections, making it easy to see which communities talk to which, but individual edges become hard to trace.\n\nYou should choose beta based on your analytical goal. If you need to trace specific connections, keep beta low (0.3-0.5). If you want to show the overall flow and structure of the system, push beta higher (0.7-0.9).\n\n::: {.callout-important}\n## When to Use Hierarchical Layouts\nCircular hierarchy layouts are powerful but specific. They are only appropriate when your network actually has a hierarchical structure. Forcing a random network into this layout creates the illusion of order where none exists. Always validate your hierarchical partition before visualizing it.\n:::\n\n### Alternative: SFDP for Hierarchies\n\nFor very large hierarchies, the radial layout can become crowded. In these cases, you can combine the SFDP algorithm with the hierarchical structure to position the tree using force-directed placement.\n\n::: {#67ba748f .cell fig-height='10' fig-width='10' execution_count=8}\n``` {.python .cell-code code-fold=\"true\"}\nimport graph_tool.all as gt\nimport matplotlib.pyplot as plt\n\ng = gt.collection.data[\"karate\"]\nstate = gt.minimize_nested_blockmodel_dl(g)\n\ngt.draw_hierarchy(state,\n                  layout=\"sfdp\",\n                  beta=0.8,\n                  output_size=(1000, 1000),\n                  inline=True)\n```\n\n::: {.cell-output .cell-output-display}\n![Hierarchical visualization with SFDP layout for the hierarchy tree. The SFDP algorithm positions hierarchy levels using force-directed placement, which can reveal different structural patterns.](networks_files/figure-html/cell-9-output-1.png){width=978 height=1000}\n:::\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n(<VertexPropertyMap object with value type 'vector<double>', for Graph 0x34720dad0, at 0x34724e210>,\n <GraphView object, directed, with 35 vertices and 34 edges, edges filtered by (<EdgePropertyMap object with value type 'bool', for Graph 0x33a2f5690, at 0x3472c7150>, False), vertices filtered by (<VertexPropertyMap object with value type 'bool', for Graph 0x33a2f5690, at 0x3472c4d90>, False), at 0x33a2f5690>,\n <VertexPropertyMap object with value type 'vector<double>', for Graph 0x33a2f5690, at 0x3472c5a10>)\n```\n:::\n:::\n\n\nThis approach is useful when you want to emphasize local connectivity patterns over strict hierarchical levels, offering a hybrid view of the data.\n\n## The Bigger Picture\n\nEvery layout algorithm embodies a hypothesis about what makes nodes \"similar\" or \"close.\" The radial tree layout assumes hierarchy is the key structure. The force-directed layout assumes that shared neighbors create similarity. The hierarchical layout with edge bundling assumes that a multi-scale community structure organizes the network.\n\nNone of these is objectively \"correct.\" They are different lenses for viewing the same data. The critical skill is matching the layout to the question you are asking.\n\nHowever, network visualization has fundamental limits. Layout is not analysis. A clear visual pattern is a hint, not a proof. You must always validate visual insights with quantitative analysis. 2D layouts lose information. Projecting a high-dimensional graph into two dimensions necessarily distorts distances. Nodes that appear close might not be similar, and nodes that appear far apart might be connected. Large networks do not scale. Once you have thousands of nodes, even the best layouts become unreadable. At that point, you should switch to statistical summaries, aggregation, or interactive tools that allow you to zoom and filter.\n\nWhen publishing network figures, always set a random seed for reproducibility. Label only the most important nodes to avoid clutter, and use color meaningfully to encode communities or attributes. Most importantly, include a caption that explains the layout algorithm so readers know how to interpret the spatial relationships.\n\nSometimes the best visualization is not a network diagram at all. If a simple bar chart of the degree distribution tells the story better than a complex graph, use the bar chart. Visualization is a means to understanding, not an end in itself.\n\n::: {.callout-note title=\"Further Reading\"}\nFor those interested in the deeper mechanics of these visualizations, **Graph-tool** offers comprehensive documentation on all its layout algorithms. Edward Tufte's **The Visual Display of Quantitative Information** remains the gold standard for general visualization principles, and Albert-László Barabási's **Network Science** provides excellent context on interpreting network visuals.\n:::\n\n",
    "supporting": [
      "networks_files"
    ],
    "filters": [],
    "includes": {}
  }
}