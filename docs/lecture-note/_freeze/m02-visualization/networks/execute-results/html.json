{
  "hash": "f6cb8159b913f5dfc7ca180dfd01db1f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Network Visualization\"\njupyter: advnetsci\nexecute:\n    enabled: true\n---\n\nYou've probably seen them before: network visualizations that look like tangled balls of yarn, where nodes cluster in impenetrable clumps and edges cross everywhere. These \"hairball diagrams\" are so common in publications that they've become a running joke in network science. The problem isn't that the networks are inherently messy---it's that **the layout fails to reveal the structure that's actually there**.\n\nThe goal of network visualization is not to make pretty pictures. It's to **make structure visible**. A good layout should help you answer questions: Are there communities? Is there hierarchy? Are certain nodes central? A bad layout obscures these answers, no matter how much you adjust the colors or node sizes.\n\nIn this lecture, we'll explore how to choose and use network layouts that reveal rather than obscure. We'll start with the simplest case---trees---then move to general networks with force-directed layouts, and finally to hierarchical structures that combine both approaches with edge bundling.\n\n**The core principle**: Layout is not decoration. It's a hypothesis about what structure matters in your network.\n\n## What is a Network?\n\nA **network** (or graph) is a collection of **nodes** (also called vertices) connected by **edges** (also called links). Networks can represent almost anything: social relationships, neural connections, citations between papers, roads between cities, or interactions between proteins.\n\n::: {.callout-note}\n## Mathematical Definition\nA network $G = (V, E)$ consists of:\n\n- A set of nodes $V = \\{v_1, v_2, ..., v_n\\}$\n- A set of edges $E \\subseteq V \\times V$ representing connections\n\nNetworks can be **directed** (edges have direction, like citations) or **undirected** (edges are symmetric, like friendships).\n:::\n\nWhy do we visualize networks? Because **topology is hard to grasp from data alone**. Looking at an adjacency matrix or edge list gives you facts but not insight. Visualization transforms abstract connectivity into spatial patterns your visual system can process.\n\nBut here's the challenge: unlike data points that have inherent positions (latitude/longitude, time series), **networks have no natural layout**. The positions you see in a network visualization are entirely constructed by the layout algorithm. Different algorithms can make the same network look completely different.\n\nThis means **choosing a layout is choosing what to emphasize**. Let's see how.\n\n## Visualizing Trees\n\nThe simplest networks are **trees**: connected networks with no cycles. Every node except the root has exactly one parent. Trees appear everywhere: biological taxonomies, organizational charts, file systems, phylogenetic trees, decision trees.\n\nFor trees, the structure is clear: there's a natural hierarchy. The **radial tree layout** makes this hierarchy visible by placing the root at the center and arranging descendants in concentric circles.\n\n::: {#f60f9ec2 .cell fig-height='8' fig-width='8' execution_count=1}\n``` {.python .cell-code code-fold=\"true\"}\nimport graph_tool.all as gt\nimport networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Generate a random tree using NetworkX\nnx_tree = nx.random_labeled_tree(n=50, seed=42)\n\n# Convert to graph-tool\ng = gt.Graph(directed=False)\ng.add_vertex(nx_tree.number_of_nodes())\nfor u, v in nx_tree.edges():\n    g.add_edge(g.vertex(u), g.vertex(v))\n\n# Create radial tree layout\npos = gt.radial_tree_layout(g, g.vertex(0))\n\n# Draw the network (let graph-tool handle rendering directly)\ngt.graph_draw(g, pos=pos,\n              vertex_fill_color=[0.275, 0.510, 0.706, 1],  # steelblue\n              vertex_size=15,\n              edge_color=[0.5, 0.5, 0.5, 1],  # gray\n              edge_pen_width=1.5,\n              output_size=(500, 500),\n              inline=True)\n```\n\n::: {.cell-output .cell-output-display}\n![Radial tree layout of a random tree with 50 nodes. The root is at the center, and descendants are arranged in concentric circles by depth.](networks_files/figure-html/cell-2-output-1.png){width=436 height=500}\n:::\n:::\n\n\nThe radial layout immediately tells you several things:\n\n- **Depth**: How far each node is from the root (distance from center)\n- **Branching structure**: Where the tree splits into subtrees\n- **Balance**: Whether the tree is symmetric or lopsided\n\n## Force-Directed Layouts\n\nMost networks aren't trees. They have cycles, cross-links, and complex connectivity patterns. For these networks, we need algorithms that can handle arbitrary topology. The most common approach is **force-directed layout**.\n\nThe idea is simple: treat nodes as charged particles that repel each other, and edges as springs that pull connected nodes together. Let the system simulate physics until it reaches equilibrium. Nodes that are closely connected end up near each other, while unconnected parts spread apart.\n\nThe **Fruchterman-Reingold algorithm** is one of the most widely used force-directed methods. It balances two forces:\n\n- **Repulsive force**: All pairs of nodes repel each other (like charged particles)\n- **Attractive force**: Connected nodes are pulled together (like springs)\n\nLet's see it in action on a well-known network: the Zachary Karate Club, a social network of 34 members of a karate club, documenting friendships before the club split into two groups.\n\n::: {#53ae8d34 .cell fig-height='6' fig-width='14' execution_count=2}\n``` {.python .cell-code code-fold=\"true\"}\nimport graph_tool.all as gt\nimport networkx as nx\nimport numpy as np\n\nnp.random.seed(42)\n\n# Generate a random tree using NetworkX\nnx_tree = nx.random_labeled_tree(n=50, seed=42)\n\n# Convert to graph-tool\ng = gt.Graph(directed=False)\ng.add_vertex(nx_tree.number_of_nodes())\nfor u, v in nx_tree.edges():\n    g.add_edge(g.vertex(u), g.vertex(v))\n\n# Force-directed layout (Fruchterman-Reingold)\npos_force = gt.fruchterman_reingold_layout(g, n_iter=1000)\n\n# Draw force-directed layout inline\ngt.graph_draw(\n    g,\n    pos=pos_force,\n    vertex_fill_color=[1.0, 0.498, 0.314, 1],  # coral\n    vertex_size=15,\n    edge_color=[0.5, 0.5, 0.5, 1],  # gray\n    edge_pen_width=1.5,\n    output_size=(500, 500),\n    inline=True\n)\n```\n\n::: {.cell-output .cell-output-display}\n![Comparison of radial layout (left) vs. force-directed layout (right) for the same tree. The radial layout emphasizes hierarchy, while force-directed layout treats all edges equally.](networks_files/figure-html/cell-3-output-1.png){width=311 height=500}\n:::\n:::\n\n\n::: {#3f76fc03 .cell fig-height='8' fig-width='10' execution_count=3}\n``` {.python .cell-code code-fold=\"true\"}\nimport graph_tool.all as gt\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load the karate club network\ng = gt.collection.data[\"karate\"]\n\n# Get community labels (the two groups that split)\n# We'll use blockmodel inference with 2 communities\nstate = gt.minimize_blockmodel_dl(g, state_args=dict(B=2))\ncommunity = state.get_blocks()\n\n# Create Fruchterman-Reingold layout\npos = gt.fruchterman_reingold_layout(g, n_iter=1000)\n\n# Map communities to colors (RGB tuples)\ncolor_map = {0: [0.906, 0.298, 0.235, 1],  # Red\n             1: [0.204, 0.596, 0.859, 1]}  # Blue\n\n# Create vertex property map for colors\nvertex_color = g.new_vertex_property(\"vector<double>\")\nfor v in g.vertices():\n    vertex_color[v] = color_map[community[v]]\n\n# Draw the network\ngt.graph_draw(g, pos=pos,\n              vertex_fill_color=vertex_color,\n              vertex_size=20,\n              edge_color=[0.584, 0.647, 0.651, 1],\n              edge_pen_width=2,\n              output_size=(1000, 800),\n              inline=True)\n```\n\n::: {.cell-output .cell-output-display}\n![Zachary Karate Club network with Fruchterman-Reingold layout. Node colors indicate the two groups that formed after the club split. The layout naturally separates the two communities.](networks_files/figure-html/cell-4-output-1.png){width=1000 height=476}\n:::\n:::\n\n\n::: {.column-margin}\n**The Karate Club dataset** comes from a study by Wayne Zachary (1977) documenting the split of a university karate club into two factions. It's one of the most famous small networks in network science.\n:::\n\nThe layout does something remarkable: even though we didn't tell the algorithm about the two groups, **it naturally separates them in space**. This happens because nodes within each group are densely connected (many edges pulling them together), while connections between groups are sparse (less pull across the boundary).\n\n### Tuning Force-Directed Layouts\n\nForce-directed algorithms have parameters that control the final layout. The most important is **the number of iterations**---how long the simulation runs before stopping.\n\n::: {#f04aee9a .cell fig-height='4' fig-width='14' execution_count=4}\n``` {.python .cell-code code-fold=\"true\"}\nimport graph_tool.all as gt\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ng = gt.collection.data[\"karate\"]\nstate = gt.minimize_blockmodel_dl(g, state_args=dict(B=2))\ncommunity = state.get_blocks()\ncolor_map = {0: [0.906, 0.298, 0.235, 1],  # Red\n             1: [0.204, 0.596, 0.859, 1]}  # Blue\n\n# Create vertex property map for colors\nvertex_color = g.new_vertex_property(\"vector<double>\")\nfor v in g.vertices():\n    vertex_color[v] = color_map[community[v]]\n\n# Different iteration counts - show progression\nprint(\"50 iterations:\")\npos = gt.fruchterman_reingold_layout(g, n_iter=50)\ngt.graph_draw(g, pos=pos,\n              vertex_fill_color=vertex_color,\n              vertex_size=15,\n              edge_color=[0.584, 0.647, 0.651, 1],\n              edge_pen_width=1.5,\n              output_size=(400, 400),\n              inline=True)\n\nprint(\"\\n500 iterations:\")\npos = gt.fruchterman_reingold_layout(g, n_iter=500)\ngt.graph_draw(g, pos=pos,\n              vertex_fill_color=vertex_color,\n              vertex_size=15,\n              edge_color=[0.584, 0.647, 0.651, 1],\n              edge_pen_width=1.5,\n              output_size=(400, 400),\n              inline=True)\n\nprint(\"\\n5000 iterations:\")\npos = gt.fruchterman_reingold_layout(g, n_iter=5000)\ngt.graph_draw(g, pos=pos,\n              vertex_fill_color=vertex_color,\n              vertex_size=15,\n              edge_color=[0.584, 0.647, 0.651, 1],\n              edge_pen_width=1.5,\n              output_size=(400, 400),\n              inline=True)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n50 iterations:\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Effect of iteration count on force-directed layout quality. Too few iterations (left) produce cramped layouts; optimal iterations (middle) balance clarity and structure; excessive iterations (right) offer minimal improvement.](networks_files/figure-html/cell-5-output-2.png){width=400 height=191}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n500 iterations:\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](networks_files/figure-html/cell-5-output-4.png){width=400 height=241}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n5000 iterations:\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](networks_files/figure-html/cell-5-output-6.png){width=206 height=400}\n:::\n:::\n\n\nWith too few iterations (50), the nodes haven't had time to spread out properly---they're still clustered near their initial positions. With sufficient iterations (500), the structure becomes clear. Beyond that (5000), you get diminishing returns: the layout looks similar but computation time increases.\n\n::: {.callout-note}\n## Rule of Thumb for Iterations\nFor small networks (< 100 nodes): 500-1000 iterations\nFor medium networks (100-1000 nodes): 1000-2000 iterations\nFor large networks (> 1000 nodes): Consider faster algorithms like SFDP\n:::\n\n### SFDP: Scalable Force-Directed Placement\n\nThe Fruchterman-Reingold algorithm slows down dramatically as networks grow because it computes forces between all pairs of nodes. For large networks, **SFDP (Scalable Force-Directed Placement)** is more efficient. It uses a multilevel approach, similar to the Barnes-Hut algorithm in physics simulations.\n\n::: {#dc43277a .cell fig-height='6' fig-width='14' execution_count=5}\n``` {.python .cell-code code-fold=\"true\"}\nimport graph_tool.all as gt\nimport networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\n\n# Generate a larger scale-free network using NetworkX\nnp.random.seed(123)\nnx_g = nx.barabasi_albert_graph(n=500, m=2, seed=123)\n\n# Convert to graph-tool\ng = gt.Graph(directed=False)\ng.add_vertex(nx_g.number_of_nodes())\nfor u, v in nx_g.edges():\n    g.add_edge(g.vertex(u), g.vertex(v))\n\n# Fruchterman-Reingold layout\nprint(\"Fruchterman-Reingold layout:\")\nstart = time.time()\npos_fr = gt.fruchterman_reingold_layout(g, n_iter=500)\ntime_fr = time.time() - start\nprint(f\"Time: {time_fr:.2f}s\")\n\ngt.graph_draw(g, pos=pos_fr,\n              vertex_fill_color=[0.275, 0.510, 0.706, 1],  # steelblue\n              vertex_size=5,\n              edge_color=[0.584, 0.647, 0.651, 1],\n              edge_pen_width=0.5,\n              output_size=(600, 600),\n              inline=True)\n\n# SFDP layout\nprint(\"\\nSFDP layout:\")\nstart = time.time()\npos_sfdp = gt.sfdp_layout(g)\ntime_sfdp = time.time() - start\nprint(f\"Time: {time_sfdp:.2f}s\")\n\ngt.graph_draw(g, pos=pos_sfdp,\n              vertex_fill_color=[1.0, 0.498, 0.314, 1],  # coral\n              vertex_size=5,\n              edge_color=[0.584, 0.647, 0.651, 1],\n              edge_pen_width=0.5,\n              output_size=(600, 600),\n              inline=True)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFruchterman-Reingold layout:\nTime: 9.02s\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Comparison of Fruchterman-Reingold (left) vs. SFDP (right) on a larger network (500 nodes, scale-free topology). SFDP is much faster while producing comparable layouts.](networks_files/figure-html/cell-6-output-2.png){width=552 height=600}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSFDP layout:\nTime: 0.51s\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](networks_files/figure-html/cell-6-output-4.png){width=583 height=600}\n:::\n:::\n\n\nSFDP is often 10-100x faster for large networks while producing layouts of comparable quality. **For networks with more than a few hundred nodes, SFDP is the better choice**.\n\n::: {.callout-warning}\n## Force-Directed Layouts Are Non-Deterministic\nForce-directed algorithms start from random initial positions and may converge to different layouts each time you run them. Always set a random seed if you need reproducible figures. The layout reveals **a** valid structure, not **the** structure.\n:::\n\n## Visualizing Hierarchical Structure\n\nMany real-world networks have **hierarchical community structure**: groups within groups, like departments within divisions within a company, or species within genera within families. Standard force-directed layouts can reveal communities, but they struggle to show the hierarchical relationships between them.\n\nFor hierarchical networks, we need a different approach: **circular hierarchy layouts with edge bundling**.\n\n### The Nested Block Model Approach\n\nFirst, we need to identify the hierarchical structure. The **nested stochastic block model** finds a hierarchical partition by grouping nodes into communities, then grouping communities into super-communities, and so on. This is exactly what the `draw_hierarchy()` function visualizes.\n\nLet's demonstrate with the C. elegans neural network---the complete wiring diagram of a nematode's nervous system:\n\n::: {#73b70d73 .cell fig-height='12' fig-width='12' execution_count=6}\n``` {.python .cell-code code-fold=\"true\"}\nimport graph_tool.all as gt\nimport matplotlib.pyplot as plt\n\n# Load C. elegans neural network\ng = gt.collection.data[\"celegansneural\"]\n\n# Infer hierarchical community structure\nstate = gt.minimize_nested_blockmodel_dl(g)\n\n# Draw hierarchy with edge bundling\ngt.draw_hierarchy(state,\n                  beta=0.8,  # Edge bundling strength\n                  output_size=(1200, 1200),\n                  inline=True)\n```\n\n::: {.cell-output .cell-output-display}\n![Hierarchical structure of the C. elegans neural network revealed through nested block model visualization with edge bundling. Inner rings represent higher-level communities, outer ring shows individual neurons. Edge bundling (beta=0.8) reduces visual clutter by routing edges through the hierarchy.](networks_files/figure-html/cell-7-output-1.png){width=1200 height=1198}\n:::\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n(<VertexPropertyMap object with value type 'vector<double>', for Graph 0x103a02810, at 0x3306085d0>,\n <GraphView object, directed, with 314 vertices and 313 edges, edges filtered by (<EdgePropertyMap object with value type 'bool', for Graph 0x330641350, at 0x330688050>, False), vertices filtered by (<VertexPropertyMap object with value type 'bool', for Graph 0x330641350, at 0x3306a6b90>, False), at 0x330641350>,\n <VertexPropertyMap object with value type 'vector<double>', for Graph 0x330641350, at 0x33064c610>)\n```\n:::\n:::\n\n\n::: {.column-margin}\n![Hierarchical edge bundling was introduced by Danny Holten (2006) for visualizing hierarchical data. The technique routes edges through their lowest common ancestor in the hierarchy tree.](https://ieeexplore.ieee.org/document/4015425)\n:::\n\nThis visualization packs an enormous amount of information into a single image:\n\n- **Concentric rings**: Each ring represents a level in the hierarchy, from coarse (inner) to fine (outer)\n- **Colored wedges**: Each wedge is a community at that hierarchical level\n- **Edge bundling**: Edges are routed through the hierarchy tree, creating bundles that reveal large-scale connectivity patterns\n\nWithout edge bundling, this network would be an incomprehensible hairball. The bundling reveals that most connections occur within communities or between closely related communities---exactly what you'd expect in a modular biological network.\n\n### Tuning Edge Bundling Strength\n\nThe key parameter is **beta**, which controls how strongly edges are bundled. Beta ranges from 0 (no bundling, straight lines) to 1 (maximum bundling, edges follow the hierarchy tree exactly).\n\n::: {#19bc5d59 .cell fig-height='6' fig-width='14' execution_count=7}\n``` {.python .cell-code code-fold=\"true\"}\nimport graph_tool.all as gt\nimport matplotlib.pyplot as plt\n\n# Use a smaller network for clearer comparison\ng = gt.collection.data[\"karate\"]\nstate = gt.minimize_nested_blockmodel_dl(g)\n\n# Beta = 0.3 (low bundling)\nprint(\"Beta = 0.3:\")\ngt.draw_hierarchy(state,\n                  beta=0.3,\n                  output_size=(600, 600),\n                  inline=True)\n\n# Beta = 0.9 (high bundling)\nprint(\"\\nBeta = 0.9:\")\ngt.draw_hierarchy(state,\n                  beta=0.9,\n                  output_size=(600, 600),\n                  inline=True)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBeta = 0.3:\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Effect of edge bundling strength (beta) on hierarchical network visualization. Low beta (left) shows individual edges but creates clutter; high beta (right) emphasizes hierarchical structure but may obscure detailed connectivity.](networks_files/figure-html/cell-8-output-2.png){width=600 height=595}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nBeta = 0.9:\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](networks_files/figure-html/cell-8-output-4.png){width=600 height=595}\n:::\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n(<VertexPropertyMap object with value type 'vector<double>', for Graph 0x330602210, at 0x33061d150>,\n <GraphView object, directed, with 35 vertices and 34 edges, edges filtered by (<EdgePropertyMap object with value type 'bool', for Graph 0x320af2bd0, at 0x3306a5e90>, False), vertices filtered by (<VertexPropertyMap object with value type 'bool', for Graph 0x320af2bd0, at 0x3306a59d0>, False), at 0x320af2bd0>,\n <VertexPropertyMap object with value type 'vector<double>', for Graph 0x320af2bd0, at 0x330685f90>)\n```\n:::\n:::\n\n\nLow beta (0.3) preserves individual edge information but creates visual clutter. High beta (0.9) emphasizes the hierarchical flow of connections---you can see which communities talk to which---but individual edges become hard to trace.\n\n**Choose beta based on your goal**:\n- To show detailed connectivity: beta = 0.3-0.5\n- To show hierarchical structure: beta = 0.7-0.9\n- General-purpose visualization: beta = 0.6-0.8\n\n::: {.callout-important}\n## When to Use Hierarchical Layouts\nCircular hierarchy layouts are powerful but **only appropriate when your network actually has hierarchical structure**. If you force a random network into this layout, you'll create the illusion of hierarchy where none exists. Always validate the hierarchical partition (e.g., using the description length of the nested block model) before using this visualization.\n:::\n\n### Alternative: SFDP Layout for Hierarchies\n\nYou can also use the SFDP layout algorithm with `draw_hierarchy()`, which positions the hierarchy tree using force-directed placement. This can be useful for very large hierarchies:\n\n::: {#164308ca .cell fig-height='10' fig-width='10' execution_count=8}\n``` {.python .cell-code code-fold=\"true\"}\nimport graph_tool.all as gt\nimport matplotlib.pyplot as plt\n\ng = gt.collection.data[\"karate\"]\nstate = gt.minimize_nested_blockmodel_dl(g)\n\ngt.draw_hierarchy(state,\n                  layout=\"sfdp\",\n                  beta=0.8,\n                  output_size=(1000, 1000),\n                  inline=True)\n```\n\n::: {.cell-output .cell-output-display}\n![Hierarchical visualization with SFDP layout for the hierarchy tree. The SFDP algorithm positions hierarchy levels using force-directed placement, which can reveal different structural patterns.](networks_files/figure-html/cell-9-output-1.png){width=978 height=1000}\n:::\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n(<VertexPropertyMap object with value type 'vector<double>', for Graph 0x330602210, at 0x3306a4ed0>,\n <GraphView object, directed, with 35 vertices and 34 edges, edges filtered by (<EdgePropertyMap object with value type 'bool', for Graph 0x32b237650, at 0x33064c7d0>, False), vertices filtered by (<VertexPropertyMap object with value type 'bool', for Graph 0x32b237650, at 0x33064d250>, False), at 0x32b237650>,\n <VertexPropertyMap object with value type 'vector<double>', for Graph 0x32b237650, at 0x3306a60d0>)\n```\n:::\n:::\n\n\nThe SFDP layout for hierarchies is particularly useful for **very large networks** where the radial layout becomes too crowded, or when you want to emphasize local connectivity patterns over strict hierarchical levels.\n\n## The Bigger Picture: Layout as Hypothesis\n\nEvery layout algorithm embodies a hypothesis about what makes nodes \"similar\" or \"close\":\n\n- **Radial tree layout** hypothesizes that hierarchy is the key structure\n- **Force-directed layout** hypothesizes that shared neighbors create similarity\n- **Hierarchical layout with edge bundling** hypothesizes that multi-scale community structure organizes the network\n\nNone of these is objectively \"correct\"---they're different lenses for viewing the same data. The critical skill is **matching the layout to the question you're asking**.\n\n### Limitations and Caveats\n\nNetwork visualization has fundamental limitations that you need to understand:\n\n**1. Layout is not analysis**. A clear visual pattern doesn't prove that pattern exists in the data---it might be an artifact of the layout algorithm. Always validate visual insights with quantitative analysis (modularity scores, statistical tests, null models).\n\n**2. 2D layouts lose information**. Projecting a high-dimensional graph structure into 2D necessarily distorts distances and relationships. Nodes that appear close might not be similar; nodes that appear far might be connected.\n\n**3. Large networks don't scale**. Once you have thousands of nodes, even the best layouts become unreadable. At that point, consider:\n   - **Aggregation**: Show communities as super-nodes\n   - **Filtering**: Display only the most important nodes/edges\n   - **Interactive tools**: Allow zooming and panning\n   - **Alternative representations**: Adjacency matrices, arc diagrams\n\n**4. Edge crossings are unavoidable** (except for planar graphs). Don't spend hours tweaking layouts to eliminate all crossings---focus on revealing meaningful structure instead.\n\n::: {.callout-note}\n## Best Practices for Publication Figures\n\n- **Always set a random seed** for reproducible force-directed layouts\n- **Label important nodes** (but not all of them---selective annotation is key)\n- **Use color meaningfully** (communities, node attributes) or not at all\n- **Make nodes proportional to importance** (degree, PageRank, betweenness)\n- **Include a caption that explains the layout algorithm** so readers know how to interpret spatial relationships\n- **Provide network statistics** (number of nodes, edges, clustering coefficient) in the caption or main text\n:::\n\n### When Visualization Isn't Enough\n\nSometimes network visualization isn't the right tool at all:\n\n- **Very large networks** (>10,000 nodes): Use statistical summaries (degree distribution, clustering) or dimensionality reduction techniques\n- **Dense networks** (many edges relative to nodes): Adjacency matrices often work better than node-link diagrams\n- **Temporal networks**: Animation rarely works; small multiples or stacked layouts are clearer\n- **Networks with important edge attributes**: Consider matrix representations where you can encode edge weights with color intensity\n\nThe goal is **insight, not aesthetics**. If a bar chart of degree distribution tells the story better than a hairball diagram, use the bar chart. Visualization is a means to understanding, not an end in itself.\n\n### Further Reading\n\n::: {.column-margin}\n**Key References**:\n\n- Holten, D. (2006). \"Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data.\" IEEE TVCG 12(5):741-748.\n- Fruchterman, T.M.J., & Reingold, E.M. (1991). \"Graph Drawing by Force-Directed Placement.\" Software: Practice and Experience 21(11):1129-1164.\n- Peixoto, T.P. (2014). \"Hierarchical Block Structures and High-Resolution Model Selection in Large Networks.\" Physical Review X 4(1):011047.\n:::\n\nNetwork visualization is a rich field with decades of research. For deeper exploration:\n\n- **Graph-tool documentation**: Comprehensive guide to all layout algorithms\n- **The visual display of quantitative information** by Edward Tufte: Principles of effective visualization\n- **Network Science** by Albert-László Barabási: Chapter on network visualization and its interpretation\n\nRemember: **the best layout is the one that helps you answer your question**. Start with the structure you're looking for, then choose the layout that makes that structure visible.\n\n",
    "supporting": [
      "networks_files"
    ],
    "filters": [],
    "includes": {}
  }
}