{
  "hash": "ec5f0a742293d572e512567f6a6d7e8b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"2D Data Visualization\"\njupyter: advnetsci\nexecute:\n    enabled: true\n---\n\nYou've probably heard that \"correlation doesn't equal causation.\" But here's an even more fundamental problem: **a correlation coefficient doesn't tell you what your data actually looks like.**\n\nIn 1973, statistician Francis Anscombe created four datasets that became legendary in data visualization. Each dataset has 11 (x, y) pairs. Each has the same mean for x and y, the same variance, and\u0014most remarkably---the same correlation coefficient (r = 0.816) and the same linear regression line.\n\nBut when you plot them, they tell completely different stories.\n\n::: {#fd92f224 .cell fig-height='10' fig-width='12' execution_count=1}\n``` {.python .cell-code code-fold=\"true\"}\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# Load Anscombe's quartet\nanscombe = sns.load_dataset(\"anscombe\")\n\n# Create the plot\nsns.set_style(\"white\")\ng = sns.FacetGrid(anscombe, col=\"dataset\", col_wrap=2, height=4, aspect=1.2)\ng.map_dataframe(sns.scatterplot, x=\"x\", y=\"y\", s=100)\ng.map_dataframe(sns.regplot, x=\"x\", y=\"y\", scatter=False, color=\"red\")\ng.set_axis_labels(\"X\", \"Y\")\ng.set_titles(\"Dataset {col_name}\")\n\n# Add correlation to each subplot\nfor ax, dataset in zip(g.axes.flat, [\"I\", \"II\", \"III\", \"IV\"]):\n    data_subset = anscombe[anscombe[\"dataset\"] == dataset]\n    r = np.corrcoef(data_subset[\"x\"], data_subset[\"y\"])[0, 1]\n    ax.text(0.05, 0.95, f'r = {r:.3f}', transform=ax.transAxes,\n            verticalalignment='top', fontsize=12, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\nsns.despine()\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![Anscombe's Quartet: Four datasets with identical summary statistics but completely different relationships](2d-data_files/figure-html/cell-2-output-1.png){}\n:::\n:::\n\n\nDataset I shows a nice linear relationship. Dataset II is clearly non-linear---a parabola that a linear model completely misses. Dataset III has a perfect linear relationship except for one outlier that changes everything. Dataset IV shows no relationship except for a single influential point that creates the illusion of correlation.\n\nThe same correlation coefficient. The same regression line. Completely different data.\n\nThis is why we visualize relationships:\n\n**Always plot your bivariate data. Summary statistics conceal structure.**\n\n# Showing All Points: Scatter Plots\n\nThe most direct way to show a relationship between two variables is to plot every point. A **scatter plot** does exactly this: each observation becomes a point in 2D space.\n\n::: {#5764039f .cell fig-height='6' fig-width='10' execution_count=2}\n``` {.python .cell-code code-fold=\"true\"}\n# Generate sample data with clear relationship\nnp.random.seed(42)\nn_points = 200\nx = np.random.normal(50, 15, n_points)\ny = 1.5 * x + np.random.normal(0, 10, n_points)\n\nfig, ax = plt.subplots(figsize=(10, 6))\nax.scatter(x, y, alpha=0.6, s=50, edgecolors='white', linewidth=0.5)\nax.set_xlabel('X Variable')\nax.set_ylabel('Y Variable')\nax.set_title('Scatter Plot: Every Point Visible')\nsns.despine()\n```\n\n::: {.cell-output .cell-output-display}\n![Basic scatter plot showing relationship between two variables](2d-data_files/figure-html/cell-3-output-1.png){}\n:::\n:::\n\n\nFor small to moderate datasets (up to ~1,000 points), scatter plots are perfect. You can see:\n- The strength and direction of the relationship\n- The spread around the trend\n- Individual outliers\n- Non-linear patterns\n- Clusters or subgroups\n\nWhen points overlap heavily, use **transparency (alpha)**. This creates natural density shading---areas with many overlapping points appear darker.\n\n::: {#66232eeb .cell fig-height='5' fig-width='14' execution_count=3}\n``` {.python .cell-code code-fold=\"true\"}\n# Generate data with heavy overlap\nnp.random.seed(123)\nn_points = 1000\nx_overlap = np.random.normal(50, 10, n_points)\ny_overlap = 0.8 * x_overlap + np.random.normal(0, 8, n_points)\n\nfig, axes = plt.subplots(1, 3, figsize=(14, 5))\nalphas = [1.0, 0.5, 0.1]\n\nfor ax, alpha in zip(axes, alphas):\n    ax.scatter(x_overlap, y_overlap, alpha=alpha, s=30)\n    ax.set_xlabel('X Variable')\n    ax.set_ylabel('Y Variable')\n    ax.set_title(f'Alpha = {alpha}')\n    sns.despine(ax=ax)\n\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![Scatter plots with different alpha values showing how transparency reveals density](2d-data_files/figure-html/cell-4-output-1.png){}\n:::\n:::\n\n\nWith alpha = 1.0 (opaque), the center is a solid blob---you can't tell if there are 10 points or 100. With alpha = 0.1, the density gradient becomes visible. Dark regions have many points; light regions have few.\n\n::: {.column-margin}\n\n![](https://www.science.org/cms/10.1126/science.aan8627/asset/d92c8e9c-6bad-48ad-a006-f9e76c62b72a/assets/graphic/358_1042_f3.jpeg)\n\nA figure from [Metaanalysis of faculty's teaching effectiveness](https://www.science.org/doi/10.1126/science.aan8627) showing the relationship between student evaluation of teaching and actual learning. Each bubble represents a course section, with size proportional to the number of students. Notice how transparency reveals the density of observations.\n\n:::\n\nFor extremely dense data where even transparency doesn't help, **jittering** can separate overlapping points by adding small random noise to their positions.\n\n::: {#d38c528f .cell fig-height='5' fig-width='14' execution_count=4}\n``` {.python .cell-code code-fold=\"true\"}\n# Generate data with discrete values (common in survey data)\nnp.random.seed(456)\nn_points = 500\nx_discrete = np.random.choice([1, 2, 3, 4, 5], n_points)\ny_discrete = x_discrete + np.random.choice([-1, 0, 1], n_points) + np.random.normal(0, 0.3, n_points)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Without jitter\naxes[0].scatter(x_discrete, y_discrete, alpha=0.5, s=50)\naxes[0].set_xlabel('X Variable (Discrete)')\naxes[0].set_ylabel('Y Variable')\naxes[0].set_title('Without Jittering')\nsns.despine(ax=axes[0])\n\n# With jitter\njitter_x = x_discrete + np.random.normal(0, 0.1, n_points)\njitter_y = y_discrete + np.random.normal(0, 0.1, n_points)\naxes[1].scatter(jitter_x, jitter_y, alpha=0.5, s=50)\naxes[1].set_xlabel('X Variable (Discrete)')\naxes[1].set_ylabel('Y Variable')\naxes[1].set_title('With Jittering')\nsns.despine(ax=axes[1])\n\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![Jittering helps separate discrete or overlapping points](2d-data_files/figure-html/cell-5-output-1.png){}\n:::\n:::\n\n\nWithout jittering, many points stack on top of each other---you might think there are only 25 data points (5 ï¿½ 5) when there are actually 500. Jittering reveals the true sample size and density at each location.\n\n# When Points Overlap: Binning Methods\n\nWhen you have tens of thousands of points, even transparency and jittering don't fully reveal the density structure. Individual points become less meaningful than the overall pattern. This is when we need to **bin** the data\u0014divide the 2D space into regions and count observations in each.\n\n## 2D Histograms (Heatmaps)\n\nA **2D histogram** extends the 1D histogram concept to two dimensions. The plane is divided into rectangular bins, and each bin's color represents the number of points it contains.\n\n::: {#18b71109 .cell fig-height='7' fig-width='10' execution_count=5}\n``` {.python .cell-code code-fold=\"true\"}\n# Generate large dataset\nnp.random.seed(789)\nn_large = 10000\nx_large = np.random.normal(50, 15, n_large)\ny_large = 0.8 * x_large + np.random.normal(0, 12, n_large)\n\nfig, ax = plt.subplots(figsize=(10, 7))\nhb = ax.hexbin(x_large, y_large, gridsize=30, cmap='YlOrRd', mincnt=1)\nax.set_xlabel('X Variable')\nax.set_ylabel('Y Variable')\nax.set_title('2D Histogram: Density Through Binning')\ncb = plt.colorbar(hb, ax=ax)\ncb.set_label('Count')\nsns.despine()\n```\n\n::: {.cell-output .cell-output-display}\n![2D histogram showing density through rectangular bins](2d-data_files/figure-html/cell-6-output-1.png){}\n:::\n:::\n\n\nThe key parameter is **bin size** (or `gridsize`). Too few bins and you lose detail; too many bins and the plot becomes noisy. Like 1D histograms, this requires experimentation.\n\n::: {#dfdb68e7 .cell fig-height='5' fig-width='14' execution_count=6}\n``` {.python .cell-code code-fold=\"true\"}\nfig, axes = plt.subplots(1, 3, figsize=(14, 5))\ngridsizes = [10, 30, 60]\n\nfor ax, gridsize in zip(axes, gridsizes):\n    hb = ax.hexbin(x_large, y_large, gridsize=gridsize, cmap='YlOrRd', mincnt=1)\n    ax.set_xlabel('X Variable')\n    ax.set_ylabel('Y Variable')\n    ax.set_title(f'Gridsize = {gridsize}')\n    plt.colorbar(hb, ax=ax)\n    sns.despine(ax=ax)\n\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![Effect of bin size on 2D histograms](2d-data_files/figure-html/cell-7-output-1.png){}\n:::\n:::\n\n\nWith gridsize = 10, we see only coarse structure. With gridsize = 60, the plot is noisy\u0014some bins have few points by chance. Gridsize = 30 provides a good balance.\n\n## Hexbin Plots\n\n**Hexagonal binning** uses hexagons instead of rectangles. Hexagons are better for 2D binning because they're closer to circles\u0014every edge is equidistant from the center, reducing bias in how we perceive density.\n\n::: {#34cf7e16 .cell fig-height='5' fig-width='14' execution_count=7}\n``` {.python .cell-code code-fold=\"true\"}\n# Generate data with interesting structure\nnp.random.seed(101)\nn = 8000\n\n# Create two clusters\ncluster1_x = np.random.normal(30, 8, n // 2)\ncluster1_y = np.random.normal(40, 8, n // 2)\ncluster2_x = np.random.normal(60, 10, n // 2)\ncluster2_y = np.random.normal(70, 10, n // 2)\n\nx_clusters = np.concatenate([cluster1_x, cluster2_x])\ny_clusters = np.concatenate([cluster1_y, cluster2_y])\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Scatter plot (for reference)\naxes[0].scatter(x_clusters, y_clusters, alpha=0.1, s=10)\naxes[0].set_xlabel('X Variable')\naxes[0].set_ylabel('Y Variable')\naxes[0].set_title('Scatter Plot (alpha = 0.1)')\nsns.despine(ax=axes[0])\n\n# Hexbin plot\nhb = axes[1].hexbin(x_clusters, y_clusters, gridsize=25, cmap='viridis', mincnt=1)\naxes[1].set_xlabel('X Variable')\naxes[1].set_ylabel('Y Variable')\naxes[1].set_title('Hexbin Plot')\nplt.colorbar(hb, ax=axes[1], label='Count')\nsns.despine(ax=axes[1])\n\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![Hexbin plot provides more perceptually uniform density representation](2d-data_files/figure-html/cell-8-output-1.png){}\n:::\n:::\n\n\nThe hexbin plot clearly reveals the two clusters and their relative densities\u0014something that's harder to see in the scatter plot even with low alpha.\n\nHexbin plots are particularly powerful for **very large datasets** (100,000+ points) where scatter plots become computationally expensive and visually overwhelming.\n\n::: {.callout-note}\n## Choosing colors for density plots\n\nWhen showing density or counts, use **sequential colormaps** that vary in lightness: light = low density, dark = high density. Good choices include:\n- `'YlOrRd'` (yellow-orange-red)\n- `'viridis'` (purple-blue-green-yellow, perceptually uniform)\n- `'Blues'` or `'Reds'` (single hue)\n\nAvoid rainbow colormaps like `'jet'`\u0014they create artificial boundaries where none exist and are not perceptually uniform.\n:::\n\n# Smooth Density Estimation: 2D KDE\n\nJust as 1D kernel density estimation (KDE) provides a smooth alternative to histograms, **2D KDE** smooths 2D histograms by placing a kernel at each data point and summing them.\n\n::: {#98ff7299 .cell fig-height='7' fig-width='10' execution_count=8}\n``` {.python .cell-code code-fold=\"true\"}\n# Use the clustered data\nfig, ax = plt.subplots(figsize=(10, 7))\nsns.kdeplot(x=x_clusters, y=y_clusters, cmap='viridis', fill=True, thresh=0.05, levels=20, ax=ax)\nax.set_xlabel('X Variable')\nax.set_ylabel('Y Variable')\nax.set_title('2D Kernel Density Estimation')\nsns.despine()\n```\n\n::: {.cell-output .cell-output-display}\n![2D kernel density estimation provides smooth density surface](2d-data_files/figure-html/cell-9-output-1.png){}\n:::\n:::\n\n\nKDE reveals smooth density gradients without arbitrary binning decisions. The key parameter is **bandwidth**\u0014how wide each kernel is. Small bandwidth gives high detail but can be noisy; large bandwidth is smooth but may blur important features.\n\n::: {#4fc8dab8 .cell fig-height='5' fig-width='14' execution_count=9}\n``` {.python .cell-code code-fold=\"true\"}\nfig, axes = plt.subplots(1, 3, figsize=(14, 5))\nbandwidths = [0.5, 1.5, 3.0]\n\nfor ax, bw in zip(axes, bandwidths):\n    sns.kdeplot(x=x_clusters, y=y_clusters, cmap='viridis', fill=True,\n                bw_adjust=bw, thresh=0.05, levels=15, ax=ax)\n    ax.set_xlabel('X Variable')\n    ax.set_ylabel('Y Variable')\n    ax.set_title(f'Bandwidth adjustment = {bw}')\n    sns.despine(ax=ax)\n\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![Effect of bandwidth on 2D KDE smoothness](2d-data_files/figure-html/cell-10-output-1.png){}\n:::\n:::\n\n\nWith `bw_adjust=0.5` (narrow bandwidth), we see fine detail but some noise. With `bw_adjust=3.0` (wide bandwidth), the plot is very smooth but the two clusters nearly merge. The default `bw_adjust=1.0` (or around 1.5 here) balances detail and smoothness.\n\n## Contour Plots\n\nA **contour plot** represents the density surface as lines of equal density\u0014like a topographic map where each contour line represents an \"elevation\" of density.\n\n::: {#b113e02c .cell fig-height='6' fig-width='14' execution_count=10}\n``` {.python .cell-code code-fold=\"true\"}\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Filled contours\nsns.kdeplot(x=x_clusters, y=y_clusters, cmap='viridis', fill=True,\n            thresh=0.05, levels=10, ax=axes[0])\naxes[0].set_xlabel('X Variable')\naxes[0].set_ylabel('Y Variable')\naxes[0].set_title('Filled Contour Plot')\nsns.despine(ax=axes[0])\n\n# Line contours with scatter\naxes[1].scatter(x_clusters, y_clusters, alpha=0.1, s=5, c='gray')\nsns.kdeplot(x=x_clusters, y=y_clusters, levels=8, color='red', linewidths=2, ax=axes[1])\naxes[1].set_xlabel('X Variable')\naxes[1].set_ylabel('Y Variable')\naxes[1].set_title('Contour Lines Over Scatter Plot')\nsns.despine(ax=axes[1])\n\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![Contour plot shows density as topographic lines](2d-data_files/figure-html/cell-11-output-1.png){}\n:::\n:::\n\n\nContour plots are excellent for:\n- Overlaying density information on scatter plots\n- Comparing multiple groups (different colored contours)\n- Showing the \"shape\" of the relationship clearly\n\n# Joint Distributions: Combining 2D and 1D\n\nA powerful approach is to show both the **joint (2D) distribution** and the **marginal (1D) distributions** of each variable. This connects 2D visualization back to the 1D methods we learned earlier.\n\nA **joint plot** combines a central 2D plot with 1D histograms or density plots along the margins.\n\n::: {#9f992023 .cell fig-height='10' fig-width='10' execution_count=11}\n``` {.python .cell-code code-fold=\"true\"}\n# Generate data with interesting marginals\nnp.random.seed(202)\nn = 1000\nx_joint = np.concatenate([np.random.normal(30, 10, n//2), np.random.normal(70, 8, n//2)])\ny_joint = np.concatenate([np.random.normal(40, 12, n//2), np.random.normal(60, 10, n//2)])\n\n# Create joint plot\ng = sns.jointplot(x=x_joint, y=y_joint, kind='scatter', alpha=0.5, height=10)\ng.set_axis_labels('X Variable', 'Y Variable')\ng.fig.suptitle('Joint Distribution with Marginal Histograms', y=1.01)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\nText(0.5, 1.01, 'Joint Distribution with Marginal Histograms')\n```\n\nJoint plot combining 2D scatter with marginal 1D distributions\n:::\n\n::: {.cell-output .cell-output-display}\n![](2d-data_files/figure-html/cell-12-output-2.png){}\n:::\n:::\n\n\nThe marginal distributions (top and right) show that both X and Y are bimodal\u0014there are two peaks. But the scatter plot reveals that the peaks are *correlated*: when X is low, Y tends to be low; when X is high, Y tends to be high. This relationship is invisible in the marginals alone.\n\nJoint plots can use different visualizations in the center:\n\n::: {#2caee04e .cell fig-height='10' fig-width='10' execution_count=12}\n``` {.python .cell-code code-fold=\"true\"}\n# Create joint plot with hexbin and KDE\ng = sns.jointplot(x=x_large, y=y_large, kind='hex', height=10,\n                  marginal_kws=dict(bins=30, fill=True))\ng.set_axis_labels('X Variable', 'Y Variable')\ng.fig.suptitle('Joint Plot: Hexbin Center with KDE Margins', y=1.01)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\nText(0.5, 1.01, 'Joint Plot: Hexbin Center with KDE Margins')\n```\n\nJoint plot with hexbin center and KDE margins\n:::\n\n::: {.cell-output .cell-output-display}\n![](2d-data_files/figure-html/cell-13-output-2.png){}\n:::\n:::\n\n\nOr with KDE everywhere:\n\n::: {#07ea02ba .cell fig-height='10' fig-width='10' execution_count=13}\n``` {.python .cell-code code-fold=\"true\"}\ng = sns.jointplot(x=x_clusters, y=y_clusters, kind='kde', height=10,\n                  fill=True, cmap='viridis', thresh=0.05)\ng.set_axis_labels('X Variable', 'Y Variable')\ng.fig.suptitle('Joint Plot: All KDE', y=1.01)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\nText(0.5, 1.01, 'Joint Plot: All KDE')\n```\n\nJoint plot with 2D KDE center and 1D KDE margins\n:::\n\n::: {.cell-output .cell-output-display}\n![](2d-data_files/figure-html/cell-14-output-2.png){}\n:::\n:::\n\n\nJoint plots are particularly useful for:\n- Understanding if marginal distributions are misleading about the relationship\n- Seeing if there's correlation between variables with interesting univariate structure\n- Presenting a complete picture of a bivariate relationship\n\n::: {.column-margin}\n\n**Pro tip**: When presenting data, start with marginal distributions to establish what each variable looks like, then show the joint distribution to reveal the relationship. This guides your audience from the familiar (1D) to the complex (2D).\n\n:::\n\n# Visualizing Relationships Across Groups\n\nOften we want to compare relationships across multiple groups or categories. There are several effective approaches.\n\n## Color coding by group\n\nThe simplest approach is to use different colors for different groups:\n\n::: {#597a3649 .cell fig-height='6' fig-width='10' execution_count=14}\n``` {.python .cell-code code-fold=\"true\"}\n# Generate multi-group data\nnp.random.seed(303)\nn_per_group = 150\n\ngroup_a_x = np.random.normal(40, 12, n_per_group)\ngroup_a_y = 0.7 * group_a_x + np.random.normal(0, 8, n_per_group)\n\ngroup_b_x = np.random.normal(55, 10, n_per_group)\ngroup_b_y = 1.2 * group_b_x + np.random.normal(-20, 10, n_per_group)\n\ngroup_c_x = np.random.normal(60, 15, n_per_group)\ngroup_c_y = 0.3 * group_c_x + np.random.normal(30, 12, n_per_group)\n\ndf_groups = pd.DataFrame({\n    'x': np.concatenate([group_a_x, group_b_x, group_c_x]),\n    'y': np.concatenate([group_a_y, group_b_y, group_c_y]),\n    'group': ['A'] * n_per_group + ['B'] * n_per_group + ['C'] * n_per_group\n})\n\nfig, ax = plt.subplots(figsize=(10, 6))\nfor group, color in zip(['A', 'B', 'C'], sns.color_palette('muted', 3)):\n    subset = df_groups[df_groups['group'] == group]\n    ax.scatter(subset['x'], subset['y'], label=f'Group {group}',\n               alpha=0.6, s=50, color=color, edgecolors='white', linewidth=0.5)\n\nax.set_xlabel('X Variable')\nax.set_ylabel('Y Variable')\nax.set_title('Relationships Across Groups')\nax.legend()\nsns.despine()\n```\n\n::: {.cell-output .cell-output-display}\n![Scatter plot with color-coded groups](2d-data_files/figure-html/cell-15-output-1.png){}\n:::\n:::\n\n\nThis reveals that the three groups have different relationships: Group A has a positive moderate slope, Group B has a steeper positive relationship, and Group C has almost no relationship.\n\n::: {.callout-warning}\n## Simpson's Paradox\n\nBe careful! Sometimes the overall trend (pooling all groups) can be opposite to the trend within each group. This is called **Simpson's Paradox**. Always visualize groups separately to check if pooling is appropriate.\n:::\n\n## Small multiples (faceting)\n\nWhen groups overlap heavily or there are many groups, **small multiples**\u0014separate plots for each group\u0014work better than color coding:\n\n::: {#f6caf70e .cell fig-height='4' fig-width='14' execution_count=15}\n``` {.python .cell-code code-fold=\"true\"}\ng = sns.FacetGrid(df_groups, col='group', height=4, aspect=1.3)\ng.map_dataframe(sns.scatterplot, x='x', y='y', alpha=0.6, s=50)\ng.map_dataframe(sns.regplot, x='x', y='y', scatter=False, color='red')\ng.set_axis_labels('X Variable', 'Y Variable')\ng.set_titles('Group {col_name}')\nsns.despine()\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![Small multiples showing relationship for each group separately](2d-data_files/figure-html/cell-16-output-1.png){}\n:::\n:::\n\n\nSmall multiples make it easy to compare the strength and direction of relationships across groups without visual clutter.\n\n## Contour overlays\n\nFor large datasets, overlaying density contours for each group can be very effective:\n\n::: {#ee43f32b .cell fig-height='7' fig-width='10' execution_count=16}\n``` {.python .cell-code code-fold=\"true\"}\nfig, ax = plt.subplots(figsize=(10, 7))\n\ncolors = sns.color_palette('muted', 3)\nfor group, color in zip(['A', 'B', 'C'], colors):\n    subset = df_groups[df_groups['group'] == group]\n    sns.kdeplot(x=subset['x'], y=subset['y'], levels=5,\n                color=color, linewidths=2, label=f'Group {group}', ax=ax)\n\nax.set_xlabel('X Variable')\nax.set_ylabel('Y Variable')\nax.set_title('Density Contours by Group')\nax.legend()\nsns.despine()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/j7/9dgqq5g53vnbsbmvh2yqtckr0000gr/T/ipykernel_75942/3335885635.py:12: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n  ax.legend()\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Overlaid density contours reveal different relationship shapes](2d-data_files/figure-html/cell-17-output-2.png){}\n:::\n:::\n\n\nThis clearly shows that Groups A and B have elongated, correlated distributions (indicating strong relationships), while Group C is more circular (indicating weak correlation).\n\n# The Bigger Picture\n\nVisualizing bivariate relationships isn't just about making pretty pictures\u0014it's about **seeing patterns that summary statistics conceal**.\n\nWhen you reduce a relationship to a single number (a correlation coefficient, a slope, a p-value), you lose crucial information:\n- Is the relationship linear or curved?\n- Are there outliers driving the result?\n- Are there subgroups with different patterns?\n- Is the relationship consistent across the range of your data?\n\nAnscombe's Quartet taught us this lesson half a century ago, yet papers still report correlations without showing scatter plots. Don't make this mistake.\n\nThe choice of visualization method matters:\n- **Scatter plots** for small to moderate datasets where individual points matter\n- **Hexbin or heatmaps** for large datasets where density matters more than individuals\n- **2D KDE and contours** for smooth, assumption-light density estimation\n- **Joint plots** for connecting bivariate relationships to univariate distributions\n\nBut the most important choice is the simplest: **always plot your data**. Let your audience see what you see. Trust them to interpret patterns, not just summary statistics.\n\nAs statistician John Tukey wrote: \"The greatest value of a picture is when it forces us to notice what we never expected to see.\"\n\n",
    "supporting": [
      "2d-data_files"
    ],
    "filters": [],
    "includes": {}
  }
}