---
title: "Overview"
---

::: {.callout-note title="What you'll learn in this module"}
This module explores how machine learning sees the world through a structuralist lens.

You'll learn:

- Why we **draw boundaries** where none exist in continuous reality.
- How **meaning emerges from relationships** rather than fixed definitions.
- What **vector representations** reveal about the continuous nature of concepts.
- How **embeddings dissolve artificial divisions** while preserving relational structure.
- The philosophical thread from **linguistic structuralism** to modern machine learning.
:::

Have you ever wondered where one category ends and another begins? The world is continuous, but we carve it into categories. Is a 17-year-old fundamentally different from an 18-year-old? Where exactly does "blue" end and "green" begin?

These divisions feel natural because language demands them. But they're artifacts of how we choose to see.

Machine learning faces the same tension. Traditional approaches force continuous phenomena into discrete boxes. Classification draws hard decision boundaries. Networks define nodes with sharp edges.

But a new generation of techniques embraces continuity. They represent concepts as vectors in high-dimensional space. Meaning emerges from geometric relationships rather than categorical assignments.

This module traces a philosophical thread from linguistic structuralism to modern representation learning. You'll understand why boundaries are observer-dependent. You'll see how cultures slice reality differently. You'll discover how vector embeddings dissolve artificial divisions while preserving the relational structure that gives things meaning.

## The Illusion of Boundaries

Let's start by questioning the categories we take for granted. Regional dialects, generational labels, and even physical objects have fuzzy boundaries that we artificially sharpen.

See [Part 1: When Boundaries Blur](01-boundaries.qmd).

## The Structuralist Perspective

Here's a radical idea. Language doesn't label pre-existing categories. It creates them through contrast. A word means what it means because of what it is not.

We'll explore how Saussure, Buddhist logic, and structural anthropology all converge on this insight. Discover [Part 2: Meaning as Difference](02-structuralism.qmd).

## Vector Representations

What happens when we take structuralism seriously? Word2Vec and modern embedding techniques operationalize this philosophical insight. By mapping concepts into continuous vector space, they restore the gradation that categorical thinking destroys.

Learn how [Part 3: From Categories to Coordinates](03-embeddings.qmd) transforms discrete symbols into geometric relationships.

## Beyond Text

The representational insight extends far beyond language. Networks become embedded in continuous space. Images map to semantic coordinates. Time series become trajectories through latent dimensions.

Explore [Part 4: Universal Representations](04-universal.qmd) to see how this perspective unifies machine learning.
