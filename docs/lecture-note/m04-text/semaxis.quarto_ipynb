{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"SemAxis: Meaning as Direction\"\n",
        "execute:\n",
        "    enabled: true\n",
        "---\n",
        "\n",
        "::: {.callout-note title=\"What you'll learn in this module\"}\n",
        "Meaning in embeddings emerges entirely from contrast, not from inherent word properties. SemAxis provides a framework for defining semantic dimensions by subtracting antonym vectors, isolating specific axes that reveal how words align on dimensions like sentiment, intensity, or any conceptual opposition.\n",
        ":::\n",
        "\n",
        "## Embedding Space as Contrast\n",
        "\n",
        "We intuitively treat word embeddings as static maps where \"king\" is simply near \"queen\". We assume the meaning is inherent to the coordinate itself, much like a city has a fixed latitude and longitude. This is a convenient fiction. In embedding space, meaning emerges entirely from contrast, which is the key concept of SemAxis.\n",
        "\n",
        "SemAxis is a way to define a semantic axis by subtracting the vector of an antonym from a word (e.g., $v_{good} - v_{bad}$). This isolates a semantic dimension, an \"axis\", that ignores all other information.\n",
        "\n",
        "Formally, given two pole words $w_+$ and $w_-$, the axis is defined as:\n",
        "\n",
        "$$\n",
        "v_{\\text{axis}} = \\frac{v_{w_+} - v_{w_-}}{||v_{w_+} - v_{w_-}\\||_2}\n",
        "$$\n",
        "\n",
        "where the denominator is the $L_2$ norm of the difference vector that ensures the axis vector $v_{\\text{axis}}$ is a unit vector. Using this \"ruler\", we project words into this axis. Operationally, the position of a word $w$ is given by the cosine similarity between $v_{w}$ and $v_{\\text{axis}}$.\n",
        "\n",
        "$$\n",
        "\\text{Position of w on axis } v_{\\text{axis}} = \\cos(v_{\\text{axis}},v_{w})\n",
        "$$\n",
        "\n",
        "Let's build a \"Sentiment Compass\" to measure the emotional charge of words that aren't explicitly emotional.\n",
        "\n",
        "First, we load the standard GloVe embeddings."
      ],
      "id": "b6ed0d65"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim.downloader as api\n",
        "\n",
        "# Download and load pre-trained GloVe embeddings\n",
        "model = api.load(\"glove-wiki-gigaword-100\")"
      ],
      "id": "6e6cb7b2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the Axis\n",
        "\n",
        "We define the axis not as a point, but as the difference vector between two poles. This vector points from \"bad\" to \"good\"."
      ],
      "id": "29ebc860"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def create_axis(pos_word, neg_word, model):\n",
        "    return model[pos_word] - model[neg_word]\n",
        "\n",
        "\n",
        "# The \"Sentiment\" Axis\n",
        "sentiment_axis = create_axis(\"good\", \"bad\", model)"
      ],
      "id": "0892f582",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measuring Alignment\n",
        "\n",
        "To see where a word falls on this axis, we project it. Mathematically, this is the dot product (normalized). If the vector points in the same direction, the score is positive. If it points away, it is negative."
      ],
      "id": "211f26ca"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_score(word, axis, model):\n",
        "    v_word = model[word]\n",
        "    # Cosine similarity is just a normalized dot product\n",
        "    return np.dot(v_word, axis) / (np.linalg.norm(v_word) * np.linalg.norm(axis))\n",
        "\n",
        "\n",
        "words = [\"excellent\", \"terrible\", \"mediocre\", \"stone\", \"flower\"]\n",
        "for w in words:\n",
        "    print(f\"{w}: {get_score(w, sentiment_axis, model):.3f}\")"
      ],
      "id": "ed7abf5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Robustness via Centroids\n",
        "\n",
        "Single words are noisy. \"Bad\" might carry connotations of \"naughty\" or \"poor quality\". To fix this, we don't use single words. We use the centroid of a cluster of synonyms. This averages out the noise and leaves only the pure semantic signal."
      ],
      "id": "74a3299e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def create_robust_axis(pos_word, neg_word, model, k=5):\n",
        "    # Get k nearest neighbors for both poles\n",
        "    pos_group = [pos_word]\n",
        "    pos_words = model.most_similar(pos_word, topn=k)\n",
        "    for word, _ in pos_words:\n",
        "        pos_group.append(word)\n",
        "\n",
        "    neg_group = [neg_word]\n",
        "    neg_words = model.most_similar(neg_word, topn=k)\n",
        "    for word, _ in neg_words:\n",
        "        neg_group.append(word)\n",
        "\n",
        "    # Average them to find the centroid\n",
        "    pos_vec = np.mean([model[w] for w in pos_group], axis=0)\n",
        "    neg_vec = np.mean([model[w] for w in neg_group], axis=0)\n",
        "\n",
        "    return pos_vec - neg_vec\n",
        "\n",
        "\n",
        "robust_axis = create_robust_axis(\"good\", \"bad\", model)"
      ],
      "id": "273ed77d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The 2D Semantic Space\n",
        "\n",
        "The real power comes when we cross two axes. By plotting words against \"Sentiment\" and \"Intensity\" (Strong vs. Weak), we reveal relationships that a single list hides."
      ],
      "id": "7bc7777d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| fig-cap: \"2D Semantic Space\"\n",
        "#| fig-align: \"center\"\n",
        "def plot_2d(words, axis_x, axis_y, model):\n",
        "    x_scores = [get_score(w, axis_x, model) for w in words]\n",
        "    y_scores = [get_score(w, axis_y, model) for w in words]\n",
        "\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.scatter(x_scores, y_scores)\n",
        "\n",
        "    for i, w in enumerate(words):\n",
        "        plt.annotate(\n",
        "            w,\n",
        "            (x_scores[i], y_scores[i]),\n",
        "            xytext=(5, 5),\n",
        "            textcoords=\"offset points\",\n",
        "            fontsize=16,\n",
        "        )\n",
        "\n",
        "    plt.axhline(0, color=\"k\", alpha=0.3)\n",
        "    plt.axvline(0, color=\"k\", alpha=0.3)\n",
        "    plt.xlabel(\"Sentiment (Bad -> Good)\")\n",
        "    plt.ylabel(\"Intensity (Weak -> Strong)\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "intensity_axis = create_axis(\"strong\", \"weak\", model)\n",
        "test_words = [\n",
        "    \"excellent\",\n",
        "    \"terrible\",\n",
        "    \"mediocre\",\n",
        "    \"mild\",\n",
        "    \"extreme\",\n",
        "    \"murder\",\n",
        "    \"charity\",\n",
        "]\n",
        "\n",
        "plot_2d(test_words, sentiment_axis, intensity_axis, model)"
      ],
      "id": "4289ee0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Key Insight\n",
        "\n",
        "To define a concept, you must first define its opposite. Meaning isn't stored in the word itself. It lives in the contrast space, the relationship between poles that defines an axis. SemAxis operationalizes this principle: by defining opposition, we isolate the dimension that matters."
      ],
      "id": "19c88f4d"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "applsoftcomp",
      "language": "python",
      "display_name": "Python (applsoftcomp)",
      "path": "/Users/skojaku-admin/Library/Jupyter/kernels/applsoftcomp"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}