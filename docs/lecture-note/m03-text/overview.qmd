---
title: "Module 03: Deep Learning for Text"
jupyter: python3
execute:
  eval: false
---

# Module Overview

Large language models (LLMs) like ChatGPT are powerful tools for research, but how do they work? This module moves from hands-on use to an intuitive understanding of their inner workings.

We start with practical tasks using LLMs and prompt engineering, then explain core concepts like embeddings and transformers.

## Why Text?

Text data is central to complex systems: literature, social media, communication, and more. Modern NLP lets us analyze these patterns at scale.

## Outcomes

After this module, you’ll be able to:
- Use LLMs for tasks such as literature analysis and information extraction
- Write prompts for structured outputs
- Visualize and interpret text embeddings
- Explain (in plain language) how transformers work
- Choose appropriate NLP methods for your research

## Content Outline

- **[LLMs in Practice](llm-intro.qmd)**: Run and use LLMs locally (Ollama, Gemma)
- **[Prompt Engineering](prompt-engineering.qmd)**: Effective techniques for communication with LLMs
- **[Embeddings](embeddings-concepts.qmd)**: Representing text as numbers and using semantic similarity
- **[Transformers](transformers.qmd)**: The architecture powering modern NLP
- **[Word Embeddings](word-embeddings.qmd)**: Classic approaches before transformers
- **[Text Fundamentals](text-fundamentals.qmd)**: Basics—tokenization, bag-of-words, TF-IDF
- **[Semantic Analysis](semantic-research.qmd)**: Case studies in scientific text analysis

## Note

This course focuses on intuition and practical skills, not theory or derivations. You'll learn by doing, not by memorizing equations.

