---
title: "Sprint Project: The Tidy Data Escape Room"
---

::: {.callout-note title="Your mission"}
You have 90 minutes to rescue a catastrophic CSV from the depths of spreadsheet hell. Your dataset is riddled with merged cells, color-coded metadata, and violations of every tidy data principle. Working in pairs as Driver and Navigator, you must clean this mess into a pristine tidy format while maintaining a granular Git history. The team with the cleanest data and the most informative commit history wins.
:::

## The Challenge

Let's talk about what makes this challenge difficult. You face a dataset designed to frustrate. Think merged header rows. Think footnotes embedded in data cells. Think summary rows scattered throughout. These are the real-world horrors that spreadsheet users create when they optimize for visual appeal rather than computational analysis.

Your task is surgical. You must transform chaos into tidy data where each variable forms a column, each observation forms a row, and each type of observational unit forms a table. But here is the twist. You cannot simply fix everything in one massive commit. Every meaningful edit requires its own commit with a descriptive message. Your Git history becomes a narrative of the cleaning process.

## The Rules

**Team Structure:** Work in pairs. One person is the Driver who controls the keyboard. The other is the Navigator who reviews, suggests, and catches mistakes. Switch roles every 15 minutes.

**Version Control Discipline:** Every change must be committed and pushed. No batch commits. If you delete a summary row, commit it. If you rename a column, commit it. If you split merged cells, commit it. Your commit messages must explain *why* you made each change.

**Tidy Data Requirements:** Your final dataset must satisfy all tidy data principles. No wide format when long format is appropriate. No metadata in data cells. No implicit missing values. No ambiguous column names.

**Time Limit:** You have 90 minutes from the moment you receive the dataset.

## The Workflow

Here is how the sprint unfolds. First, you clone the shared repository containing the disaster CSV. Examine it carefully. Document the problems you find. Create a cleaning plan as a markdown file in your repo. Commit this plan.

Now begin cleaning. Tackle one problem at a time. Perhaps you start by removing summary rows. Commit that change with a message like "Remove embedded summary rows that violate observation-per-row principle." Then you might split a date column that combines month and year. Commit again.

Push frequently. Pushing forces you to resolve conflicts early rather than at the end. It also lets instructors monitor your progress in real-time.

As you clean, update your plan. Check off completed tasks. Document decisions. If you chose long format over wide format, explain why in your plan document. Commit these documentation updates too.

## What Makes You Win

The victory goes to the team that delivers the best combination of clean data and clear history. Judges evaluate three dimensions.

**Data Quality:** Is your dataset truly tidy? Can we load it and immediately begin analysis without further cleaning? Are variable types correct? Are missing values handled explicitly rather than implicitly?

**Git History:** Do your commits tell a story? Can someone reconstruct your cleaning logic by reading commit messages? Did you make atomic commits that change one thing at a time?

**Documentation:** Does your plan document decisions and justifications? If you made a non-obvious choice, is it explained?

## Common Pitfalls

Let's discuss what trips people up. The most common mistake is making too few commits. Teams clean for an hour then commit everything at once. This defeats the purpose. Commit early and commit often.

Another trap is cleaning without a plan. Teams dive straight into editing and lose track of what they have fixed. Take five minutes upfront to document problems. This roadmap prevents you from missing issues.

The third pitfall is merge conflicts from infrequent pushing. Push after every few commits. This keeps your local and remote repositories synchronized and prevents painful merge conflicts at the deadline.

## The Takeaway

This sprint builds muscle memory for reproducible data work. You practice Git discipline under pressure. You internalize tidy data principles through application. You learn to document your thinking as you go rather than reconstructing it later.

These habits matter beyond this classroom. In real projects, future-you will thank past-you for clear commit messages and tidy data. Collaborators will thank you for maintainable repositories. Reviewers will thank you for transparent cleaning processes.

Ready to escape the room? Let the sprint begin.
