---
title: "Reproducible Environments & Projects"
---

::: {.callout-note title="What you'll learn in this module"}
This module teaches you how to build truly reproducible projects. You'll understand the three pillars of reproducibility: virtual environments, workflow automation, and comprehensive documentation. You'll learn practical tools like uv and Snakemake, and discover how good project organization prevents errors and enables seamless collaboration.
:::

## The Importance of Reproducibility

Reproducibility is a cornerstone of good science and a fundamental principle in computational research. At its core, it means this: an independent researcher should be able to duplicate your results using the same materials and procedures you used. In data science, this means your code must produce the exact same outputs every single time, given the same input data, regardless of which machine runs it.

Now, a quick distinction helps clarify what we're really doing. **Reproducibility** asks: can an independent researcher achieve the exact same results using your data and code? This is a computational challenge. **Replicability**, on the other hand, asks: can an independent researcher confirm your scientific conclusions by conducting a brand new, independent study? This is a scientific challenge. We focus here on computational reproducibility, which is the essential first step. Without it, replication becomes impossible.

## Pillars of a Reproducible Project

Achieving reproducibility requires a conscious effort and the right set of tools. We can think of a reproducible project as having three main pillars: [Virtual Environments](https://aeturrell.github.io/python4DS/environments.html), [Workflow automation](https://aeturrell.github.io/python4DS/workflows.html), and [Comprehensive documentation](https://aeturrell.github.io/python4DS/documentation.html).

### Virtual Environments

A virtual environment is an isolated container holding all the packages and dependencies your project needs. Without one, you risk "dependency hell": installing a new library for one project breaks another project that needs a different version of the same library.

Picture the problem: you have project A using pandas 1.3 and project B using pandas 2.0. Without virtual environments, your system has only one pandas version installed, and one project breaks. Virtual environments solve this by giving each project its own isolated package space.

For this course, we recommend **[uv](https://astral.sh/uv)**. It's a modern, blazingly fast Python package and environment manager written in Rust. Unlike older tools like `pip` and `venv`, `uv` combines both package installation and environment creation into one tool. This integrated approach and high performance can dramatically speed up your Python workflows.

Ready to get started? Check the [uv documentation](https://docs.astral.sh/uv/concepts/projects/init/#packaged-applications).

::: {.callout-note}
**Why not conda?** Conda is a mature, well-used tool in the Python community. Unlike `uv`, conda can manage non-Python dependencies like compilers or optimized BLAS libraries. This flexibility is powerful if you need system-level packages. However, this same flexibility creates complexity: conda environments can develop intricate dependencies that make them harder to replicate. `uv` focuses solely on Python packages, which actually simplifies reproducibility. Less flexibility sometimes means better reproducibility.
:::

### Workflow Management

As your project grows, the order of steps matters, and it gets complicated fast. One script preprocesses data, another trains a model, a third generates figures. If you run them manually in the wrong order, or forget which ones depend on which, errors creep in silently.

::: {#fig-workflow}
![](https://divingintogeneticsandgenomics.com/img/rule_graph_lancet.png)

This diagram shows a research project as a workflow, where each box is a script and connections show data flowing from one script to the next. As projects grow, these dependencies become impossible to track mentally.
:::

A workflow management tool automates this complexity. You define the steps and their dependencies, and the tool figures out the correct order, runs them all, and even parallelizes where possible.

**[Snakemake](https://snakemake.readthedocs.io/en/stable/)** is excellent for this. It uses a readable, Python-based language where you define rules: here's how to create output files from input files. Snakemake handles the rest. Want to learn more? Watch this [introductory video](https://www.youtube.com/watch?v=r9PWnEmz_tc).

One principle matters deeply: make individual scripts **atomic**. One script preprocesses data. Another trains a model. A third generates figures. When scripts are minimal and focused, they become readable, reusable, and easy to debug.

### Comprehensive Documentation

Code and data are not self-explanatory. Comprehensive documentation is crucial for anyone reading your project (including your future self) to understand the what, why, and how.

Every project should have a `README.md` file in its root directory. This file explains what the project is about, what the files are, and how to run the analysis. A strong README includes a few key sections: start with a clear **project description** explaining what it does and its goals. Add a **file structure summary** so readers can navigate. If you include example datasets, describe the **data table structure**, including column names and formats. Provide **installation instructions** so people can set up the environment. Explain **usage** with examples of how to run the main scripts. Finally, add **contact and license information** so readers know who to ask and under what terms they can use your work.

## Project Organization Best Practices

Beyond the core tools, organizing your project thoughtfully is crucial for long-term reproducibility and collaboration.

### File and Directory Structure

A logical file structure makes it easy for others and for future you to find things. Start with **descriptive naming**. Give files and directories clear, self-explanatory names so you can find them via search. Instead of `analysis.py`, use `preprocess_customer_data.py`.

For files that evolve over time (like datasets or reports), consider **adding timestamps**. Name a report `2025-10-20_survey_analysis.qmd` instead of `report.qmd`. This lets you instantly identify which version is which.

Want to dive deeper? Check out [How to name files](https://www.youtube.com/watch?v=ES1LTlnpLMk) and [A Simple File Management System](https://www.youtube.com/watch?v=MM-MPS57qKA&t=230s).

### Writing Clean Code

Here's a simple truth: code quality directly impacts reproducibility. If your code is hard to read, it's hard to verify. It's hard to reuse. And it's hard for someone else (or your future self) to understand why you made each choice.

The book [Clean Code: A Handbook of Agile Software Craftsmanship by Robert C. Martin](https://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882) is an excellent guide to writing code that's readable, maintainable, and trustworthy.

## Bringing It Together

By combining virtual environments, comprehensive documentation, workflow management, and thoughtful project organization, you've now built the foundation for reproducible computational projects. These practices protect your work, enable collaboration, and most importantly, help you trust your own results.
