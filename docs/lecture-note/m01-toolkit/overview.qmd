---
title: "Overview"
---

Imagine spending months on a groundbreaking data analysis, only to find that you can't reproduce your own results. Or, imagine a colleague asks for your code and data from a project you did last year, and you can't remember where you saved the files, or which version of the code produced the final results. These scenarios are all too common in data science, and they highlight the importance of **Provenance**. Provenance is a complete lineage of the data and code from its origin to its final form. It is a cornerstone of good science, allowing others to verify your findings and build upon your work.

This module will introduce you to the tools and principles that will help you build a reproducible data science pipeline in a systematic way. We'll cover the following topics:

1. **Version Control**: We'll explore the "horror stories" of what can happen without proper version control, from losing days of work to causing major security breaches. We'll then introduce **Git** and **GitHub** as powerful tools to track changes in your code and data, collaborate with others, and save yourself from future headaches.
    - [Version Control with Git & GitHub](git-github.qmd)
2. **Data Provenance and Tidy Data**: We'll discuss the importance of knowing the history of your data (data provenance) and how to structure it in a way that makes it easy to work with (tidy data). We'll see how a little bit of organization up front can save you hours of pain and suffering down the road.
    - [Data Provenance](data-provenance.qmd)
    - [Tidy Data](tidy-data.qmd)
3. **Reproduceability**: We will learn how to build a reproducible data science pipeline, from the environment to the code to the data.
    - [Reproducible Environments & Projects](reproduceability.qmd)

By the end of this module, you'll have a solid foundation in the tools and principles of reproducible data science, and you'll be well on your way to becoming a data science rockstar.
