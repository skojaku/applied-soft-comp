{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a37aa5be",
   "metadata": {},
   "source": [
    "# Understanding SemAxis: Semantic Axes in Word Vector Spaces\n",
    "\n",
    "## Motivation and Background\n",
    "\n",
    "\n",
    "SemAxis is a framework for analyzing word semantics in vector spaces by defining semantic axes between pairs of antonymous words {footcite}`an2018semaxis`. For example, we can create a \"soft-hard\" axis and measure how other words align with this dimension. This allows us to capture how word meanings shift across different domains - the word \"soft\" may align differently with this axis when used in product reviews versus sports commentary. By leveraging word embeddings and semantic axes, SemAxis provides a systematic way to characterize these domain-specific semantic variations.\n",
    "\n",
    "## Core Concept: Semantic Axes\n",
    "\n",
    "At the heart of SemAxis is the concept of semantic axes. A semantic axis is defined by a pair of antonymous words (pole words) in the word embedding space. For example, we might define axes like:\n",
    "\n",
    "- good – bad\n",
    "- soft – hard\n",
    "- professional – amateur\n",
    "\n",
    "Mathematically, for a pair of antonymous words w+ and w-, the semantic axis vector is computed as:\n",
    "\n",
    "$$v_f = v_{w+} - v_{w-}$$\n",
    "\n",
    "where $v_f$ represents the semantic axis vector, and $v_{w+}$ and $v_{w-}$ are the word vectors of the pole words.\n",
    "\n",
    "![](https://raw.githubusercontent.com/ghdi6758/SemAxis/master/doc/images/semaxis_diagram.png)\n",
    "\n",
    "\n",
    "## Computing Word Semantics Along an Axis\n",
    "\n",
    "Once a semantic axis is defined, we can measure how any word aligns with this axis using cosine similarity:\n",
    "\n",
    "$$\\text{score}(w)_{v_f} = \\cos(v_w, v_f) = \\frac{v_w \\cdot v_f}{||v_w|| ||v_f||}$$\n",
    "\n",
    "This score indicates where a word falls along the semantic dimension defined by the axis. A higher positive score suggests the word is semantically closer to w+, while a negative score indicates closer alignment with w-.\n",
    "\n",
    "## Building Robust Semantic Axes\n",
    "\n",
    "To make semantic axes more robust and less sensitive to specific word choices, SemAxis employs an expansion technique:\n",
    "\n",
    "1. Start with initial pole words (e.g., \"good\" and \"bad\")\n",
    "2. Find k nearest neighbors for each pole word in the embedding space\n",
    "3. Compute the centroid of each expanded pole set\n",
    "4. Define the axis using these centroids rather than individual words\n",
    "\n",
    "This approach helps capture broader semantic concepts rather than relying on single words.\n",
    "\n",
    "```{note}\n",
    "The robustness of semantic axes is crucial for reliable analysis. Always validate your axes with domain experts when possible and consider using multiple related antonym pairs to capture complex semantic concepts.\n",
    "```\n",
    "\n",
    "## Applications and Use Cases\n",
    "\n",
    "SemAxis can be applied to various natural language processing tasks:\n",
    "\n",
    "1. Analyzing domain-specific word usage (e.g., how technical terms are used differently across scientific fields)\n",
    "2. Comparing word semantics across different communities or time periods\n",
    "3. Building domain-specific sentiment lexicons\n",
    "4. Understanding cultural and social biases in language\n",
    "\n",
    "## Hands-on Exercise\n",
    "\n",
    "In this hands-on section, we'll implement key concepts of SemAxis using Python and pre-trained GloVe embeddings. We'll take a functional programming approach to keep things clear and straightforward.\n",
    "\n",
    "### Loading Word Embeddings\n",
    "\n",
    "First, let's get our embeddings using gensim's built-in downloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "373ae9fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'triu' from 'scipy.linalg' (/Users/skojaku-admin/miniforge3/envs/applsoftcomp/lib/python3.10/site-packages/scipy/linalg/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mapi\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Download and load pre-trained GloVe embeddings\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglove-wiki-gigaword-100\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/applsoftcomp/lib/python3.10/site-packages/gensim/__init__.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/applsoftcomp/lib/python3.10/site-packages/gensim/corpora/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexedcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmmcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleicorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/applsoftcomp/lib/python3.10/site-packages/gensim/corpora/indexedcorpus.py:14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[1;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIndexedCorpus\u001b[39;00m(interfaces\u001b[38;5;241m.\u001b[39mCorpusABC):\n",
      "File \u001b[0;32m~/miniforge3/envs/applsoftcomp/lib/python3.10/site-packages/gensim/interfaces.py:19\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[1;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCorpusABC\u001b[39;00m(utils\u001b[38;5;241m.\u001b[39mSaveLoad):\n",
      "File \u001b[0;32m~/miniforge3/envs/applsoftcomp/lib/python3.10/site-packages/gensim/matutils.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m entropy\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_blas_funcs, triu\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlapack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_lapack_funcs\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m psi  \u001b[38;5;66;03m# gamma function utils\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'triu' from 'scipy.linalg' (/Users/skojaku-admin/miniforge3/envs/applsoftcomp/lib/python3.10/site-packages/scipy/linalg/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Download and load pre-trained GloVe embeddings\n",
    "model = api.load('glove-wiki-gigaword-100')\n",
    "print(f\"Model contains {len(model.key_to_index)} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d2d33b",
   "metadata": {},
   "source": [
    "### Creating a Semantic Axis\n",
    "\n",
    "Let's implement the core function for creating a semantic axis from two pole words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_semantic_axis(pos_word, neg_word, model):\n",
    "    \"\"\"Create a semantic axis from two pole words\"\"\"\n",
    "    # Get word vectors for both poles\n",
    "    pos_vector = model[pos_word]\n",
    "    neg_vector = model[neg_word]\n",
    "\n",
    "    # Create axis vector by subtracting negative pole from positive pole\n",
    "    axis_vector = pos_vector - neg_vector\n",
    "\n",
    "    return axis_vector\n",
    "\n",
    "# Example: Create a sentiment axis\n",
    "sentiment_axis = create_semantic_axis('good', 'bad', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c925ff8",
   "metadata": {},
   "source": [
    "### Computing Word Scores\n",
    "\n",
    "Now let's create a function to measure how words align along our semantic axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd8cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_score(word, axis_vector, model):\n",
    "    \"\"\"Compute how a word aligns with a semantic axis\"\"\"\n",
    "    word_vector = model[word]\n",
    "\n",
    "    # Compute cosine similarity between word and axis\n",
    "    score = np.dot(word_vector, axis_vector) / (\n",
    "        np.linalg.norm(word_vector) * np.linalg.norm(axis_vector)\n",
    "    )\n",
    "    return score\n",
    "\n",
    "# Let's test some words along the sentiment axis\n",
    "test_words = ['excellent', 'terrible', 'amazing', 'horrible', 'mediocre']\n",
    "scores = [(word, get_word_score(word, sentiment_axis, model))\n",
    "          for word in test_words]\n",
    "\n",
    "# Print results\n",
    "for word, score in sorted(scores, key=lambda x: x[1]):\n",
    "    print(f\"{word}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765b07f1",
   "metadata": {},
   "source": [
    "### Visualizing Word Alignments\n",
    "\n",
    "Let's create a simple visualization of how words align along our semantic axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_semantic_alignment(words, axis_vector, model, axis_name=\"Sentiment\"):\n",
    "    \"\"\"Plot words along a semantic axis\"\"\"\n",
    "    scores = [(word, get_word_score(word, axis_vector, model))\n",
    "             for word in words]\n",
    "    scores = sorted(scores, key=lambda x: x[1])\n",
    "\n",
    "    words, values = zip(*scores)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.barh(words, values)\n",
    "    plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.title(f'Word Alignment on {axis_name} Axis')\n",
    "    plt.xlabel(f'← Negative    Score    Positive →')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test with more words\n",
    "test_words = ['excellent', 'terrible', 'amazing', 'horrible',\n",
    "              'mediocre', 'outstanding', 'average', 'good', 'bad']\n",
    "plot_semantic_alignment(test_words, sentiment_axis, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2508ef",
   "metadata": {},
   "source": [
    "### Creating Robust Semantic Axes\n",
    "\n",
    "Let's implement the expanded pole words approach for more reliable axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d02c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_robust_axis(pos_word, neg_word, model, k=5):\n",
    "    \"\"\"Create a semantic axis using expanded pole words\"\"\"\n",
    "    # Get neighboring words for positive pole\n",
    "    pos_neighbors = [word for word, _ in model.most_similar(pos_word, topn=k)]\n",
    "    pos_neighbors.append(pos_word)\n",
    "\n",
    "    # Get neighboring words for negative pole\n",
    "    neg_neighbors = [word for word, _ in model.most_similar(neg_word, topn=k)]\n",
    "    neg_neighbors.append(neg_word)\n",
    "\n",
    "    # Calculate centroid vectors\n",
    "    pos_centroid = np.mean([model[w] for w in pos_neighbors], axis=0)\n",
    "    neg_centroid = np.mean([model[w] for w in neg_neighbors], axis=0)\n",
    "\n",
    "    # Create axis vector\n",
    "    return pos_centroid - neg_centroid\n",
    "\n",
    "# Create a robust sentiment axis and compare results\n",
    "robust_sentiment_axis = create_robust_axis('good', 'bad', model)\n",
    "plot_semantic_alignment(test_words, robust_sentiment_axis, model,\n",
    "                       \"Robust Sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b289b4",
   "metadata": {},
   "source": [
    "### Analyzing Words Along Multiple Axes\n",
    "\n",
    "Finally, let's see how words position themselves in a 2D semantic space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae91f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_words_2d(words, axis1, axis2, model,\n",
    "                  axis1_name=\"Axis 1\", axis2_name=\"Axis 2\"):\n",
    "    \"\"\"Plot words in 2D semantic space defined by two axes\"\"\"\n",
    "    # Get scores for both axes\n",
    "    scores_1 = [get_word_score(word, axis1, model) for word in words]\n",
    "    scores_2 = [get_word_score(word, axis2, model) for word in words]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(scores_1, scores_2, marker='o')\n",
    "\n",
    "    # Add word labels with some padding\n",
    "    for i, word in enumerate(words):\n",
    "        plt.annotate(word, (scores_1[i], scores_2[i]),\n",
    "                    xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "    plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "    plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
    "    plt.xlabel(axis1_name)\n",
    "    plt.ylabel(axis2_name)\n",
    "    plt.title('Words in 2D Semantic Space')\n",
    "\n",
    "    # Add some padding to the plot edges\n",
    "    plt.margins(0.1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create two different axes\n",
    "sentiment_axis = create_semantic_axis('good', 'bad', model)\n",
    "strength_axis = create_semantic_axis('strong', 'weak', model)\n",
    "\n",
    "# Plot words in 2D semantic space\n",
    "test_words = ['excellent', 'terrible', 'powerful', 'weak',\n",
    "              'mediocre', 'strong', 'mild', 'intense', \"bad\", \"good\"]\n",
    "plot_words_2d(test_words, sentiment_axis, strength_axis, model,\n",
    "              \"Sentiment (Bad → Good)\", \"Strength (Weak → Strong)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3252d637",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "When working with semantic axes:\n",
    "- Test your axes with words that have known relationships to validate their behavior\n",
    "- Consider using domain-specific word embeddings for specialized applications\n",
    "- Compare results from regular and robust axes to ensure stability\n",
    "\n",
    "```{footbibliography}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}