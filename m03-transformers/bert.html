
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Bidirectional Encoder Representations from Transformers (BERT) &#8212; Applied Soft Computing</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'm03-transformers/bert';</script>
    <script src="../_static/js/custom.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Sentence-BERT" href="sentence-bert.html" />
    <link rel="prev" title="Transformers" href="transformers.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../home.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.jpg" class="logo__image only-light" alt="Applied Soft Computing - Home"/>
    <script>document.write(`<img src="../_static/logo.jpg" class="logo__image only-dark" alt="Applied Soft Computing - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../home.html">
                    Welcome to SSIE 541/441 Applied Soft Computing
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Intro</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../intro/why-applied-soft-computing.html">Why applied soft computing?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/setup.html">Set up</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/deliverables.html">Deliverables</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Word and Document Embeddings</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m01-word-embedding/what-to-learn.html">Module 1: Word Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m01-word-embedding/pen-and-paper.html">Pen and Paper Exercise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m01-word-embedding/tf-idf.html">Teaching computers how to understand words</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m01-word-embedding/word2vec.html">word2vec: a small model with a big idea</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m01-word-embedding/word2vec_plus.html">GloVe and FastText: Building on Word2Vec’s Foundation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m01-word-embedding/sem-axis.html">Understanding SemAxis: Semantic Axes in Word Vector Spaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m01-word-embedding/bias-in-embedding.html">Bias in Word Embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m01-word-embedding/doc2vec.html">Doc2Vec: From Words to Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m01-word-embedding/summary.html">Summary</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Recurrent Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m02-recurrent-neural-network/what-to-learn.html">Module 2: Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-recurrent-neural-network/rnn-interactive.html">🧠 Learn RNNs Through Physics!</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-recurrent-neural-network/reccurrent-neural-net.html">Recurrent Neural Network (RNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-recurrent-neural-network/lstm.html">Long Short-Term Memory (LSTM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-recurrent-neural-network/elmo.html">Embedding from Language Models (ELMo)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-recurrent-neural-network/seq2seq.html">Sequence-to-Sequence Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-recurrent-neural-network/summary.html">Summary</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Transformers</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="what-to-learn.html">Module 3: Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="transformers.html">Transformers</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Bidirectional Encoder Representations from Transformers (BERT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="sentence-bert.html">Sentence-BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpt.html">Generative Pre-trained Transformer (GPT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="t5.html">Text-to-Text Transfer Transformer (T5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Teaching Machine How to Understand Images</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m04-image-processing/what-to-learn.html">Module 3: Image Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m04-image-processing/pen-and-paper.html">Pen and paper exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m04-image-processing/image-processing.html">Preliminaries: Image Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m04-image-processing/cnn.html">From Traditional Image Processing to Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m04-image-processing/lenet.html">LeNet and LeNet-5: Pioneering CNN Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m04-image-processing/alexnet.html">AlexNet: A Breakthrough in Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m04-image-processing/vgg.html">VGGNet - A Deep Convolutional Neural Network for Image Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m04-image-processing/inception.html">GoogleNet and the Inception Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m04-image-processing/resnet.html">ResNet (Residual Neural Networks)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Teaching Machine How to Understand Graphs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m05-graph/what-to-learn.html">Module 4: Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-graph/pen-and-paper.html">Pen and paper exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-graph/spectral-embedding.html">Spectral Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-graph/graph-embedding-w-word2vec.html">Graph embedding with word2vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-graph/spectral-vs-neural-embedding.html">Spectral vs Neural Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-graph/from-image-to-graph.html">From Image to Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-graph/graph-convolutional-network.html">Graph Convolutional Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-graph/popular-gnn.html">Popular Graph Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-graph/appendix.html">Appendix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-graph/software.html">Software for Network Embedding</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/skojaku/applied-soft-comp/gh-pages?urlpath=tree/docs/lecture-note/m03-transformers/bert.md" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/skojaku/applied-soft-comp" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/skojaku/applied-soft-comp/issues/new?title=Issue%20on%20page%20%2Fm03-transformers/bert.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/m03-transformers/bert.ipynb" target="_blank"
   class="btn btn-sm btn-download-notebook-button dropdown-item"
   title="Download notebook file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li><a href="../_sources/m03-transformers/bert.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Bidirectional Encoder Representations from Transformers (BERT)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture">Architecture</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#special-tokens">Special tokens</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#position-and-segment-embeddings">Position and Segment embeddings</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-training">Pre-training</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#masked-language-modeling-mlm">Masked Language Modeling (MLM)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#next-sentence-prediction-nsp">Next Sentence Prediction (NSP)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning">Fine-tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variants-and-improvements">Variants and improvements</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hands-on">Hands on</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">Exercise</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="bidirectional-encoder-representations-from-transformers-bert">
<h1>Bidirectional Encoder Representations from Transformers (BERT)<a class="headerlink" href="#bidirectional-encoder-representations-from-transformers-bert" title="Link to this heading">#</a></h1>
<p>We learned about ELMo’s approach to the problem of polysemy using bidirectional LSTMs. BERT builds upon its bidirectional approach by using a self-attention mechanism in transformers.
BERT has become the leading transformer model for natural language processing tasks like question answering and text classification. Its effectiveness led Google to incorporate it into their search engine to improve query understanding. In this section, we will explore BERT’s architecture and mechanisms.</p>
<figure class="align-center" id="bert-mlm">
<a class="reference internal image-reference" href="https://cdn.botpenguin.com/assets/website/BERT_c35709b509.webp"><img alt="BERT MLM" src="https://cdn.botpenguin.com/assets/website/BERT_c35709b509.webp" style="width: 50%;" /></a>
</figure>
<section id="architecture">
<h2>Architecture<a class="headerlink" href="#architecture" title="Link to this heading">#</a></h2>
<p>BERT consists of a stack of encoder transformer layers. Each layer is composed of a self-attention mechanism, a feed-forward neural network, and layer normalization, wired together with residual connections.
The output of each layer is fed into the next layer, and as we go through the layers, the token embeddings get more and more contextualized, reflecting the context more and more, thanks to the self-attention mechanism.</p>
<figure class="align-center" id="bert-architecture">
<a class="reference internal image-reference" href="https://www.researchgate.net/publication/372906672/figure/fig2/AS:11431281179224913&#64;1691164535766/BERT-model-architecture.ppm"><img alt="BERT architecture" src="https://www.researchgate.net/publication/372906672/figure/fig2/AS:11431281179224913&#64;1691164535766/BERT-model-architecture.ppm" style="width: 80%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 31 </span><span class="caption-text">BERT consists of a stack of encoder transformer layers. The position embeddings are added to the token embeddings to provide the model with information about the position of the tokens in the sequence.</span><a class="headerlink" href="#bert-architecture" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="tip admonition">
<p class="admonition-title">Which layer of BERT should we use?</p>
<p>BERT internally generates multiple hierarchical representations of the input sentence. The higher layers of the model capture more abstract and context-sensitive information, while the lower layers capture more local and surface-level information. Which layer to use depends on the task. For example, if we want to do text classification, we should use the output of the last layer. If we are interested in word-level representations, we should use the output of the first layer.</p>
</div>
</section>
<section id="special-tokens">
<h2>Special tokens<a class="headerlink" href="#special-tokens" title="Link to this heading">#</a></h2>
<p>BERT uses several special tokens to represent the input sentence.</p>
<ul class="simple">
<li><p>[CLS] is used to represent the start of the sentence.</p></li>
<li><p>[SEP] is used to represent the end of the sentence.</p></li>
<li><p>[MASK] is used to represent the masked words.</p></li>
<li><p>[UNK] is used to represent the unknown words.</p></li>
</ul>
<p>For example, the sentence “The cat sat on the mat. It then went to sleep.” is represented as “[CLS] The cat sat on the mat [SEP] It then went to sleep [SEP]”.</p>
<p>In BERT, [CLS] token is used to classify the input sentences, as we will see later. As a result, the model learns to encode a summary of the input sentence into the [CLS] token, which is particularly useful when we want the embedding of the whole input text, instead of the token level embeddings. <a class="footnote-reference brackets" href="#footcite-reimers2019sentence" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p>
</section>
<section id="position-and-segment-embeddings">
<h2>Position and Segment embeddings<a class="headerlink" href="#position-and-segment-embeddings" title="Link to this heading">#</a></h2>
<p>BERT uses <em>position</em> and <em>segment</em> embeddings to provide the model with information about the position of the tokens in the sequence.</p>
<ul class="simple">
<li><p>Position embeddings are used to provide the model with information about the position of the tokens in the sequence. Unlike the sinusoidal position embedding used in the original transformer paper <a class="footnote-reference brackets" href="#footcite-vaswani2017attention" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>, BERT uses learnable position embeddings.</p></li>
<li><p>The segment embeddings are used to distinguish the sentences in the input. For example, for the sentence “The cat sat on the mat. It then went to sleep.”, the tokens in the first sentence are added with segment embedding 0, and the tokens in the second sentence are added with segment embedding 1. These segmend embeddings are also learned during the pre-training process.</p></li>
</ul>
<figure class="align-center" id="bert-position-segment-embeddings">
<a class="reference internal image-reference" href="https://i.sstatic.net/thmqC.png"><img alt="BERT position and segment embeddings" src="https://i.sstatic.net/thmqC.png" style="width: 80%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 32 </span><span class="caption-text">Position and segment embeddings in BERT. Position embeddings, which are learnable, are added to the token embeddings. Segment embeddings indicate the sentence that the token belongs to (e.g., <span class="math notranslate nohighlight">\(E_A\)</span> and <span class="math notranslate nohighlight">\(E_B\)</span>).</span><a class="headerlink" href="#bert-position-segment-embeddings" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="tip admonition">
<p class="admonition-title">Tip</p>
<p>Position embeddings can be either absolute or relative:</p>
<p>Absolute position embeddings (like in BERT) directly encode the position of each token as a fixed index (1st, 2nd, 3rd position etc). Each position gets its own unique embedding vector that is learned during training.</p>
<p>Relative position embeddings (like sinusoidal embeddings in the original Transformer) encode the relative distance between tokens rather than their absolute positions. For example, they can encode that token A is 2 positions away from token B, regardless of their absolute positions in the sequence. This makes them more flexible for handling sequences of varying lengths.</p>
<p>For interested readers, you can read more about the difference between absolute and relative position embeddings in <a class="reference external" href="https://ofir.io/The-Use-Case-for-Relative-Position-Embeddings/">The Use Case for Relative Position Embeddings – Ofir Press</a> and <a class="reference external" href="https://arxiv.org/abs/2108.12409">Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation</a>.</p>
</div>
<section id="pre-training">
<h3>Pre-training<a class="headerlink" href="#pre-training" title="Link to this heading">#</a></h3>
<p>A key aspect of BERT is its pre-training process, which involves two main objectives:</p>
<ul class="simple">
<li><p>Masked Language Modeling (MLM)</p></li>
<li><p>Next Sentence Prediction (NSP)</p></li>
</ul>
<p>Both objectives are designed to learn the language structure, such as the relationship between words and sentences.</p>
<section id="masked-language-modeling-mlm">
<h4>Masked Language Modeling (MLM)<a class="headerlink" href="#masked-language-modeling-mlm" title="Link to this heading">#</a></h4>
<p>In MLM, the model is trained to predict the original words that are masked in the input sentence. The masked words are replaced with a special token, [MASK], and the model is trained to predict the original words. For example, the sentence “The cat [MASK] on the mat” is transformed into “The cat [MASK] on the mat”. The model is trained to predict the original word “sat” in the sentence.</p>
<figure class="align-center" id="id3">
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/UKPLab/sentence-transformers/master/docs/img/MLM.png"><img alt="BERT MLM" src="https://raw.githubusercontent.com/UKPLab/sentence-transformers/master/docs/img/MLM.png" style="width: 80%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 33 </span><span class="caption-text">Masked Language Modeling (MLM). A token is randomly masked and the model is trained to predict the original word.</span><a class="headerlink" href="#id3" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>To generate training data for MLM, BERT randomly masks 15% of the tokens in each sequence. However, the masking process is not as straightforward as simply replacing words with [MASK] tokens. For the 15% of tokens chosen for masking:</p>
<ul class="simple">
<li><p>80% of the time, replace the word with the [MASK] token</p>
<ul>
<li><p>Example: “the cat sat on the mat” → “the cat [MASK] on the mat”</p></li>
</ul>
</li>
<li><p>10% of the time, replace the word with a random word</p>
<ul>
<li><p>Example: “the cat sat on the mat” → “the cat dog on the mat”</p></li>
</ul>
</li>
<li><p>10% of the time, keep the word unchanged</p>
<ul>
<li><p>Example: “the cat sat on the mat” → “the cat sat on the mat”</p></li>
</ul>
</li>
</ul>
<p>The model must predict the original token for all selected positions, regardless of whether they were masked, replaced, or left unchanged. This helps prevent the model from simply learning to detect replaced tokens.</p>
<p>During training, the model processes the modified input sequence through its transformer layers and predicts the original token at each masked position using the contextual representations.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>While replacing words with random tokens or leaving them unchanged may seem counterintuitive, research has shown this approach is effective <a class="footnote-reference brackets" href="#footcite-raffel2020exploring" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>. It has become an essential component of BERT’s pre-training process.</p>
</div>
</section>
<section id="next-sentence-prediction-nsp">
<h4>Next Sentence Prediction (NSP)<a class="headerlink" href="#next-sentence-prediction-nsp" title="Link to this heading">#</a></h4>
<figure class="align-center" id="bert-nsp">
<a class="reference internal image-reference" href="https://amitness.com/posts/images/bert-nsp.png"><img alt="BERT NSP" src="https://amitness.com/posts/images/bert-nsp.png" style="width: 80%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 34 </span><span class="caption-text">Next Sentence Prediction (NSP). The model is trained to predict whether two sentences are consecutive or not.</span><a class="headerlink" href="#bert-nsp" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Next Sentence Prediction (NSP) trains BERT to understand relationships between sentences. The model learns to predict whether two sentences naturally follow each other in text. During training, half of the sentence pairs are consecutive sentences from documents (labeled as IsNext), while the other half are random sentence pairs (labeled as NotNext).</p>
<p>The input format uses special tokens to structure the sentence pairs: a [CLS] token at the start, the first sentence, a [SEP] token, the second sentence, and a final [SEP] token. For instance:</p>
<div class="math notranslate nohighlight">
\[
\text{``[CLS] }\underbrace{\text{I went to the store}}_{\text{Sentence 1}}\text{ [SEP] }\underbrace{\text{They were out of milk}}_{\text{Sentence 2}}\text{ [SEP]}&quot;.
\]</div>
<p>BERT uses the final hidden state of the [CLS] token to classify whether the sentences are consecutive or not. This helps the model develop a broader understanding of language context and relationships between sentences.</p>
<p>These two objectives help BERT learn the structure of language, such as the relationship between words and sentences.</p>
</section>
</section>
</section>
<section id="fine-tuning">
<h2>Fine-tuning<a class="headerlink" href="#fine-tuning" title="Link to this heading">#</a></h2>
<p>A powerful aspect of BERT is its ability to be fine-tuned on a wide range of tasks with minimal changes to the model architecture. This is achieved through transfer learning, where the pre-trained BERT model is used as a starting point for specific tasks.</p>
<p>Consider a hospital that wants to classify patient reviews. Due to privacy concerns, collecting enough data to train a deep learning model from scratch would be difficult. This is where BERT shines - since it’s already pre-trained on vast amounts of text data and understands language structure, it can be fine-tuned effectively even with a small dataset of patient reviews. The pre-trained BERT model can be adapted to this specific classification task with only minor architectural changes.</p>
<div class="tip admonition">
<p class="admonition-title">Tip</p>
<p>You can find many fine-tuned and pre-trained models for various tasks by searching the <a class="reference external" href="https://huggingface.co/models">Hugging Face model hub</a>, with the keyword “BERT”.</p>
</div>
</section>
<section id="variants-and-improvements">
<h2>Variants and improvements<a class="headerlink" href="#variants-and-improvements" title="Link to this heading">#</a></h2>
<p><em><em>RoBERTa (Robustly Optimized BERT Approach)</em> <a class="footnote-reference brackets" href="#footcite-liu2019roberta" id="id5" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a></em> improved upon BERT through several optimizations: removing the Next Sentence Prediction task, using dynamic masking that changes the mask patterns across training epochs, training with larger batches, and using a larger dataset. These changes led to significant performance improvements while maintaining BERT’s core architecture.</p>
<p><strong>DistilBERT</strong> <a class="footnote-reference brackets" href="#footcite-sanh2019distilbert" id="id6" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a> focused on making BERT more efficient through knowledge distillation, where a smaller student model learns from the larger BERT teacher model. It achieves 95% of BERT’s performance while being 40% smaller and 60% faster, making it more suitable for resource-constrained environments and real-world applications.</p>
<p><strong>ALBERT</strong> <a class="footnote-reference brackets" href="#footcite-lan2019albert" id="id7" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a> introduced parameter reduction techniques to address BERT’s memory limitations. It uses factorized embedding parameterization and cross-layer parameter sharing to dramatically reduce parameters while maintaining performance. ALBERT also replaced Next Sentence Prediction with Sentence Order Prediction, where the model must determine if two consecutive sentences are in the correct order.</p>
<p>Domain-specific BERT models have been trained on specialized corpora to better handle specific fields. Examples include <strong>BioBERT</strong> <a class="footnote-reference brackets" href="#footcite-lee2020biobert" id="id8" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a> for biomedical text, <strong>SciBERT</strong> <a class="footnote-reference brackets" href="#footcite-reimers2019sentence" id="id9" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> for scientific papers, and <strong>FinBERT</strong> <a class="footnote-reference brackets" href="#footcite-araci2019finbert" id="id10" role="doc-noteref"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></a> for financial documents. These models demonstrate superior performance in their respective domains compared to the general-purpose BERT.</p>
<p><strong>Multilingual BERT (mBERT)</strong> <a class="footnote-reference brackets" href="#footcite-liu2019roberta" id="id11" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a> was trained on Wikipedia data from 104 languages, using a shared vocabulary across all languages. Despite not having explicit cross-lingual objectives during training, mBERT shows remarkable zero-shot cross-lingual transfer abilities, allowing it to perform tasks in languages it wasn’t explicitly aligned on. This has made it a valuable resource for low-resource languages and cross-lingual applications.</p>
</section>
<section id="hands-on">
<h2>Hands on<a class="headerlink" href="#hands-on" title="Link to this heading">#</a></h2>
<p>Let us load a pre-trained BERT model and see how it works using a sense disambiguation task. The sense disambiguation task is a task that involves identifying the correct sense of a word in a sentence. For example, given a sentence with word “apple”, we need to identify whether it refers to the fruit or the technology company.</p>
<p>Let us first load the necessary libraries.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">transformers</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">bokeh.plotting</span><span class="w"> </span><span class="kn">import</span> <span class="n">figure</span><span class="p">,</span> <span class="n">show</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">bokeh.io</span><span class="w"> </span><span class="kn">import</span> <span class="n">output_notebook</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">bokeh.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">ColumnDataSource</span><span class="p">,</span> <span class="n">HoverTool</span>
</pre></div>
</div>
</div>
</div>
<p>We will use <a class="reference external" href="https://github.com/danlou/bert-disambiguation/tree/master/data/CoarseWSD-20">CoarseWSD-20</a>. The dataset contains sentences with polysemous words and their sense labels. We will see how to use BERT to disambiguate the word senses. Read the <a class="reference external" href="https://github.com/danlou/bert-disambiguation/blob/master/data/CoarseWSD-20/README.txt">README</a> for more details.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">load_data</span><span class="p">(</span><span class="n">focal_word</span><span class="p">,</span> <span class="n">is_train</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">data_type</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span> <span class="k">if</span> <span class="n">is_train</span> <span class="k">else</span> <span class="s2">&quot;test&quot;</span>
    <span class="n">data_file</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;https://raw.githubusercontent.com/danlou/bert-disambiguation/master/data/CoarseWSD-20/</span><span class="si">{</span><span class="n">focal_word</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">data_type</span><span class="si">}</span><span class="s2">.data.txt&quot;</span>
    <span class="n">label_file</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;https://raw.githubusercontent.com/danlou/bert-disambiguation/master/data/CoarseWSD-20/</span><span class="si">{</span><span class="n">focal_word</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">data_type</span><span class="si">}</span><span class="s2">.gold.txt&quot;</span>

    <span class="n">data_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
        <span class="n">data_file</span><span class="p">,</span>
        <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;word_pos&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="s2">&quot;sentence&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">},</span>
        <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;word_pos&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence&quot;</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">label_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
        <span class="n">label_file</span><span class="p">,</span>
        <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">},</span>
        <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">combined_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">data_table</span><span class="p">,</span> <span class="n">label_table</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">combined_table</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>


<span class="n">focal_word</span> <span class="o">=</span> <span class="s2">&quot;apple&quot;</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">focal_word</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">train_data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>word_pos</th>
      <th>sentence</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7</td>
      <td>both seasons are available for download from a...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1270</th>
      <td>21</td>
      <td>third-party support avid 's media composer 3.5...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2051</th>
      <td>18</td>
      <td>working conditions wage levels in an examinati...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1084</th>
      <td>9</td>
      <td>initially a weak copy protection system in the...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2276</th>
      <td>8</td>
      <td>originally , it was possible to develop on app...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>882</th>
      <td>14</td>
      <td>in the late 18th and early 19th centuries , we...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>533</th>
      <td>9</td>
      <td>organizations such as at&amp;t , coca-cola , starb...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1566</th>
      <td>0</td>
      <td>apple rejected the app three times , calling i...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1269</th>
      <td>11</td>
      <td>approximately 10 million sony batteries used i...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1475</th>
      <td>10</td>
      <td>swift is a multi-paradigm , compiled programmi...</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We will use transformers library developed by Hugging Face to define the BERT model. To use the model, we will need:</p>
<ul class="simple">
<li><p>BERT tokenizer that converts the text into tokens.</p></li>
<li><p>BERT model that computes the embeddings of the tokens.</p></li>
</ul>
<p>We will use the bert-base-uncased model and tokenizer. Let’s define the model and tokenizer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1"># set the model to evaluation mode</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="c1"># Print the model architecture</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>BertModel(
  (embeddings): BertEmbeddings(
    (word_embeddings): Embedding(30522, 768, padding_idx=0)
    (position_embeddings): Embedding(512, 768)
    (token_type_embeddings): Embedding(2, 768)
    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): BertEncoder(
    (layer): ModuleList(
      (0-11): 12 x BertLayer(
        (attention): BertAttention(
          (self): BertSdpaSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (intermediate_act_fn): GELUActivation()
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (pooler): BertPooler(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (activation): Tanh()
  )
)
</pre></div>
</div>
</div>
</div>
<p>This prints the model architecture, which shows:</p>
<ol class="arabic simple">
<li><p>BertEmbeddings layer that converts tokens into embeddings using:</p>
<ul class="simple">
<li><p>Word embeddings (30522 vocab size, 768 dimensions)</p></li>
<li><p>Position embeddings (512 positions, 768 dimensions)</p></li>
<li><p>Token type embeddings (2 types, 768 dimensions)</p></li>
<li><p>Layer normalization and dropout</p></li>
</ul>
</li>
<li><p>BertEncoder with 12 identical BertLayers, each containing:</p>
<ul class="simple">
<li><p>Self-attention mechanism with query/key/value projections</p></li>
<li><p>Intermediate layer with GELU activation</p></li>
<li><p>Output layer with layer normalization</p></li>
</ul>
</li>
<li><p>BertPooler that processes the [CLS] token embedding with:</p>
<ul class="simple">
<li><p>Dense layer (768 dimensions)</p></li>
<li><p>Tanh activation</p></li>
</ul>
</li>
</ol>
<p>All layers maintain the 768-dimensional hidden size, except the intermediate layer which expands to 3072 dimensions.</p>
<p>With BERT, we need to prepare text in ways that BERT can understand. Specifically, we prepend it with [CLS] and append [SEP]. We will then convert the text to a tensor of token ids, which is ready to be fed into the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">prepare_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;[CLS] &quot;</span> <span class="o">+</span> <span class="n">text</span> <span class="o">+</span> <span class="s2">&quot; [SEP]&quot;</span>
    <span class="n">tokenized_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">indexed_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="n">tokenized_text</span><span class="p">)</span>

    <span class="n">segments_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indexed_tokens</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
    <span class="n">tokens_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">indexed_tokens</span><span class="p">])</span>
    <span class="n">segments_tensor</span> <span class="o">=</span> <span class="n">segments_ids</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">tokenized_text</span><span class="p">,</span> <span class="n">tokens_tensor</span><span class="p">,</span> <span class="n">segments_tensor</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s get the BERT embeddings for the sentence “Bank is located in the city of London”.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Bank is located in the city of London&quot;</span>
<span class="n">tokenized_text</span><span class="p">,</span> <span class="n">tokens_tensor</span><span class="p">,</span> <span class="n">segments_tensor</span> <span class="o">=</span> <span class="n">prepare_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This produces the following output.
<strong>Tokenized text</strong>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">tokenized_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;[CLS]&#39;, &#39;bank&#39;, &#39;is&#39;, &#39;located&#39;, &#39;in&#39;, &#39;the&#39;, &#39;city&#39;, &#39;of&#39;, &#39;london&#39;, &#39;[SEP]&#39;]
</pre></div>
</div>
</div>
</div>
<p><strong>Token IDs</strong>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">tokens_tensor</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 101, 2924, 2003, 2284, 1999, 1996, 2103, 1997, 2414,  102]])
</pre></div>
</div>
</div>
</div>
<p><strong>Segment IDs</strong>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">segments_tensor</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])
</pre></div>
</div>
</div>
</div>
<p>Then, let’s get the BERT embeddings for each token.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Configure model to return hidden states</span>
<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">tokens_tensor</span><span class="p">,</span> <span class="n">segments_tensor</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The output includes <code class="docutils literal notranslate"><span class="pre">loss</span></code>, <code class="docutils literal notranslate"><span class="pre">logits</span></code>, and <code class="docutils literal notranslate"><span class="pre">hidden_states</span></code>. We will use <code class="docutils literal notranslate"><span class="pre">hidden_states</span></code>, which contains the embeddings of the tokens.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">hidden_states</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;how many layers? &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape? &quot;</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>how many layers?  13
Shape?  torch.Size([1, 10, 768])
</pre></div>
</div>
</div>
</div>
<p>The hidden states are a list of 13 tensors, where each tensor is of shape (batch_size, sequence_length, hidden_size). The first tensor is the input embeddings, and the subsequent tensors are the hidden states of the BERT layers.</p>
<p>So, we have 13 choice of hidden states. Deep layers close to the output capture the context of the word from the previous layers.</p>
<p>Here we will take the average over the last four hidden states for each token.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">last_four_layers</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">:]</span>
<span class="c1"># Stack the layers and then calculate mean</span>
<span class="n">stacked_layers</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">last_four_layers</span><span class="p">)</span>
<span class="n">emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">stacked_layers</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">emb</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([1, 10, 768])
</pre></div>
</div>
</div>
</div>
<p>emb is of shape (sequence_length, hidden_size). Let us summarize the embeddings of the tokens into a function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_bert_embeddings</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">tokenized_text</span><span class="p">,</span> <span class="n">tokens_tensor</span><span class="p">,</span> <span class="n">segments_tensor</span> <span class="o">=</span> <span class="n">prepare_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">tokens_tensor</span><span class="p">,</span> <span class="n">segments_tensor</span><span class="p">)</span>
    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># Access hidden states from tuple output</span>
    <span class="c1"># Stack the last 4 layers then take mean</span>
    <span class="n">stacked_layers</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">:])</span>
    <span class="n">emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">stacked_layers</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">emb</span><span class="p">,</span> <span class="n">tokenized_text</span>
</pre></div>
</div>
</div>
</div>
<p>Now, let us embed text and get the embeddings of the focal token.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># label</span>
<span class="n">emb</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># embedding</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># sentence</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_focal_token_embedding</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">focal_word_idx</span><span class="p">):</span>
    <span class="n">emb</span><span class="p">,</span> <span class="n">tokenized_text</span> <span class="o">=</span> <span class="n">get_bert_embeddings</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">emb</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">focal_word_idx</span><span class="p">]</span>  <span class="c1"># Access first batch dimension</span>

<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">train_data</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">]</span>
    <span class="n">focal_word_idx</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s2">&quot;word_pos&quot;</span><span class="p">]</span>
    <span class="n">_emb</span> <span class="o">=</span> <span class="n">get_focal_token_embedding</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">focal_word_idx</span><span class="p">)</span>
    <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
    <span class="n">emb</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_emb</span><span class="p">)</span>
    <span class="n">sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, let us visualize the embeddings using PCA.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert list of tensors to numpy array</span>
<span class="n">emb_numpy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">emb</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">xy</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">emb_numpy</span><span class="p">)</span>

<span class="n">output_notebook</span><span class="p">()</span>

<span class="c1"># Create data source for Bokeh</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">ColumnDataSource</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">xy</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">xy</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">label</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">sentence</span><span class="o">=</span><span class="n">sentences</span>
<span class="p">))</span>

<span class="c1"># Create Bokeh figure</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">figure</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Word Embeddings Visualization&quot;</span><span class="p">,</span> <span class="n">x_axis_label</span><span class="o">=</span><span class="s2">&quot;PCA 1&quot;</span><span class="p">,</span> <span class="n">y_axis_label</span><span class="o">=</span><span class="s2">&quot;PCA 2&quot;</span><span class="p">,</span>
           <span class="n">width</span><span class="o">=</span><span class="mi">700</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>

<span class="c1"># Add hover tool</span>
<span class="n">hover</span> <span class="o">=</span> <span class="n">HoverTool</span><span class="p">(</span><span class="n">tooltips</span><span class="o">=</span><span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;Label&#39;</span><span class="p">,</span> <span class="s1">&#39;@label&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;Sentence&#39;</span><span class="p">,</span> <span class="s1">&#39;@sentence&#39;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">p</span><span class="o">.</span><span class="n">add_tools</span><span class="p">(</span><span class="n">hover</span><span class="p">)</span>

<span class="c1"># Create color map for labels</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="n">unique_labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
<span class="n">color_map</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()</span><span class="o">.</span><span class="n">as_hex</span><span class="p">()[</span><span class="mi">0</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">)]</span>
<span class="n">source</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;color&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">color_map</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">]</span>

<span class="c1"># Add scatter plot</span>
<span class="n">p</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">line_color</span><span class="o">=</span><span class="s2">&quot;DarkSlateGrey&quot;</span><span class="p">,</span> <span class="n">line_width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
         <span class="n">fill_color</span><span class="o">=</span><span class="s1">&#39;color&#39;</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">)</span>

<span class="n">show</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output text_html">    <style>
        .bk-notebook-logo {
            display: block;
            width: 20px;
            height: 20px;
            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);
        }
    </style>
    <div>
        <a href="https://bokeh.org" target="_blank" class="bk-notebook-logo"></a>
        <span id="f839305d-c3ac-40c6-afb1-e6a9fce654d4">Loading BokehJS ...</span>
    </div>
</div><script type="application/javascript">'use strict';
(function(root) {
  function now() {
    return new Date();
  }

  const force = true;

  if (typeof root._bokeh_onload_callbacks === "undefined" || force === true) {
    root._bokeh_onload_callbacks = [];
    root._bokeh_is_loading = undefined;
  }

const JS_MIME_TYPE = 'application/javascript';
  const HTML_MIME_TYPE = 'text/html';
  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';
  const CLASS_NAME = 'output_bokeh rendered_html';

  /**
   * Render data to the DOM node
   */
  function render(props, node) {
    const script = document.createElement("script");
    node.appendChild(script);
  }

  /**
   * Handle when an output is cleared or removed
   */
  function handleClearOutput(event, handle) {
    function drop(id) {
      const view = Bokeh.index.get_by_id(id)
      if (view != null) {
        view.model.document.clear()
        Bokeh.index.delete(view)
      }
    }

    const cell = handle.cell;

    const id = cell.output_area._bokeh_element_id;
    const server_id = cell.output_area._bokeh_server_id;

    // Clean up Bokeh references
    if (id != null) {
      drop(id)
    }

    if (server_id !== undefined) {
      // Clean up Bokeh references
      const cmd_clean = "from bokeh.io.state import curstate; print(curstate().uuid_to_server['" + server_id + "'].get_sessions()[0].document.roots[0]._id)";
      cell.notebook.kernel.execute(cmd_clean, {
        iopub: {
          output: function(msg) {
            const id = msg.content.text.trim()
            drop(id)
          }
        }
      });
      // Destroy server and session
      const cmd_destroy = "import bokeh.io.notebook as ion; ion.destroy_server('" + server_id + "')";
      cell.notebook.kernel.execute(cmd_destroy);
    }
  }

  /**
   * Handle when a new output is added
   */
  function handleAddOutput(event, handle) {
    const output_area = handle.output_area;
    const output = handle.output;

    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only
    if ((output.output_type != "display_data") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {
      return
    }

    const toinsert = output_area.element.find("." + CLASS_NAME.split(' ')[0]);

    if (output.metadata[EXEC_MIME_TYPE]["id"] !== undefined) {
      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];
      // store reference to embed id on output_area
      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE]["id"];
    }
    if (output.metadata[EXEC_MIME_TYPE]["server_id"] !== undefined) {
      const bk_div = document.createElement("div");
      bk_div.innerHTML = output.data[HTML_MIME_TYPE];
      const script_attrs = bk_div.children[0].attributes;
      for (let i = 0; i < script_attrs.length; i++) {
        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);
        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent
      }
      // store reference to server id on output_area
      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE]["server_id"];
    }
  }

  function register_renderer(events, OutputArea) {

    function append_mime(data, metadata, element) {
      // create a DOM node to render to
      const toinsert = this.create_output_subarea(
        metadata,
        CLASS_NAME,
        EXEC_MIME_TYPE
      );
      this.keyboard_manager.register_events(toinsert);
      // Render to node
      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};
      render(props, toinsert[toinsert.length - 1]);
      element.append(toinsert);
      return toinsert
    }

    /* Handle when an output is cleared or removed */
    events.on('clear_output.CodeCell', handleClearOutput);
    events.on('delete.Cell', handleClearOutput);

    /* Handle when a new output is added */
    events.on('output_added.OutputArea', handleAddOutput);

    /**
     * Register the mime type and append_mime function with output_area
     */
    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {
      /* Is output safe? */
      safe: true,
      /* Index of renderer in `output_area.display_order` */
      index: 0
    });
  }

  // register the mime type if in Jupyter Notebook environment and previously unregistered
  if (root.Jupyter !== undefined) {
    const events = require('base/js/events');
    const OutputArea = require('notebook/js/outputarea').OutputArea;

    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {
      register_renderer(events, OutputArea);
    }
  }
  if (typeof (root._bokeh_timeout) === "undefined" || force === true) {
    root._bokeh_timeout = Date.now() + 5000;
    root._bokeh_failed_load = false;
  }

  const NB_LOAD_WARNING = {'data': {'text/html':
     "<div style='background-color: #fdd'>\n"+
     "<p>\n"+
     "BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \n"+
     "may be due to a slow or bad network connection. Possible fixes:\n"+
     "</p>\n"+
     "<ul>\n"+
     "<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\n"+
     "<li>use INLINE resources instead, as so:</li>\n"+
     "</ul>\n"+
     "<code>\n"+
     "from bokeh.resources import INLINE\n"+
     "output_notebook(resources=INLINE)\n"+
     "</code>\n"+
     "</div>"}};

  function display_loaded(error = null) {
    const el = document.getElementById("f839305d-c3ac-40c6-afb1-e6a9fce654d4");
    if (el != null) {
      const html = (() => {
        if (typeof root.Bokeh === "undefined") {
          if (error == null) {
            return "BokehJS is loading ...";
          } else {
            return "BokehJS failed to load.";
          }
        } else {
          const prefix = `BokehJS ${root.Bokeh.version}`;
          if (error == null) {
            return `${prefix} successfully loaded.`;
          } else {
            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;
          }
        }
      })();
      el.innerHTML = html;

      if (error != null) {
        const wrapper = document.createElement("div");
        wrapper.style.overflow = "auto";
        wrapper.style.height = "5em";
        wrapper.style.resize = "vertical";
        const content = document.createElement("div");
        content.style.fontFamily = "monospace";
        content.style.whiteSpace = "pre-wrap";
        content.style.backgroundColor = "rgb(255, 221, 221)";
        content.textContent = error.stack ?? error.toString();
        wrapper.append(content);
        el.append(wrapper);
      }
    } else if (Date.now() < root._bokeh_timeout) {
      setTimeout(() => display_loaded(error), 100);
    }
  }

  function run_callbacks() {
    try {
      root._bokeh_onload_callbacks.forEach(function(callback) {
        if (callback != null)
          callback();
      });
    } finally {
      delete root._bokeh_onload_callbacks
    }
    console.debug("Bokeh: all callbacks have finished");
  }

  function load_libs(css_urls, js_urls, callback) {
    if (css_urls == null) css_urls = [];
    if (js_urls == null) js_urls = [];

    root._bokeh_onload_callbacks.push(callback);
    if (root._bokeh_is_loading > 0) {
      console.debug("Bokeh: BokehJS is being loaded, scheduling callback at", now());
      return null;
    }
    if (js_urls == null || js_urls.length === 0) {
      run_callbacks();
      return null;
    }
    console.debug("Bokeh: BokehJS not loaded, scheduling load and callback at", now());
    root._bokeh_is_loading = css_urls.length + js_urls.length;

    function on_load() {
      root._bokeh_is_loading--;
      if (root._bokeh_is_loading === 0) {
        console.debug("Bokeh: all BokehJS libraries/stylesheets loaded");
        run_callbacks()
      }
    }

    function on_error(url) {
      console.error("failed to load " + url);
    }

    for (let i = 0; i < css_urls.length; i++) {
      const url = css_urls[i];
      const element = document.createElement("link");
      element.onload = on_load;
      element.onerror = on_error.bind(null, url);
      element.rel = "stylesheet";
      element.type = "text/css";
      element.href = url;
      console.debug("Bokeh: injecting link tag for BokehJS stylesheet: ", url);
      document.body.appendChild(element);
    }

    for (let i = 0; i < js_urls.length; i++) {
      const url = js_urls[i];
      const element = document.createElement('script');
      element.onload = on_load;
      element.onerror = on_error.bind(null, url);
      element.async = false;
      element.src = url;
      console.debug("Bokeh: injecting script tag for BokehJS library: ", url);
      document.head.appendChild(element);
    }
  };

  function inject_raw_css(css) {
    const element = document.createElement("style");
    element.appendChild(document.createTextNode(css));
    document.body.appendChild(element);
  }

  const js_urls = ["https://cdn.bokeh.org/bokeh/release/bokeh-3.6.0.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.0.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.0.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.0.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.6.0.min.js"];
  const css_urls = [];

  const inline_js = [    function(Bokeh) {
      Bokeh.set_log_level("info");
    },
function(Bokeh) {
    }
  ];

  function run_inline_js() {
    if (root.Bokeh !== undefined || force === true) {
      try {
            for (let i = 0; i < inline_js.length; i++) {
      inline_js[i].call(root, root.Bokeh);
    }

      } catch (error) {display_loaded(error);throw error;
      }if (force === true) {
        display_loaded();
      }} else if (Date.now() < root._bokeh_timeout) {
      setTimeout(run_inline_js, 100);
    } else if (!root._bokeh_failed_load) {
      console.log("Bokeh: BokehJS failed to load within specified timeout.");
      root._bokeh_failed_load = true;
    } else if (force !== true) {
      const cell = $(document.getElementById("f839305d-c3ac-40c6-afb1-e6a9fce654d4")).parents('.cell').data().cell;
      cell.output_area.append_execute_result(NB_LOAD_WARNING)
    }
  }

  if (root._bokeh_is_loading === 0) {
    console.debug("Bokeh: BokehJS loaded, going straight to plotting");
    run_inline_js();
  } else {
    load_libs(css_urls, js_urls, function() {
      console.debug("Bokeh: BokehJS plotting callback run at", now());
      run_inline_js();
    });
  }
}(window));</script><div class="output text_html">
  <div id="bf01f8ea-07b8-43db-9267-2e18f1840f17" data-root-id="p1004" style="display: contents;"></div>
</div><script type="application/javascript">(function(root) {
  function embed_document(root) {
  const docs_json = {"e79580ac-c14e-4577-8f39-21d18444fd8d":{"version":"3.6.0","title":"Bokeh Application","roots":[{"type":"object","name":"Figure","id":"p1004","attributes":{"width":700,"height":500,"x_range":{"type":"object","name":"DataRange1d","id":"p1005"},"y_range":{"type":"object","name":"DataRange1d","id":"p1006"},"x_scale":{"type":"object","name":"LinearScale","id":"p1014"},"y_scale":{"type":"object","name":"LinearScale","id":"p1015"},"title":{"type":"object","name":"Title","id":"p1007","attributes":{"text":"Word Embeddings Visualization"}},"renderers":[{"type":"object","name":"GlyphRenderer","id":"p1046","attributes":{"data_source":{"type":"object","name":"ColumnDataSource","id":"p1001","attributes":{"selected":{"type":"object","name":"Selection","id":"p1002","attributes":{"indices":[],"line_indices":[]}},"selection_policy":{"type":"object","name":"UnionRenderers","id":"p1003"},"data":{"type":"map","entries":[["x",{"type":"ndarray","array":{"type":"bytes","data":"Ojxzv2mB4D4qb9vAJvD2P9cqkr7t+vw/x1DbvnQe1D+1XQTBUXvJQEUn1j8/2BTAoXecwOvEib6GpbFA0XeuQJnl58AQdQRAPXiHP53IkkDJJs3AaOL+wKbvJsDdEii+hqEMQXdB6z8dk36/4AkGwdcirUDIKkVAlhJOQLhZC0D/jtk/K23swJDOZEDekYfACyicvldOpj6x6Te/wjmGv3MjB0CkOwa/q8oJQMaZP8BG6dzAkLr5QE0woL8gG50/Pr4EwWCH6D9Oe1tAvtD3P1X3Z8CycKpAgcoMPycD1cA/ngjBUmKFv0BIHkAt0D4/OMU1wLUr378KaNQ/MvtqQNvWX0CfoY/AGBDbQJkPCcAWOG4/6p/uP00mJT9j4D3A0BAvwNkD/EAqpTzAawGoQGSsd0APub6/5TKSQAfcur85YSzAGUIPQCyoqL2ge58/TrWcQOjNbkDH79HAqCkRwKvbmsBUTRRAAqnsP4FPm7xrDRBAjykgvycqlEA8aOc/dP/SvucircDuhoy/itK+Pg=="},"shape":[100],"dtype":"float32","order":"little"}],["y",{"type":"ndarray","array":{"type":"bytes","data":"7bKhwBcgFj/lZ72+Rym4v0dJvsDu0WJAmDHfQGpSRL/IaK1AVXcWwNx9uz+9hRm/5xQ/v2A7b7+9ZetAV+43v442J0CRhrVAm1JRQD1osj/titA/fg6oQMoOQMDLT3zA9YqjQE4Om8BrFgfAmV6RQNy9DkGXnUhA3ZaswPmbBEA4WQe/s0bAvkmNrcB+7gLAYuWiwEL8nsBHcgLA1UgDPloVWkDRi76/0gkPQOl3SD8/JKQ/yqg5QGmPCMBU9Uk/g1+mQKvpmL8dbb3AGjZKwFNYoD9H+bJAjuclQApNZD4xp81AlzG3QJeQosCgaB3A2h+WwCUV976qtjZAkPRSwPQdiMCtDoI+xTxoPxWad8DGGn7AuSGWQD/U3b8KIoHA4VkuwHKLo0Cjq4LAcgYNwNy/iMA835c+hWCvQFCk6b9+wZy/8CMRP0Kyo79VCgDAjw42QGXklED28h49IFcDvhCaXD6TVonAMwSEwPkylj9/Vd+/sEGqPBmwDEB6hL2/VL5xP7Q9m77pbC/AMc2RPw=="},"shape":[100],"dtype":"float32","order":"little"}],["label",[0,0,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,1,0,1,1,0,0,0,1,0,0,0,1,0,1,0,0,1,1,0,0,0,0,0,0,0,1,0,0,1,0,0,0,1,1,1,0,0,1,0,1,0,0,1,0,0,0]],["sentence",["both seasons are available for download from apple 's itunes store .","third-party support avid 's media composer 3.5.0 provides support via avid media access ( ama ) , a new plug-in architecture apple 's final cut pro 7 provides native avc-intra decoding within a prores 422 timeline .","working conditions wage levels in an examination of chinese factories producing electronic goods for the west , including apple and microsoft , reporting indicates that workers are often paid less than 2 usd per hour .","initially a weak copy protection system in the 1980s apple macintosh operating system , the term '' flipping the bozo bit '' was later reused to describe a decision to ignore a person 's input .","originally , it was possible to develop on apple and dec platforms ; now , windows is the supported platform for development .","in the late 18th and early 19th centuries , westford primarily produced granite , apple , and worsted yarn .","organizations such as at&t , coca-cola , starbucks , apple , and harley-davidson all participate in marketing development and distribution of their marketing concepts .","apple rejected the app three times , calling its content '' crude and objectionable '' .","approximately 10 million sony batteries used in dell , sony , apple , lenovo , panasonic , toshiba , hitachi , fujitsu and sharp laptops were recalled in 2006 .","swift is a multi-paradigm , compiled programming language created by apple for ios and os&nbsp;x development .","they also have mobile versions of livegonzo.com for apple products , blackberry and android ; and they are broadcasting each of the live shows on iphone , ipad , ipod , blackberry and android phones .","early promoters of the festival intended for the event to recognize the scenic beauty of the valley and the historic background of the apple growing industry , as well as to provide an opportunity to foster and develop local cultural talent through participation in festival events .","on unix - compatible systems , including gnu / linux and apple mac os x , tex is distributed in the form of the tetex distribution and more recently the tex live distribution .","his prayer is answered by frigg , wife of odin , who sends him an apple , which is dropped on his lap by frigg 's servant in the form of a crow while rerir is sitting on a mound .","zte and china mobile have done turnkey mobile phone network projects in pakistan , ethiopia , etc. mobile phones mobile phone manufacturers bbk coolpad ( yulong ) cect gionee haier hisense huawei konka lenovo ( motorola ) meizu oneplus oppo sagetel ( ningbo bird ) tcl xiaomi zte apple blackberry google htc ( dopod ) lg microsoft ( nokia ) pantech philips samsung sony sharp domestics sales the domestic sales of cell phone made a breakthrough of 100 million in china in 2006 .","iframe logo iframe is a digital video format developed by apple .","development although it was once a leading manufacturer of smartphones in terms of market share , htc has recently struggled in the wake of other vendors such as samsung and apple , due particularly to their wider marketing reach .","past projects the firm has contributed to the development of products for many fortune 500 companies , including aol , apple , ge , intel , logitech , microsoft , nielsen , nike , panasonic , precor , philips , samsung , starbucks , t-mobile and tomtom .","tameka 's other favorite items include brazil nut , water melon , apple and rum .","it was later renamed '' power3 '' , probably to distinguish it from the more consumer oriented '' powerpc '' processors used by apple .","companies such as apple , general radio , nordstrom and british airways have all had continued success throughout the years because of their capacity for ambidexterity .","the people of ain ebel cultivate their land and produce olive , almond , chestnut , pecan , grape , fig , pomegranate , and apple .","'' the next single '' ride '' was released on 8 march 2004 , although it was n't a big chart success , '' ride '' is one of the band 's best known songs because it was featured in a number of advertisement , including commercials for apple 's ipod , nissan , american chopper , nascar hot pass , wkcf and .","music video the music video was uploaded to youtube on may 28 , 2014 , using the apple and twitter software vine .","operating systems available for these platforms include ms windows , freebsd , the different gnu / linux distribution , apple mac os x , and oracle solaris .","'' home '' was released to the apple itunes store on june 8 , 2010 .","adaptations to new technology in october 2010 , random house of canada introduced the '' conversation starters '' application for apple 's iphone and ipad .","but lately some farmers try other crops such as grape , apple , pistacio and olive .","notable examples include : linkedin : the serious network 6 reasons why apis are reshaping your business facebook : the perfect startup amazon.com : the hidden empire apple : 8 easy steps to beat microsoft ( and google ) why could google die ... maybe not now , but tomorrow excubation the company operates with a startup mindset , launching prototypes with lean budgets and skeleton crews , and later expanding resources to accommodate growth .","applegeeks was largely based around the misadventures of '' hawk , '' a somewhat delusional college student with an unnatural fondness for apple products ; his aspiring writer friend , jayce ; and their friends and cohorts .","it powers apple 's safari web browser and was previously used in google 's chrome web browser .","on june 11 , 2012 , apple announced new macbook air and macbook pro with usb 3.0 .","0xdeadfa11 ( '' dead fall '' ) is used by apple in ios crash reports , when the user force quits an application .","the gray currawong also eats berries of introduced plants such as pyracantha angustifolia and fortuneana , and cotoneaster species , and crops such as maize , apple , pear , quince , various stone fruit of the genus prunus , grape , tomato , passion flower , and the nectar of gymea lily ( doryanthes excelsa ) .","during the 2011 -- 12 season , the afv ios app was released on the app store , allowing users of apple mobile devices to record and upload funny videos for submission to the show .","in 2011 the bill was amended further to include ; apple , ginger , passion fruit , peach and pear wine in 2013 , the state assembly unanimously passed a resolution to study the impact of liquor prohibition .","in january 2007 , the first season of star trek : the original series became available for download from apple 's itunes store .","the game was later ported to apple 's iphone and ipod touch on november 14 , 2009 .","they sometimes eat apple .","partners the academy 's partners include apple , arri , cannes film festival , goldsmiths , university of london , kodak , new horizons film festival , riverside studios , deluxe entertainment services group inc . , and anglia ruskin university ( cambridge campus ) courses of study the college provides a variety of film-making courses , taught either in london or in the algarve , portugal ( in association with the algarve film commission ) .","operators such as at & t mobility can not offer their traditional services ( such as downloads of wallpapers , ringtones , games , applications , etc. ) as apple controls the total iphone user experience .","videos could be displayed , downloaded and shared across the web in either apple quicktime or flv format .","in modern ides all major development environments supply some manner of class browser , including apple xcode for mac os x cincom smalltalk codewarrior for microsoft windows , mac os , and embedded systems eclipse embarcadero delphi embarcadero jbuilder ibm websphere intellij idea kdevelop microsoft visual studio netbeans red gate .net reflector squeak smalltalk step ahead javelin visual prolog zeus for windows ide modern class browsers fall into three general categories : the columnar browsers , the outline browsers , and the diagram browsers .","famous alumni include u.s. president richard nixon , chile president ricardo lagos , former cabinet member and former senator elizabeth dole , philanthropist melinda french gates , and the chief executive officers of apple ( tim cook ) , morgan stanley ( john j. mack ) and pfizer ( edmund t. pratt , jr . ) and former general motors corporation ceo ( rick wagoner ) as well as the first united states chief performance officer jeffrey zients .","notable merchants companies like apple , target , barnes & noble , qdoba , fuddruckers , walmart , reebok , sephora , the north face , toshiba , puma , drugstore.com , adidas and pacsun offer student discounts via edhance .","renderware was widely cross-platform : it ran on windows as well as apple mac os x - based applications and many video game consoles such as nintendo gamecube , wii , xbox , xbox 360 , playstation 2 , playstation 3 , and playstation portable .","it is also possible that apple and apricot were imported on a small scale , and by greco-roman times quince , pear , plum , peach , filbert , walnut , pine nut , and pistachio were introduced .","the granny smith is a tip-bearing apple cultivar , which originated in australia in 1868 .","these rely on media that are not owned by the data owner but by service provider such as google , apple , microsoft and facebook .","apple finally reorganized the compact macintosh case to accommodate a fan with the release of the macintosh se .","it also supported apple 's game sprockets .","in 2007 he became the voice for text-to-speech software , which in 2011 included the british version of siri , the personal assistant application for the apple iphone .","in fruit such as the apple , cranberry and quince , it is referred to as black rot , and in twigs and trunks it causes canker .","plot of cpu transistor count against dates of introduction ; note the logarithmic vertical scale ; the line corresponds to exponential growth with transistor count doubling every two years an osborne executive portable computer , from 1982 with a zilog z80 4mhz cpu , and a 2007 apple iphone with a 412mhz arm11 cpu ; the executive weighs 100 times as much , has nearly 500 times as much volume , cost approximately 10 times as much ( adjusted for inflation ) , and has about 1/100th the clock frequency of the smartphone '' moore 's law '' is the observation that , over the history of computing hardware , the number of transistor in a dense integrated circuit doubles approximately every two years .","products in the caldera include fruits ( apple , grapes , quince fruit , pomegranate , fig , peach and tomato ) and vegetables ( bean , corn , potato , yam , manioc , and peppers ) for local consumption and commercial production .","the ccaf has raised objections to class action settlements involving the grand theft auto '' hot coffee '' minigame , honda civic hybrid , apple backdating , a.g. edwards , bluetooth headsets , and the cobell indian trust .","it provides specialized global wireless distribution and services , serving mobile device manufacturers , wireless operators and retailers , including global distribution for motorola , blackberry , apple , htc , lg and samsung .","aside from these two primary crops , the region produces a wide variety of products which include barley , corn , flax , grape , potato , rice , sugar beet , sunflower , tobacco , apricot , pear , plum , apple , cherries , pomegranate , melon , dates , fig , sesame , pistachio , and nuts .","hypertransport has also been used by ibm and apple for the power mac g5 machines , as well as a number of modern mips systems .","computer-based dvd ( digital versatile disk ) drives dvd recorder drives have become standard equipment in many , though not all , computer systems currently on the market , after being initially popularized by the pioneer / apple superdrive ; aftermarket drives as of early 2007 can cost as little as $ 23 .","the most common version of unix ( bearing certification ) is apple 's os x , while linux is the most popular non-certified workalike .","the festival was originally created in 1962 as a way to provide a market for the county 's apple production .","however , in recent years , its market share declined as a result of the growing use of touchscreen smartphones from other vendors , such as apple 's iphone line and android - based products .","net , open source ( via monotouch ) core data by apple for mac os x and ios . net ado.net entity framework , included in .","bootcd is a tool for making bootable cd with apple 's operating system mac os x with a working finder and dock .","among the ingredients used are plum or pear syrup , dried pears , plums or cherries , apple vinegar and honey .","similar to glib , apple 's cross-platform core foundation framework provides several basic data types .","basque cider is an apple cider from the basque region of europe served at sagardotegi ( cider house ) .","while the megarray connector is physically similar to the apple power mac g4 cpu daughtercard connector , it is not electrically compatible .","in april 2010 , the site was the 28th most visited site in the world according to alexa 's internet rankings and in august 2010 , the site was the 27th most visited site drawing more traffic than the websites of aol , bbc , flickr , craigslist , apple , cnn , linkedin , adobe , cnet , espn and several other heavy hitters .","in january , 2012 the focus changed to economic development projects and the organization was rebranded as aythos , inc. projects in 2012 aythos was asked to consult for a grant to develop apple tree and kiwifruit plant farms in villages in helambu .","this included apple , grape , maple and vinegar products that were sold to the public in a store in south amherst .","for example , microsoft makes the microsoft windows api public , and apple releases its apis carbon and cocoa , so that software can be written for their platform .","history official support for mac os 9 ( and mac os 8.6 ) in the mozilla application suite ended with the release of mozilla 1.2.1 in 2002 , coincident with apple ending support for their legacy operating system .","in 2010 the museum began with the collection of source code of important software , beginning with apple 's macpaint 1.3 , written in a combination of assembly and pascal and available as download for the public .","created notes are synced through all the user 's apple devices through the icloud service .","xgrid is developed by apple .","following the august 2014 acquisition of beats by apple , a new ad was released featuring the pill characters , in which siri refuses to invite them attend a party being held by dr. dre to celebrate the deal .","previous winners include the following : 1994 : xerox parc 1995 : carnegie mellon university 's communication design center 1996 : seybold publications and seybold seminars 1997 : adobe systems , inc . 1998 : netscape communications corp . 1999 : rensselaer polytechnic institute 2000 : mit press 2001 : information mapping , inc . 2002 : world wide web consortium 2003 : ibm 2004 : the society for technical communication ( stc ) 2005 : the british computer society ( bcs ) 2007 : university of washington 's laboratory for usability testing and evaluaton ( lute ) 2009 : apple 2011 : sap the winner of the graduate student competition is provided with subsidized participation in the sigdoc conference , and the opportunity to publish and present their work .","the druids preferred yew for wand-making over their other favorite woods , apple and oak .","it was developed by apple as '' firewire '' in the late 1980s and early 1990s , and macintosh computers have supported '' firewire target disk mode '' since 1999 .","business model a welcome message from plos to nature publishing group on the launch of scientific reports , inspired by a similar message sent in 1981 by apple to ibm upon the latter 's entry into the personal computer market with its ibm personal computer .","opal is the brand name for a variety of apple produced by crossing golden delicious with topaz .","another prominent proponent of the voucher system was apple co-founder and ceo , steve jobs , who said : some proponents of school vouchers , including the sutherland institute and many supporters of the utah voucher effort , see it as a remedy for the negative cultural impact caused by under-performing public schools , which falls disproportionately on demographic minorities .","rickner helped create the first truetype fonts at apple and did all the font hinting for microsoft 's georgia and verdana fonts .","aside from co-founding purple moon , she has served as an interaction design consultant for multiple companies including sony pictures , apple , and citibank .","less usual foods that have been reported are dried vegetable remains , dried fruits ( especially apple and raisin ) , horn shavings ( an organic fertilizer ) , cork and even refined sugar .","it is one of the country 's most important apple growing regions and other stone fruit such as cherries and apricots are also harvested locally .","ingredients kofo syrup , the main ingredient of kofola , consists of 14 natural ingredients ( such as extracts from apple , cherry , currant , or herbal aroma ) , sugar , and caramel .","since its creation apple has added additional verifications to the finder to prevent such an attack .","live at xm is an ep by wheatus released on 15 december 2004 and exclusively available at apple 's itunes store .","it consists of two hollow parts : a handle and a top , the so-called apple .","thunderbolt was co-developed by apple and intel .","kazakhstan is thought to be one of the places that the apple originated , particularly the wild ancestor of malus domestica , malus sieversii .","old macintosh db25 scsi port apple used db-25 connectors , which , having only 25 pins rather than 50 , were less expensive to make , but compromised functionality .","she proposed what became lisaproject to trip hawkins at apple .","pl\u0103cint\u0103 is a romania traditional pastry resembling a thin , small round or square-shaped cake , usually filled with a soft cheese such as urd\u0103 or apple .","some stores inside the mall include apple , teavana , banana republic , a multi level h&m ( coming 2014 ) , ann taylor , build-a-bear workshop , coach , pandora , sephora , michael kors , white house/black market , williams-sonoma , and a two level dual gender forever 21 history augusta mall had about 90 retail spaces when it first opened , anchored by two department stores : rich's and davison's .","universal binary in apple parlance , an executable file or application bundle that runs natively on either powerpc or intel - manufactured ia-32 or intel 64 - based macs ; it is an implementation of the concept more generally known as a fat binary .","the company 's technology practice expanded rapidly over the 1990s with major clients including apple , sun microsystems and qualcomm and its headquarters moved to silicon valley in the late 1990s ."]],["color",["#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#ff7f0e","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#ff7f0e","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#ff7f0e","#ff7f0e","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#ff7f0e","#1f77b4","#ff7f0e","#ff7f0e","#1f77b4","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#ff7f0e","#1f77b4","#1f77b4","#ff7f0e","#ff7f0e","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#1f77b4","#1f77b4","#ff7f0e","#ff7f0e","#ff7f0e","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#ff7f0e","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#1f77b4","#1f77b4"]]]}}},"view":{"type":"object","name":"CDSView","id":"p1047","attributes":{"filter":{"type":"object","name":"AllIndices","id":"p1048"}}},"glyph":{"type":"object","name":"Scatter","id":"p1043","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"value","value":12},"line_color":{"type":"value","value":"DarkSlateGrey"},"line_width":{"type":"value","value":2},"fill_color":{"type":"field","field":"color"}}},"nonselection_glyph":{"type":"object","name":"Scatter","id":"p1044","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"value","value":12},"line_color":{"type":"value","value":"DarkSlateGrey"},"line_alpha":{"type":"value","value":0.1},"line_width":{"type":"value","value":2},"fill_color":{"type":"field","field":"color"},"fill_alpha":{"type":"value","value":0.1},"hatch_alpha":{"type":"value","value":0.1}}},"muted_glyph":{"type":"object","name":"Scatter","id":"p1045","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"value","value":12},"line_color":{"type":"value","value":"DarkSlateGrey"},"line_alpha":{"type":"value","value":0.2},"line_width":{"type":"value","value":2},"fill_color":{"type":"field","field":"color"},"fill_alpha":{"type":"value","value":0.2},"hatch_alpha":{"type":"value","value":0.2}}}}}],"toolbar":{"type":"object","name":"Toolbar","id":"p1013","attributes":{"tools":[{"type":"object","name":"PanTool","id":"p1026"},{"type":"object","name":"WheelZoomTool","id":"p1027","attributes":{"renderers":"auto"}},{"type":"object","name":"BoxZoomTool","id":"p1028","attributes":{"overlay":{"type":"object","name":"BoxAnnotation","id":"p1029","attributes":{"syncable":false,"line_color":"black","line_alpha":1.0,"line_width":2,"line_dash":[4,4],"fill_color":"lightgrey","fill_alpha":0.5,"level":"overlay","visible":false,"left":{"type":"number","value":"nan"},"right":{"type":"number","value":"nan"},"top":{"type":"number","value":"nan"},"bottom":{"type":"number","value":"nan"},"left_units":"canvas","right_units":"canvas","top_units":"canvas","bottom_units":"canvas","handles":{"type":"object","name":"BoxInteractionHandles","id":"p1035","attributes":{"all":{"type":"object","name":"AreaVisuals","id":"p1034","attributes":{"fill_color":"white","hover_fill_color":"lightgray"}}}}}}}},{"type":"object","name":"SaveTool","id":"p1036"},{"type":"object","name":"ResetTool","id":"p1037"},{"type":"object","name":"HelpTool","id":"p1038"},{"type":"object","name":"HoverTool","id":"p1039","attributes":{"renderers":"auto","tooltips":[["Label","@label"],["Sentence","@sentence"]]}}]}},"left":[{"type":"object","name":"LinearAxis","id":"p1021","attributes":{"ticker":{"type":"object","name":"BasicTicker","id":"p1022","attributes":{"mantissas":[1,2,5]}},"formatter":{"type":"object","name":"BasicTickFormatter","id":"p1023"},"axis_label":"PCA 2","major_label_policy":{"type":"object","name":"AllLabels","id":"p1024"}}}],"below":[{"type":"object","name":"LinearAxis","id":"p1016","attributes":{"ticker":{"type":"object","name":"BasicTicker","id":"p1017","attributes":{"mantissas":[1,2,5]}},"formatter":{"type":"object","name":"BasicTickFormatter","id":"p1018"},"axis_label":"PCA 1","major_label_policy":{"type":"object","name":"AllLabels","id":"p1019"}}}],"center":[{"type":"object","name":"Grid","id":"p1020","attributes":{"axis":{"id":"p1016"}}},{"type":"object","name":"Grid","id":"p1025","attributes":{"dimension":1,"axis":{"id":"p1021"}}}]}}]}};
  const render_items = [{"docid":"e79580ac-c14e-4577-8f39-21d18444fd8d","roots":{"p1004":"bf01f8ea-07b8-43db-9267-2e18f1840f17"},"root_ids":["p1004"]}];
  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);
  }
  if (root.Bokeh !== undefined) {
    embed_document(root);
  } else {
    let attempts = 0;
    const timer = setInterval(function(root) {
      if (root.Bokeh !== undefined) {
        clearInterval(timer);
        embed_document(root);
      } else {
        attempts++;
        if (attempts > 100) {
          clearInterval(timer);
          console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");
        }
      }
    }, 10, root)
  }
})(window);</script></div>
</div>
</section>
<section id="exercise">
<h2>Exercise<a class="headerlink" href="#exercise" title="Link to this heading">#</a></h2>
<p>We have used the last 4 layers of BERT to generate the embeddings of the tokens. Now, let’s use the last <span class="math notranslate nohighlight">\(k = 1, 2, 3\)</span> layers of BERT to generate the embeddings of the tokens. Then plot the embeddings using PCA.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<div class="docutils container" id="id12">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-reimers2019sentence" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id9">2</a>)</span>
<p>Nils Reimers and Iryna Gurevych. Sentence-bert: sentence embeddings using siamese bert-networks. In <em>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing</em>. Association for Computational Linguistics, 11 2019. URL: <a class="reference external" href="https://arxiv.org/abs/1908.10084">https://arxiv.org/abs/1908.10084</a>.</p>
</aside>
<aside class="footnote brackets" id="footcite-vaswani2017attention" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, <em>Advances in Neural Information Processing Systems</em>, volume 30. Curran Associates, Inc., 2017. URL: <a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a>.</p>
</aside>
<aside class="footnote brackets" id="footcite-raffel2020exploring" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">3</a><span class="fn-bracket">]</span></span>
<p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. <em>Journal of machine learning research</em>, 21(140):1–67, 2020.</p>
</aside>
<aside class="footnote brackets" id="footcite-liu2019roberta" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id5">1</a>,<a role="doc-backlink" href="#id11">2</a>)</span>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: a robustly optimized bert pretraining approach. <em>ArXiv</em>, 2019. URL: <a class="reference external" href="https://api.semanticscholar.org/CorpusID:198953378">https://api.semanticscholar.org/CorpusID:198953378</a>.</p>
</aside>
<aside class="footnote brackets" id="footcite-sanh2019distilbert" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id6">5</a><span class="fn-bracket">]</span></span>
<p>Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter. <em>ArXiv</em>, 2019. URL: <a class="reference external" href="https://api.semanticscholar.org/CorpusID:203626972">https://api.semanticscholar.org/CorpusID:203626972</a>.</p>
</aside>
<aside class="footnote brackets" id="footcite-lan2019albert" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">6</a><span class="fn-bracket">]</span></span>
<p>Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. Albert: a lite bert for self-supervised learning of language representations. In <em>International Conference on Learning Representations</em>. 2020. URL: <a class="reference external" href="https://openreview.net/forum?id=H1eA7AEtvS">https://openreview.net/forum?id=H1eA7AEtvS</a>.</p>
</aside>
<aside class="footnote brackets" id="footcite-lee2020biobert" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">7</a><span class="fn-bracket">]</span></span>
<p>Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, and Jaewoo Kang. Biobert: a pre-trained biomedical language representation model for biomedical text mining. <em>Bioinformatics</em>, 36(4):1234–1240, 2020.</p>
</aside>
<aside class="footnote brackets" id="footcite-araci2019finbert" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id10">8</a><span class="fn-bracket">]</span></span>
<p>Dogu Araci. Finbert: financial sentiment analysis with pre-trained language models. <em>ArXiv</em>, 2019. URL: <a class="reference external" href="https://api.semanticscholar.org/CorpusID:201646244">https://api.semanticscholar.org/CorpusID:201646244</a>.</p>
</aside>
</aside>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "skojaku/applied-soft-comp",
            ref: "gh-pages",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./m03-transformers"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="transformers.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Transformers</p>
      </div>
    </a>
    <a class="right-next"
       href="sentence-bert.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Sentence-BERT</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture">Architecture</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#special-tokens">Special tokens</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#position-and-segment-embeddings">Position and Segment embeddings</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-training">Pre-training</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#masked-language-modeling-mlm">Masked Language Modeling (MLM)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#next-sentence-prediction-nsp">Next Sentence Prediction (NSP)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning">Fine-tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variants-and-improvements">Variants and improvements</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hands-on">Hands on</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">Exercise</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Sadamori Kojaku
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>