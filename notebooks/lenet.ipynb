{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/skojaku/applied-soft-comp/blob/master/notebooks/lenet.ipynb)\n",
    "\n",
    "\n",
    "# LeNet-1 for MNIST\n",
    "\n",
    "In this notebook, we will implement LeNet-1 for MNIST dataset. We will first train the model on the MNIST dataset and then create an interactive digit recognizer using the trained model.\n",
    "\n",
    "\n",
    "![](https://production-media.paperswithcode.com/datasets/MNIST-0000000001-2e09631a_09liOmx.jpg)\n",
    "\n",
    "\n",
    "## Install libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to install the libraries\n",
    "# !pip install ipywidgets pillow ipycanvas pytorch_lightning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using Google Colab, uncomment the following line to enable the custom widget manager\n",
    "#from google.colab import output\n",
    "#output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-1\n",
    "Let us first define the LeNet-1 model using PyTorch Lightning. We note that this is not a faithful implementation of LeNet-1. We will use some modern techniques such as the Adam optimizer to speed up the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "class LeNet1(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    PyTorch Lightning implementation of LeNet-1\n",
    "    Includes training, validation, and test functionality\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate=1e-3):\n",
    "        super(LeNet1, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Metrics\n",
    "        self.train_accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "        # First convolutional layer (1x28x28 -> 4x24x24)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5, stride=1)\n",
    "\n",
    "        # Average pooling layer (4x24x24 -> 4x12x12)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Second convolutional layer (4x12x12 -> 12x8x8)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=12, kernel_size=5, stride=1)\n",
    "\n",
    "        # Fully connected layer (12*4*4=192 -> 10)\n",
    "        self.fc = nn.Linear(12 * 4 * 4, 10)\n",
    "\n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "\n",
    "        # Initialize validation losses\n",
    "        self.val_losses = []\n",
    "        self.train_losses = []\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights using Xavier initialization\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First conv block\n",
    "        x = self.conv1(x)\n",
    "        x = torch.tanh(\n",
    "            x\n",
    "        )  # while the original paper does not mention the activation function, we use tanh here\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Second conv block\n",
    "        x = self.conv2(x)\n",
    "        x = torch.tanh(\n",
    "            x\n",
    "        )  # while the original paper does not mention the activation function, we use tanh here\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Flatten and fully connected\n",
    "        x = x.view(-1, 12 * 4 * 4)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Define optimizers and LR schedulers\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=\"min\", factor=0.1, patience=10, verbose=True\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val_loss\"},\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"Training step\"\"\"\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        # Log metrics\n",
    "        acc = self.train_accuracy(logits, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True)\n",
    "\n",
    "        self.train_losses.append({\"loss\": loss.item(), \"acc\": acc.item()})\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"Validation step\"\"\"\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        # Log metrics\n",
    "        acc = self.val_accuracy(logits, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "        self.val_losses.append({\"loss\": loss.item(), \"acc\": acc.item()})\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"Test step\"\"\"\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        # Log metrics\n",
    "        acc = self.test_accuracy(logits, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Button, HBox, VBox, HTML\n",
    "from IPython.display import display\n",
    "import io\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "from torchvision import transforms\n",
    "import ipywidgets as widgets\n",
    "from ipycanvas import Canvas\n",
    "\n",
    "class DigitRecognizer:\n",
    "    def __init__(self, model_path):\n",
    "        # Load the trained model\n",
    "        self.model = LeNet1.load_from_checkpoint(model_path)\n",
    "        self.model.eval()\n",
    "\n",
    "        # Initialize the drawing canvas\n",
    "        self.canvas_size = 280  # 28x28 pixels * 10 for better drawing\n",
    "\n",
    "        # Create canvas with sync_image_data enabled\n",
    "        self.canvas = Canvas(width=self.canvas_size, height=self.canvas_size, sync_image_data=True)\n",
    "\n",
    "        # Set initial canvas properties\n",
    "        self.canvas.fill_style = \"white\"\n",
    "        self.canvas.fill_rect(0, 0, self.canvas_size, self.canvas_size)\n",
    "        self.canvas.line_cap = \"round\"\n",
    "        self.canvas.line_join = \"round\"\n",
    "\n",
    "        # Create buttons\n",
    "        self.clear_button = Button(description='Clear')\n",
    "        self.predict_button = Button(description='Predict')\n",
    "        self.result_label = HTML(value='<h3>Draw a digit and click Predict</h3>')\n",
    "\n",
    "        # Setup button callbacks\n",
    "        self.clear_button.on_click(self.clear_canvas)\n",
    "        self.predict_button.on_click(self.make_prediction)\n",
    "\n",
    "        # Setup drawing state\n",
    "        self.drawing = False\n",
    "        self.last_x = None\n",
    "        self.last_y = None\n",
    "\n",
    "        # Setup mouse event handlers\n",
    "        self.canvas.on_mouse_down(self.start_drawing)\n",
    "        self.canvas.on_mouse_move(self.draw)\n",
    "        self.canvas.on_mouse_up(self.stop_drawing)\n",
    "        self.canvas.on_mouse_out(self.stop_drawing)\n",
    "\n",
    "        # Display the UI\n",
    "        display(VBox([\n",
    "            self.canvas,\n",
    "            HBox([self.clear_button, self.predict_button]),\n",
    "            self.result_label\n",
    "        ]))\n",
    "\n",
    "    def clear_canvas(self, b=None):\n",
    "        \"\"\"Clear the canvas\"\"\"\n",
    "        self.canvas.fill_style = \"white\"\n",
    "        self.canvas.fill_rect(0, 0, self.canvas_size, self.canvas_size)\n",
    "        self.result_label.value = '<h3>Draw a digit and click Predict</h3>'\n",
    "\n",
    "    def start_drawing(self, x, y):\n",
    "        self.drawing = True\n",
    "        self.last_x = x\n",
    "        self.last_y = y\n",
    "\n",
    "        # Option 1: Remove initial point drawing entirely\n",
    "        # Just initialize the position without drawing anything\n",
    "\n",
    "        # OR Option 2: Draw a much smaller initial point\n",
    "        self.canvas.begin_path()\n",
    "        self.canvas.arc(x, y, 2, 0, 2 * np.pi)  # Reduced radius from 10 to 2\n",
    "        self.canvas.fill_style = 'black'\n",
    "        self.canvas.fill()\n",
    "        self.canvas.close_path()\n",
    "\n",
    "    def draw(self, x, y):\n",
    "        if self.drawing and self.last_x is not None and self.last_y is not None:\n",
    "            self.canvas.begin_path()\n",
    "            self.canvas.move_to(self.last_x, self.last_y)\n",
    "            self.canvas.line_to(x, y)\n",
    "            self.canvas.line_width = 20\n",
    "            self.canvas.stroke_style = 'black'\n",
    "            self.canvas.stroke()\n",
    "            self.canvas.close_path()\n",
    "\n",
    "            self.last_x = x\n",
    "            self.last_y = y\n",
    "\n",
    "    def stop_drawing(self, x, y):\n",
    "        self.drawing = False\n",
    "        self.last_x = None\n",
    "        self.last_y = None\n",
    "\n",
    "    def preprocess_image(self):\n",
    "        # Get image data and convert to PIL Image\n",
    "        image_data = self.canvas.get_image_data()\n",
    "        img = PIL.Image.frombytes('RGBA', (self.canvas_size, self.canvas_size), image_data)\n",
    "\n",
    "        # Convert to grayscale\n",
    "        img = img.convert('L')\n",
    "\n",
    "        # Add thresholding to make strokes more distinct\n",
    "        img = img.point(lambda x: 0 if x > 128 else 255)\n",
    "\n",
    "        # Center the digit in the image\n",
    "        bbox = img.getbbox()\n",
    "        if bbox:\n",
    "            img = img.crop(bbox)\n",
    "            # Add padding to maintain aspect ratio\n",
    "            padded = PIL.Image.new('L', (max(img.size), max(img.size)), 255)\n",
    "            padded.paste(img, ((max(img.size)-img.size[0])//2, (max(img.size)-img.size[1])//2))\n",
    "            img = padded\n",
    "\n",
    "        # Resize to MNIST dimensions\n",
    "        img = img.resize((28, 28), PIL.Image.Resampling.LANCZOS)\n",
    "\n",
    "        # Convert to tensor and normalize\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),  # convert to tensor\n",
    "                transforms.Normalize(\n",
    "                    (0,), (1,)\n",
    "                ),  # normalize the data such that the mean is 0 and the standard deviation is 1\n",
    "            ]\n",
    "        )\n",
    "        # Add batch dimension\n",
    "        tensor = transform(img).unsqueeze(0)\n",
    "        return tensor\n",
    "\n",
    "    def make_prediction(self, b=None):\n",
    "        \"\"\"Make a prediction on the drawn digit\"\"\"\n",
    "        # Preprocess the image\n",
    "        tensor = self.preprocess_image()\n",
    "\n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            output = self.model(tensor)\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "            prediction = output.argmax(dim=1).item()\n",
    "            confidence = probabilities[0][prediction].item() * 100\n",
    "\n",
    "        # Update result display\n",
    "        self.result_label.value = f'<h3>Prediction: {prediction} (Confidence: {confidence:.2f}%)</h3>'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the MNISTDataModule class to load the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    \"\"\"\n",
    "    PyTorch Lightning data module for MNIST dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dir: str = \"./data\", batch_size: int = 32):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Define transforms\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),  # convert to tensor\n",
    "                transforms.Normalize(\n",
    "                    (0,), (1,)\n",
    "                ),  # normalize the data such that the mean is 0 and the standard deviation is 1\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Download data if needed\"\"\"\n",
    "        datasets.MNIST(self.data_dir, train=True, download=True)\n",
    "        datasets.MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"Setup train, val, and test datasets\"\"\"\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = datasets.MNIST(\n",
    "                self.data_dir, train=True, transform=self.transform\n",
    "            )\n",
    "            self.mnist_train, self.mnist_val = random_split(\n",
    "                mnist_full, [55000, 5000], generator=torch.Generator().manual_seed(42)\n",
    "            )\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = datasets.MNIST(\n",
    "                self.data_dir, train=False, transform=self.transform\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.mnist_train, batch_size=self.batch_size, shuffle=True, num_workers=1\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers=1)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the lecture note for the break down of the code above. \n",
    "\n",
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/skojaku-admin/miniforge3/envs/advnetsci/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "1 | val_accuracy   | MulticlassAccuracy | 0      | train\n",
      "2 | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "3 | conv1          | Conv2d             | 104    | train\n",
      "4 | pool           | AvgPool2d          | 0      | train\n",
      "5 | conv2          | Conv2d             | 1.2 K  | train\n",
      "6 | fc             | Linear             | 1.9 K  | train\n",
      "--------------------------------------------------------------\n",
      "3.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6ff30f40e74e92a8beba22e50ae149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skojaku-admin/miniforge3/envs/advnetsci/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/skojaku-admin/miniforge3/envs/advnetsci/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20141f7548714afd92f759da67f553b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a69779b5f55426380d2bb6a23d2497b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d88f528584b47df9297d2ed1c4b6746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe452d95c904305b667d57782d4a4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16824ff046744dabca977056914c1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, train the model or load a pre-trained model\n",
    "model = LeNet1(learning_rate=1e-3)\n",
    "data_module = MNISTDataModule(batch_size=512)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    accelerator=\"auto\",  # Uses GPU if available\n",
    "    devices=1,\n",
    ")\n",
    "\n",
    "# Train and test\n",
    "trainer.fit(model, data_module)\n",
    "trainer.save_checkpoint('lenet1.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d48d3b20aa47d088090e8af19ccb57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Canvas(height=280, sync_image_data=True, width=280), HBox(children=(Button(description='Clear',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Then create the interactive recognizer\n",
    "recognizer = DigitRecognizer('lenet1.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advnetsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
